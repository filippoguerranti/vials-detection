M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 1
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5010 - global_acc: 0.8080 - class_acc: [0.8171 0.7579 0.9111 0.7450] 
VALID | loss: 0.0996 - global_acc: 0.9644 - class_acc: [0.9993 0.9993 0.9372 0.9204] - BEST!
Epoch 2/40
TRAIN | loss: 0.0917 - global_acc: 0.9719 - class_acc: [0.9982 0.9867 0.9435 0.9594] 
VALID | loss: 0.0646 - global_acc: 0.9728 - class_acc: [0.9986 1.0000 0.9205 0.9733] - BEST!
Epoch 3/40
TRAIN | loss: 0.0688 - global_acc: 0.9788 - class_acc: [0.9984 0.9866 0.9603 0.9694] 
VALID | loss: 0.0709 - global_acc: 0.9723 - class_acc: [1.0000 1.0000 0.8961 0.9920]
Epoch 4/40
TRAIN | loss: 0.0546 - global_acc: 0.9828 - class_acc: [0.9995 0.9892 0.9691 0.9734] 
VALID | loss: 0.0332 - global_acc: 0.9881 - class_acc: [1.0000 1.0000 0.9605 0.9924] - BEST!
Epoch 5/40
TRAIN | loss: 0.0470 - global_acc: 0.9861 - class_acc: [0.9998 0.9878 0.9769 0.9799] 
VALID | loss: 0.0286 - global_acc: 0.9896 - class_acc: [1.0000 1.0000 0.9897 0.9678] - BEST!
Epoch 6/40
TRAIN | loss: 0.0443 - global_acc: 0.9874 - class_acc: [0.9989 0.9884 0.9779 0.9841] 
VALID | loss: 0.3759 - global_acc: 0.8938 - class_acc: [0.9993 0.9993 0.6543 0.9127]
Epoch 7/40
TRAIN | loss: 0.0433 - global_acc: 0.9868 - class_acc: [0.9995 0.9900 0.9789 0.9787] 
VALID | loss: 0.0288 - global_acc: 0.9925 - class_acc: [1.0000 1.0000 0.9721 0.9973] - BEST!
Epoch 8/40
TRAIN | loss: 0.0405 - global_acc: 0.9881 - class_acc: [0.9995 0.9885 0.9821 0.9823] 
VALID | loss: 0.0135 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9874 0.9959] - BEST!
Epoch 9/40
TRAIN | loss: 0.0373 - global_acc: 0.9904 - class_acc: [0.9995 0.9919 0.9840 0.9862] 
VALID | loss: 0.0993 - global_acc: 0.9602 - class_acc: [1.0000 0.9993 0.8382 1.0000]
Epoch 10/40
TRAIN | loss: 0.0336 - global_acc: 0.9903 - class_acc: [1.0000 0.9921 0.9847 0.9840] 
VALID | loss: 0.0227 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 0.9782 0.9922]
Epoch 11/40
TRAIN | loss: 0.0357 - global_acc: 0.9898 - class_acc: [0.9995 0.9905 0.9837 0.9856] 
VALID | loss: 0.0164 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9905 0.9965] - BEST!
Epoch 12/40
TRAIN | loss: 0.0305 - global_acc: 0.9924 - class_acc: [0.9993 0.9908 0.9891 0.9905] 
VALID | loss: 0.0099 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9961 0.9899]
Epoch 13/40
TRAIN | loss: 0.0303 - global_acc: 0.9920 - class_acc: [1.0000 0.9922 0.9881 0.9879] 
VALID | loss: 0.0248 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9697 0.9993]
Epoch 14/40
TRAIN | loss: 0.0314 - global_acc: 0.9921 - class_acc: [0.9998 0.9920 0.9873 0.9894] 
VALID | loss: 0.0142 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9979 0.9822]
Epoch 15/40
TRAIN | loss: 0.0293 - global_acc: 0.9933 - class_acc: [1.0000 0.9940 0.9876 0.9918] 
VALID | loss: 0.0168 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9825 0.9993]
Epoch 16/40
TRAIN | loss: 0.0276 - global_acc: 0.9933 - class_acc: [0.9998 0.9946 0.9874 0.9912] 
VALID | loss: 0.0701 - global_acc: 0.9763 - class_acc: [1.0000 1.0000 0.9089 1.0000]
Epoch 17/40
TRAIN | loss: 0.0328 - global_acc: 0.9916 - class_acc: [0.9986 0.9929 0.9861 0.9888] 
VALID | loss: 0.0142 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9883 0.9961]
Epoch 18/40
TRAIN | loss: 0.0227 - global_acc: 0.9943 - class_acc: [0.9998 0.9947 0.9902 0.9924] 
VALID | loss: 0.0092 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9966 0.9913] - BEST!
Epoch 19/40
TRAIN | loss: 0.0247 - global_acc: 0.9938 - class_acc: [0.9995 0.9948 0.9900 0.9912] 
VALID | loss: 0.0217 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9795 0.9960]
Epoch 20/40
TRAIN | loss: 0.0276 - global_acc: 0.9933 - class_acc: [0.9995 0.9942 0.9878 0.9915] 
VALID | loss: 0.0080 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9946 0.9966] - BEST!
Epoch 21/40
TRAIN | loss: 0.0232 - global_acc: 0.9946 - class_acc: [1.0000 0.9943 0.9909 0.9929] 
VALID | loss: 0.0149 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9852 0.9979]
Epoch 22/40
TRAIN | loss: 0.0214 - global_acc: 0.9948 - class_acc: [0.9998 0.9946 0.9908 0.9940] 
VALID | loss: 0.0104 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9960 0.9878]
Epoch 23/40
TRAIN | loss: 0.0225 - global_acc: 0.9949 - class_acc: [0.9998 0.9962 0.9901 0.9934] 
VALID | loss: 0.0086 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9952 0.9966] - BEST!
Epoch 24/40
TRAIN | loss: 0.0207 - global_acc: 0.9952 - class_acc: [0.9998 0.9948 0.9927 0.9935] 
VALID | loss: 0.0123 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9860 0.9986]
Epoch 25/40
TRAIN | loss: 0.0233 - global_acc: 0.9943 - class_acc: [0.9995 0.9929 0.9918 0.9928] 
VALID | loss: 0.0080 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9923 0.9986]
Epoch 26/40
TRAIN | loss: 0.0223 - global_acc: 0.9946 - class_acc: [1.0000 0.9947 0.9901 0.9935] 
VALID | loss: 0.0131 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9899 0.9980]
Epoch 27/40
TRAIN | loss: 0.0218 - global_acc: 0.9946 - class_acc: [1.0000 0.9949 0.9898 0.9939] 
VALID | loss: 0.0141 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9858 1.0000]
Epoch 28/40
TRAIN | loss: 0.0216 - global_acc: 0.9946 - class_acc: [0.9995 0.9946 0.9918 0.9924] 
VALID | loss: 0.0089 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9937 0.9973]
Epoch 29/40
TRAIN | loss: 0.0215 - global_acc: 0.9946 - class_acc: [1.0000 0.9952 0.9919 0.9912] 
VALID | loss: 0.0097 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9924 1.0000] - BEST!
Epoch 30/40
TRAIN | loss: 0.0218 - global_acc: 0.9948 - class_acc: [1.0000 0.9955 0.9913 0.9925] 
VALID | loss: 0.0160 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9895 0.9973]
Epoch 31/40
TRAIN | loss: 0.0195 - global_acc: 0.9953 - class_acc: [1.0000 0.9930 0.9929 0.9954] 
VALID | loss: 0.0114 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 1.0000 0.9833]
Epoch 32/40
TRAIN | loss: 0.0224 - global_acc: 0.9947 - class_acc: [0.9998 0.9947 0.9905 0.9936] 
VALID | loss: 0.0150 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9934 0.9993] - BEST!
Epoch 33/40
TRAIN | loss: 0.0144 - global_acc: 0.9964 - class_acc: [1.0000 0.9968 0.9941 0.9948] 
VALID | loss: 0.0053 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9966 0.9980] - BEST!
Epoch 34/40
TRAIN | loss: 0.0168 - global_acc: 0.9955 - class_acc: [0.9998 0.9950 0.9938 0.9932] 
VALID | loss: 0.0057 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9965 0.9993] - BEST!
Epoch 35/40
TRAIN | loss: 0.0213 - global_acc: 0.9956 - class_acc: [0.9998 0.9954 0.9936 0.9937] 
VALID | loss: 0.0087 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9980 0.9917]
Epoch 36/40
TRAIN | loss: 0.0169 - global_acc: 0.9960 - class_acc: [0.9998 0.9948 0.9943 0.9950] 
VALID | loss: 0.0070 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9993 0.9931]
Epoch 37/40
TRAIN | loss: 0.0160 - global_acc: 0.9963 - class_acc: [1.0000 0.9945 0.9956 0.9951] 
VALID | loss: 0.0090 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9946 0.9993]
Epoch 38/40
TRAIN | loss: 0.0187 - global_acc: 0.9963 - class_acc: [0.9998 0.9959 0.9942 0.9952] 
VALID | loss: 0.0039 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9973 0.9967]
Epoch 39/40
TRAIN | loss: 0.0184 - global_acc: 0.9957 - class_acc: [0.9998 0.9962 0.9937 0.9934] 
VALID | loss: 0.0103 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9959 0.9993]
Epoch 40/40
TRAIN | loss: 0.0225 - global_acc: 0.9955 - class_acc: [0.9998 0.9960 0.9924 0.9938] 
VALID | loss: 0.0144 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9932 0.9993]


Evaluating...
TEST | loss: 0.0495 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 1.0000 0.9911]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 2
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5307 - global_acc: 0.8079 - class_acc: [0.9011 0.6918 0.9128 0.7306] 
VALID | loss: 0.1204 - global_acc: 0.9523 - class_acc: [1.0000 1.0000 0.8233 0.9827] - BEST!
Epoch 2/40
TRAIN | loss: 0.1005 - global_acc: 0.9688 - class_acc: [0.9979 0.9843 0.9424 0.9503] 
VALID | loss: 0.0602 - global_acc: 0.9760 - class_acc: [1.0000 1.0000 0.9568 0.9459] - BEST!
Epoch 3/40
TRAIN | loss: 0.0720 - global_acc: 0.9768 - class_acc: [0.9986 0.9837 0.9607 0.9643] 
VALID | loss: 0.0411 - global_acc: 0.9877 - class_acc: [1.0000 1.0000 0.9606 0.9911] - BEST!
Epoch 4/40
TRAIN | loss: 0.0604 - global_acc: 0.9790 - class_acc: [0.9991 0.9834 0.9681 0.9654] 
VALID | loss: 0.0330 - global_acc: 0.9888 - class_acc: [0.9993 1.0000 0.9830 0.9722] - BEST!
Epoch 5/40
TRAIN | loss: 0.0472 - global_acc: 0.9840 - class_acc: [1.0000 0.9868 0.9750 0.9742] 
VALID | loss: 0.0250 - global_acc: 0.9905 - class_acc: [1.0000 1.0000 0.9861 0.9753] - BEST!
Epoch 6/40
TRAIN | loss: 0.0396 - global_acc: 0.9862 - class_acc: [0.9995 0.9884 0.9823 0.9746] 
VALID | loss: 0.0347 - global_acc: 0.9869 - class_acc: [1.0000 1.0000 0.9881 0.9588]
Epoch 7/40
TRAIN | loss: 0.0368 - global_acc: 0.9883 - class_acc: [0.9993 0.9904 0.9815 0.9821] 
VALID | loss: 0.0238 - global_acc: 0.9915 - class_acc: [1.0000 1.0000 0.9678 0.9986] - BEST!
Epoch 8/40
TRAIN | loss: 0.0410 - global_acc: 0.9876 - class_acc: [0.9995 0.9893 0.9840 0.9777] 
VALID | loss: 0.0136 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9979 0.9849] - BEST!
Epoch 9/40
TRAIN | loss: 0.0321 - global_acc: 0.9902 - class_acc: [1.0000 0.9911 0.9856 0.9842] 
VALID | loss: 0.0202 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9896 0.9890]
Epoch 10/40
TRAIN | loss: 0.0380 - global_acc: 0.9893 - class_acc: [0.9995 0.9917 0.9829 0.9829] 
VALID | loss: 0.0217 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9790 0.9980]
Epoch 11/40
TRAIN | loss: 0.0340 - global_acc: 0.9913 - class_acc: [0.9998 0.9937 0.9855 0.9861] 
VALID | loss: 0.0178 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9891 0.9879]
Epoch 12/40
TRAIN | loss: 0.0290 - global_acc: 0.9925 - class_acc: [0.9998 0.9931 0.9877 0.9896] 
VALID | loss: 0.0683 - global_acc: 0.9750 - class_acc: [1.0000 0.9993 0.9033 1.0000]
Epoch 13/40
TRAIN | loss: 0.0281 - global_acc: 0.9916 - class_acc: [1.0000 0.9922 0.9844 0.9895] 
VALID | loss: 0.0078 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9967 0.9966] - BEST!
Epoch 14/40
TRAIN | loss: 0.0310 - global_acc: 0.9912 - class_acc: [0.9989 0.9915 0.9847 0.9897] 
VALID | loss: 0.0126 - global_acc: 0.9963 - class_acc: [1.0000 0.9993 0.9954 0.9899]
Epoch 15/40
TRAIN | loss: 0.0303 - global_acc: 0.9923 - class_acc: [1.0000 0.9935 0.9885 0.9874] 
VALID | loss: 0.0406 - global_acc: 0.9872 - class_acc: [1.0000 1.0000 0.9501 0.9986]
Epoch 16/40
TRAIN | loss: 0.0220 - global_acc: 0.9947 - class_acc: [1.0000 0.9921 0.9928 0.9939] 
VALID | loss: 0.0176 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9837 0.9993]
Epoch 17/40
TRAIN | loss: 0.0215 - global_acc: 0.9932 - class_acc: [1.0000 0.9938 0.9884 0.9905] 
VALID | loss: 0.0061 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9979 0.9932]
Epoch 18/40
TRAIN | loss: 0.0286 - global_acc: 0.9917 - class_acc: [0.9993 0.9921 0.9858 0.9896] 
VALID | loss: 0.0563 - global_acc: 0.9835 - class_acc: [1.0000 1.0000 0.9336 0.9993]
Epoch 19/40
TRAIN | loss: 0.0223 - global_acc: 0.9940 - class_acc: [0.9998 0.9948 0.9886 0.9928] 
VALID | loss: 0.0169 - global_acc: 0.9954 - class_acc: [1.0000 0.9993 0.9857 0.9966]
Epoch 20/40
TRAIN | loss: 0.0246 - global_acc: 0.9943 - class_acc: [0.9998 0.9951 0.9898 0.9924] 
VALID | loss: 0.0174 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9802 0.9993]
Epoch 21/40
TRAIN | loss: 0.0221 - global_acc: 0.9948 - class_acc: [0.9998 0.9951 0.9900 0.9941] 
VALID | loss: 0.0062 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9993 0.9967] - BEST!
Epoch 22/40
TRAIN | loss: 0.0195 - global_acc: 0.9951 - class_acc: [1.0000 0.9962 0.9902 0.9940] 
VALID | loss: 0.0138 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9930 0.9859]
Epoch 23/40
TRAIN | loss: 0.0186 - global_acc: 0.9951 - class_acc: [0.9995 0.9956 0.9906 0.9946] 
VALID | loss: 0.0122 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9858 1.0000]
Epoch 24/40
TRAIN | loss: 0.0208 - global_acc: 0.9944 - class_acc: [1.0000 0.9947 0.9907 0.9924] 
VALID | loss: 0.0153 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9898 0.9986]
Epoch 25/40
TRAIN | loss: 0.0182 - global_acc: 0.9951 - class_acc: [1.0000 0.9947 0.9906 0.9952] 
VALID | loss: 0.0139 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9980 0.9844]
Epoch 26/40
TRAIN | loss: 0.0207 - global_acc: 0.9951 - class_acc: [0.9995 0.9954 0.9917 0.9939] 
VALID | loss: 0.0121 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9866 0.9993]
Epoch 27/40
TRAIN | loss: 0.0175 - global_acc: 0.9958 - class_acc: [0.9998 0.9969 0.9926 0.9938] 
VALID | loss: 0.0122 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9905 1.0000]
Epoch 28/40
TRAIN | loss: 0.0217 - global_acc: 0.9951 - class_acc: [0.9998 0.9961 0.9911 0.9930] 
VALID | loss: 0.0051 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9986 0.9966]
Epoch 29/40
TRAIN | loss: 0.0195 - global_acc: 0.9955 - class_acc: [0.9993 0.9970 0.9912 0.9942] 
VALID | loss: 0.0186 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9831 0.9986]
Epoch 30/40
TRAIN | loss: 0.0165 - global_acc: 0.9960 - class_acc: [0.9998 0.9960 0.9930 0.9952] 
VALID | loss: 0.0156 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9911 1.0000]
Epoch 31/40
TRAIN | loss: 0.0217 - global_acc: 0.9944 - class_acc: [0.9993 0.9945 0.9905 0.9933] 
VALID | loss: 0.0102 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9941 0.9986]
Epoch 32/40
TRAIN | loss: 0.0168 - global_acc: 0.9967 - class_acc: [1.0000 0.9977 0.9949 0.9941] 
VALID | loss: 0.0188 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9871 1.0000]
Epoch 33/40
TRAIN | loss: 0.0139 - global_acc: 0.9964 - class_acc: [1.0000 0.9964 0.9940 0.9951] 
VALID | loss: 0.0108 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9934 0.9986]
Epoch 34/40
TRAIN | loss: 0.0148 - global_acc: 0.9966 - class_acc: [0.9998 0.9955 0.9954 0.9958] 
VALID | loss: 0.0104 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9961 0.9993]
Epoch 35/40
TRAIN | loss: 0.0144 - global_acc: 0.9967 - class_acc: [1.0000 0.9968 0.9939 0.9959] 
VALID | loss: 0.0365 - global_acc: 0.9900 - class_acc: [1.0000 1.0000 0.9584 1.0000]
Epoch 36/40
TRAIN | loss: 0.0133 - global_acc: 0.9965 - class_acc: [0.9998 0.9973 0.9950 0.9941] 
VALID | loss: 0.0060 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9966 0.9986]
Epoch 37/40
TRAIN | loss: 0.0146 - global_acc: 0.9966 - class_acc: [1.0000 0.9965 0.9938 0.9962] 
VALID | loss: 0.0330 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9847 0.9993]
Epoch 38/40
TRAIN | loss: 0.0169 - global_acc: 0.9953 - class_acc: [0.9993 0.9946 0.9939 0.9934] 
VALID | loss: 0.0253 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9812 1.0000]
Epoch 39/40
TRAIN | loss: 0.0193 - global_acc: 0.9960 - class_acc: [0.9995 0.9977 0.9917 0.9951] 
VALID | loss: 0.0076 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9967 0.9959]
Epoch 40/40
TRAIN | loss: 0.0136 - global_acc: 0.9969 - class_acc: [1.0000 0.9972 0.9953 0.9952] 
VALID | loss: 0.0076 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9993 0.9920]


Evaluating...
TEST | loss: 0.2787 - global_acc: 0.8973 - class_acc: [1.0000 1.0000 1.0000 0.7453]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 3
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5372 - global_acc: 0.7951 - class_acc: [0.8117 0.7679 0.7761 0.8248] 
VALID | loss: 0.1051 - global_acc: 0.9622 - class_acc: [0.9993 1.0000 0.9435 0.9040] - BEST!
Epoch 2/40
TRAIN | loss: 0.0907 - global_acc: 0.9745 - class_acc: [0.9982 0.9890 0.9512 0.9599] 
VALID | loss: 0.2310 - global_acc: 0.9045 - class_acc: [1.0000 0.9993 0.6103 0.9986]
Epoch 3/40
TRAIN | loss: 0.0645 - global_acc: 0.9812 - class_acc: [0.9993 0.9892 0.9664 0.9704] 
VALID | loss: 0.0410 - global_acc: 0.9835 - class_acc: [0.9993 0.9993 0.9810 0.9553] - BEST!
Epoch 4/40
TRAIN | loss: 0.0536 - global_acc: 0.9841 - class_acc: [0.9991 0.9898 0.9734 0.9742] 
VALID | loss: 0.0945 - global_acc: 0.9637 - class_acc: [1.0000 1.0000 0.8575 0.9986]
Epoch 5/40
TRAIN | loss: 0.0438 - global_acc: 0.9874 - class_acc: [0.9995 0.9916 0.9789 0.9800] 
VALID | loss: 0.0697 - global_acc: 0.9738 - class_acc: [1.0000 0.9993 0.9008 0.9993]
Epoch 6/40
TRAIN | loss: 0.0432 - global_acc: 0.9876 - class_acc: [0.9991 0.9914 0.9794 0.9809] 
VALID | loss: 0.0347 - global_acc: 0.9884 - class_acc: [1.0000 1.0000 0.9705 0.9836] - BEST!
Epoch 7/40
TRAIN | loss: 0.0356 - global_acc: 0.9898 - class_acc: [0.9998 0.9925 0.9811 0.9857] 
VALID | loss: 0.0230 - global_acc: 0.9930 - class_acc: [0.9993 1.0000 0.9777 0.9952] - BEST!
Epoch 8/40
TRAIN | loss: 0.0339 - global_acc: 0.9900 - class_acc: [0.9998 0.9932 0.9824 0.9846] 
VALID | loss: 0.0216 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9786 0.9942] - BEST!
Epoch 9/40
TRAIN | loss: 0.0326 - global_acc: 0.9910 - class_acc: [0.9996 0.9948 0.9847 0.9848] 
VALID | loss: 0.0207 - global_acc: 0.9937 - class_acc: [1.0000 0.9993 0.9898 0.9857] - BEST!
Epoch 10/40
TRAIN | loss: 0.0262 - global_acc: 0.9933 - class_acc: [1.0000 0.9957 0.9882 0.9892] 
VALID | loss: 0.0487 - global_acc: 0.9816 - class_acc: [1.0000 1.0000 0.9283 0.9980]
Epoch 11/40
TRAIN | loss: 0.0286 - global_acc: 0.9921 - class_acc: [0.9991 0.9938 0.9887 0.9869] 
VALID | loss: 0.0154 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9951 0.9879] - BEST!
Epoch 12/40
TRAIN | loss: 0.0263 - global_acc: 0.9940 - class_acc: [0.9995 0.9962 0.9897 0.9905] 
VALID | loss: 0.0138 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9896 0.9924]
Epoch 13/40
TRAIN | loss: 0.0237 - global_acc: 0.9939 - class_acc: [0.9998 0.9961 0.9884 0.9913] 
VALID | loss: 0.0154 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9860 0.9945]
Epoch 14/40
TRAIN | loss: 0.0243 - global_acc: 0.9944 - class_acc: [0.9998 0.9968 0.9904 0.9905] 
VALID | loss: 0.0132 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9919 0.9968] - BEST!
Epoch 15/40
TRAIN | loss: 0.0268 - global_acc: 0.9943 - class_acc: [0.9993 0.9962 0.9903 0.9916] 
VALID | loss: 1.4906 - global_acc: 0.7716 - class_acc: [0.9993 0.9993 0.5789 0.5061]
Epoch 16/40
TRAIN | loss: 0.0292 - global_acc: 0.9929 - class_acc: [0.9993 0.9957 0.9888 0.9877] 
VALID | loss: 0.0886 - global_acc: 0.9719 - class_acc: [1.0000 1.0000 0.9987 0.8877]
Epoch 17/40
TRAIN | loss: 0.0212 - global_acc: 0.9944 - class_acc: [1.0000 0.9952 0.9895 0.9929] 
VALID | loss: 0.0107 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9934 0.9979] - BEST!
Epoch 18/40
TRAIN | loss: 0.0234 - global_acc: 0.9947 - class_acc: [1.0000 0.9962 0.9911 0.9916] 
VALID | loss: 0.0124 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9864 1.0000]
Epoch 19/40
TRAIN | loss: 0.0242 - global_acc: 0.9946 - class_acc: [0.9995 0.9973 0.9903 0.9911] 
VALID | loss: 0.0154 - global_acc: 0.9985 - class_acc: [1.0000 0.9993 0.9953 0.9993] - BEST!
Epoch 20/40
TRAIN | loss: 0.0221 - global_acc: 0.9955 - class_acc: [1.0000 0.9975 0.9915 0.9930] 
VALID | loss: 0.0157 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9866 1.0000]
Epoch 21/40
TRAIN | loss: 0.0170 - global_acc: 0.9959 - class_acc: [0.9998 0.9968 0.9928 0.9943] 
VALID | loss: 0.0050 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9980 0.9966] - BEST!
Epoch 22/40
TRAIN | loss: 0.0224 - global_acc: 0.9949 - class_acc: [0.9998 0.9970 0.9911 0.9917] 
VALID | loss: 0.0091 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9980 0.9945]
Epoch 23/40
TRAIN | loss: 0.0199 - global_acc: 0.9949 - class_acc: [0.9995 0.9980 0.9903 0.9918] 
VALID | loss: 0.0108 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9903 0.9986]
Epoch 24/40
TRAIN | loss: 0.0217 - global_acc: 0.9953 - class_acc: [0.9993 0.9945 0.9935 0.9938] 
VALID | loss: 0.0068 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 1.0000 0.9927]
Epoch 25/40
TRAIN | loss: 0.0139 - global_acc: 0.9965 - class_acc: [1.0000 0.9984 0.9935 0.9943] 
VALID | loss: 0.0179 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 1.0000 0.9756]
Epoch 26/40
TRAIN | loss: 0.0152 - global_acc: 0.9963 - class_acc: [1.0000 0.9980 0.9937 0.9937] 
VALID | loss: 0.0105 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9979 0.9886]
Epoch 27/40
TRAIN | loss: 0.0179 - global_acc: 0.9961 - class_acc: [1.0000 0.9967 0.9927 0.9953] 
VALID | loss: 0.0090 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9941 0.9986]
Epoch 28/40
TRAIN | loss: 0.0181 - global_acc: 0.9964 - class_acc: [0.9998 0.9972 0.9928 0.9958] 
VALID | loss: 0.0068 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9979 0.9954]
Epoch 29/40
TRAIN | loss: 0.0167 - global_acc: 0.9963 - class_acc: [0.9998 0.9993 0.9932 0.9927] 
VALID | loss: 0.0157 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9876 0.9987]
Epoch 30/40
TRAIN | loss: 0.0198 - global_acc: 0.9955 - class_acc: [0.9998 0.9968 0.9907 0.9944] 
VALID | loss: 0.0115 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9993 0.9850]
Epoch 31/40
TRAIN | loss: 0.0151 - global_acc: 0.9968 - class_acc: [0.9998 0.9989 0.9932 0.9954] 
VALID | loss: 0.0122 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9913 0.9979]
Epoch 32/40
TRAIN | loss: 0.0234 - global_acc: 0.9955 - class_acc: [0.9998 0.9957 0.9926 0.9941] 
VALID | loss: 0.0467 - global_acc: 0.9823 - class_acc: [1.0000 1.0000 0.9898 0.9396]
Epoch 33/40
TRAIN | loss: 0.0159 - global_acc: 0.9968 - class_acc: [0.9998 0.9980 0.9936 0.9960] 
VALID | loss: 0.0069 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9948 0.9973]
Epoch 34/40
TRAIN | loss: 0.0164 - global_acc: 0.9961 - class_acc: [0.9995 0.9980 0.9925 0.9946] 
VALID | loss: 0.0109 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9993 0.9871]
Epoch 35/40
TRAIN | loss: 0.0208 - global_acc: 0.9959 - class_acc: [0.9995 0.9976 0.9929 0.9936] 
VALID | loss: 0.0082 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9974 0.9952]
Epoch 36/40
TRAIN | loss: 0.0143 - global_acc: 0.9969 - class_acc: [0.9998 0.9989 0.9926 0.9964] 
VALID | loss: 0.0155 - global_acc: 0.9961 - class_acc: [1.0000 0.9957 0.9972 0.9914]
Epoch 37/40
TRAIN | loss: 0.0185 - global_acc: 0.9968 - class_acc: [1.0000 0.9968 0.9934 0.9969] 
VALID | loss: 0.0086 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9987 0.9972] - BEST!
Epoch 38/40
TRAIN | loss: 0.0143 - global_acc: 0.9974 - class_acc: [1.0000 0.9975 0.9954 0.9966] 
VALID | loss: 0.0100 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9973 0.9966]
Epoch 39/40
TRAIN | loss: 0.0130 - global_acc: 0.9977 - class_acc: [1.0000 0.9972 0.9959 0.9975] 
VALID | loss: 0.0041 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9993 0.9980] - BEST!
Epoch 40/40
TRAIN | loss: 0.0144 - global_acc: 0.9977 - class_acc: [1.0000 0.9972 0.9958 0.9978] 
VALID | loss: 0.0159 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9848 0.9979]


Evaluating...
TEST | loss: 0.3221 - global_acc: 0.9507 - class_acc: [1.0000 1.0000 1.0000 0.8777]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 4
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5231 - global_acc: 0.7593 - class_acc: [0.9739 0.7926 0.5771 0.6845] 
VALID | loss: 0.3460 - global_acc: 0.8366 - class_acc: [1.0000 0.9993 0.3326 0.9987] - BEST!
Epoch 2/40
TRAIN | loss: 0.0900 - global_acc: 0.9732 - class_acc: [0.9931 0.9847 0.9365 0.9777] 
VALID | loss: 0.3541 - global_acc: 0.8693 - class_acc: [0.9993 0.9993 0.4957 1.0000] - BEST!
Epoch 3/40
TRAIN | loss: 0.0688 - global_acc: 0.9809 - class_acc: [0.9930 0.9879 0.9567 0.9860] 
VALID | loss: 0.1399 - global_acc: 0.9404 - class_acc: [1.0000 1.0000 0.7703 0.9986] - BEST!
Epoch 4/40
TRAIN | loss: 0.0543 - global_acc: 0.9842 - class_acc: [0.9952 0.9902 0.9638 0.9878] 
VALID | loss: 0.1092 - global_acc: 0.9568 - class_acc: [0.9993 1.0000 0.8267 0.9979] - BEST!
Epoch 5/40
TRAIN | loss: 0.0513 - global_acc: 0.9864 - class_acc: [0.9953 0.9915 0.9707 0.9883] 
VALID | loss: 0.0687 - global_acc: 0.9738 - class_acc: [0.9973 1.0000 0.8984 0.9986] - BEST!
Epoch 6/40
TRAIN | loss: 0.0416 - global_acc: 0.9891 - class_acc: [0.9952 0.9920 0.9762 0.9927] 
VALID | loss: 0.1839 - global_acc: 0.9341 - class_acc: [1.0000 1.0000 0.7358 0.9993]
Epoch 7/40
TRAIN | loss: 0.0434 - global_acc: 0.9900 - class_acc: [0.9943 0.9891 0.9828 0.9939] 
VALID | loss: 0.0769 - global_acc: 0.9694 - class_acc: [1.0000 1.0000 0.8780 1.0000]
Epoch 8/40
TRAIN | loss: 0.0345 - global_acc: 0.9915 - class_acc: [0.9950 0.9925 0.9833 0.9950] 
VALID | loss: 0.0850 - global_acc: 0.9632 - class_acc: [1.0000 1.0000 0.8486 1.0000]
Epoch 9/40
TRAIN | loss: 0.0350 - global_acc: 0.9917 - class_acc: [0.9957 0.9935 0.9827 0.9948] 
VALID | loss: 0.0790 - global_acc: 0.9670 - class_acc: [1.0000 1.0000 0.8677 1.0000]
Epoch 10/40
TRAIN | loss: 0.0364 - global_acc: 0.9903 - class_acc: [0.9968 0.9937 0.9797 0.9909] 
VALID | loss: 0.0689 - global_acc: 0.9738 - class_acc: [1.0000 1.0000 0.8960 1.0000]
Epoch 11/40
TRAIN | loss: 0.0272 - global_acc: 0.9936 - class_acc: [0.9961 0.9956 0.9870 0.9958] 
VALID | loss: 0.0668 - global_acc: 0.9731 - class_acc: [1.0000 1.0000 0.8920 1.0000]
Epoch 12/40
TRAIN | loss: 0.0242 - global_acc: 0.9936 - class_acc: [0.9970 0.9943 0.9882 0.9953] 
VALID | loss: 0.0424 - global_acc: 0.9845 - class_acc: [1.0000 1.0000 0.9404 0.9993] - BEST!
Epoch 13/40
TRAIN | loss: 0.0276 - global_acc: 0.9934 - class_acc: [0.9968 0.9930 0.9886 0.9952] 
VALID | loss: 0.0698 - global_acc: 0.9763 - class_acc: [1.0000 1.0000 0.9049 1.0000]
Epoch 14/40
TRAIN | loss: 0.0292 - global_acc: 0.9940 - class_acc: [0.9968 0.9955 0.9887 0.9949] 
VALID | loss: 0.0378 - global_acc: 0.9867 - class_acc: [1.0000 1.0000 0.9472 1.0000] - BEST!
Epoch 15/40
TRAIN | loss: 0.0244 - global_acc: 0.9944 - class_acc: [0.9955 0.9958 0.9905 0.9957] 
VALID | loss: 0.0525 - global_acc: 0.9831 - class_acc: [1.0000 1.0000 0.9340 1.0000]
Epoch 16/40
TRAIN | loss: 0.0208 - global_acc: 0.9947 - class_acc: [0.9979 0.9957 0.9892 0.9960] 
VALID | loss: 0.0907 - global_acc: 0.9673 - class_acc: [1.0000 1.0000 0.8691 1.0000]
Epoch 17/40
TRAIN | loss: 0.0246 - global_acc: 0.9947 - class_acc: [0.9964 0.9950 0.9896 0.9976] 
VALID | loss: 0.0379 - global_acc: 0.9883 - class_acc: [1.0000 1.0000 0.9535 1.0000] - BEST!
Epoch 18/40
TRAIN | loss: 0.0188 - global_acc: 0.9961 - class_acc: [0.9977 0.9960 0.9932 0.9975] 
VALID | loss: 0.0560 - global_acc: 0.9813 - class_acc: [1.0000 1.0000 0.9245 1.0000]
Epoch 19/40
TRAIN | loss: 0.0232 - global_acc: 0.9947 - class_acc: [0.9960 0.9934 0.9931 0.9961] 
VALID | loss: 0.0199 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9765 1.0000] - BEST!
Epoch 20/40
TRAIN | loss: 0.0182 - global_acc: 0.9952 - class_acc: [0.9971 0.9948 0.9927 0.9961] 
VALID | loss: 0.0783 - global_acc: 0.9721 - class_acc: [1.0000 1.0000 0.8893 1.0000]
Epoch 21/40
TRAIN | loss: 0.0220 - global_acc: 0.9946 - class_acc: [0.9970 0.9963 0.9900 0.9951] 
VALID | loss: 0.0275 - global_acc: 0.9905 - class_acc: [1.0000 0.9986 0.9647 1.0000]
Epoch 22/40
TRAIN | loss: 0.0189 - global_acc: 0.9955 - class_acc: [0.9966 0.9969 0.9930 0.9957] 
VALID | loss: 0.0930 - global_acc: 0.9673 - class_acc: [1.0000 1.0000 0.8695 1.0000]
Epoch 23/40
TRAIN | loss: 0.0167 - global_acc: 0.9961 - class_acc: [0.9968 0.9945 0.9950 0.9982] 
VALID | loss: 0.0240 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9677 1.0000]
Epoch 24/40
TRAIN | loss: 0.0177 - global_acc: 0.9954 - class_acc: [0.9961 0.9952 0.9942 0.9961] 
VALID | loss: 0.1030 - global_acc: 0.9658 - class_acc: [1.0000 1.0000 0.8680 1.0000]
Epoch 25/40
TRAIN | loss: 0.0163 - global_acc: 0.9959 - class_acc: [0.9977 0.9968 0.9935 0.9957] 
VALID | loss: 0.0238 - global_acc: 0.9922 - class_acc: [0.9993 1.0000 0.9699 1.0000]
Epoch 26/40
TRAIN | loss: 0.0147 - global_acc: 0.9968 - class_acc: [0.9982 0.9966 0.9953 0.9973] 
VALID | loss: 0.0396 - global_acc: 0.9866 - class_acc: [1.0000 1.0000 0.9463 1.0000]
Epoch 27/40
TRAIN | loss: 0.0161 - global_acc: 0.9954 - class_acc: [0.9965 0.9948 0.9923 0.9980] 
VALID | loss: 0.0601 - global_acc: 0.9816 - class_acc: [1.0000 1.0000 0.9269 1.0000]
Epoch 28/40
TRAIN | loss: 0.0145 - global_acc: 0.9963 - class_acc: [0.9982 0.9952 0.9946 0.9971] 
VALID | loss: 0.0695 - global_acc: 0.9796 - class_acc: [1.0000 1.0000 0.9193 1.0000]
Epoch 29/40
TRAIN | loss: 0.0114 - global_acc: 0.9968 - class_acc: [0.9984 0.9969 0.9947 0.9970] 
VALID | loss: 0.0513 - global_acc: 0.9828 - class_acc: [1.0000 1.0000 0.9338 1.0000]
Epoch 30/40
TRAIN | loss: 0.0190 - global_acc: 0.9947 - class_acc: [0.9968 0.9946 0.9928 0.9946] 
VALID | loss: 0.0698 - global_acc: 0.9787 - class_acc: [0.9993 1.0000 0.9158 1.0000]
Epoch 31/40
TRAIN | loss: 0.0154 - global_acc: 0.9963 - class_acc: [0.9972 0.9968 0.9950 0.9959] 
VALID | loss: 0.0177 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9843 0.9980] - BEST!
Epoch 32/40
TRAIN | loss: 0.0186 - global_acc: 0.9963 - class_acc: [0.9979 0.9962 0.9945 0.9966] 
VALID | loss: 0.0577 - global_acc: 0.9828 - class_acc: [1.0000 1.0000 0.9344 1.0000]
Epoch 33/40
TRAIN | loss: 0.0143 - global_acc: 0.9965 - class_acc: [0.9968 0.9979 0.9945 0.9971] 
VALID | loss: 0.0150 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9838 1.0000] - BEST!
Epoch 34/40
TRAIN | loss: 0.0114 - global_acc: 0.9968 - class_acc: [0.9986 0.9961 0.9953 0.9971] 
VALID | loss: 0.0152 - global_acc: 0.9959 - class_acc: [0.9993 1.0000 0.9853 0.9993]
Epoch 35/40
TRAIN | loss: 0.0153 - global_acc: 0.9960 - class_acc: [0.9964 0.9954 0.9957 0.9964] 
VALID | loss: 0.0142 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9863 0.9993] - BEST!
Epoch 36/40
TRAIN | loss: 0.0146 - global_acc: 0.9963 - class_acc: [0.9982 0.9956 0.9953 0.9962] 
VALID | loss: 0.0518 - global_acc: 0.9835 - class_acc: [1.0000 1.0000 0.9301 1.0000]
Epoch 37/40
TRAIN | loss: 0.0166 - global_acc: 0.9964 - class_acc: [0.9972 0.9954 0.9960 0.9970] 
VALID | loss: 0.0275 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9723 1.0000]
Epoch 38/40
TRAIN | loss: 0.0160 - global_acc: 0.9956 - class_acc: [0.9982 0.9947 0.9948 0.9946] 
VALID | loss: 0.0322 - global_acc: 0.9901 - class_acc: [1.0000 1.0000 0.9613 1.0000]
Epoch 39/40
TRAIN | loss: 0.0124 - global_acc: 0.9967 - class_acc: [0.9991 0.9977 0.9945 0.9954] 
VALID | loss: 0.0596 - global_acc: 0.9831 - class_acc: [0.9993 1.0000 0.9327 1.0000]
Epoch 40/40
TRAIN | loss: 0.0115 - global_acc: 0.9964 - class_acc: [0.9982 0.9958 0.9956 0.9962] 
VALID | loss: 0.0680 - global_acc: 0.9794 - class_acc: [1.0000 1.0000 0.9176 1.0000]


Evaluating...
TEST | loss: 0.0480 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9995 0.9878]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 5
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5124 - global_acc: 0.7977 - class_acc: [0.8383 0.8063 0.8548 0.6890] 
VALID | loss: 0.1212 - global_acc: 0.9496 - class_acc: [1.0000 1.0000 0.8007 0.9912] - BEST!
Epoch 2/40
TRAIN | loss: 0.1172 - global_acc: 0.9618 - class_acc: [0.9986 0.9653 0.9277 0.9555] 
VALID | loss: 0.0601 - global_acc: 0.9804 - class_acc: [1.0000 0.9980 0.9488 0.9746] - BEST!
Epoch 3/40
TRAIN | loss: 0.0931 - global_acc: 0.9690 - class_acc: [0.9989 0.9745 0.9388 0.9641] 
VALID | loss: 0.0504 - global_acc: 0.9823 - class_acc: [0.9993 1.0000 0.9331 0.9959] - BEST!
Epoch 4/40
TRAIN | loss: 0.0773 - global_acc: 0.9734 - class_acc: [0.9993 0.9793 0.9464 0.9684] 
VALID | loss: 0.0438 - global_acc: 0.9838 - class_acc: [1.0000 1.0000 0.9405 0.9925] - BEST!
Epoch 5/40
TRAIN | loss: 0.0677 - global_acc: 0.9782 - class_acc: [0.9989 0.9874 0.9555 0.9711] 
VALID | loss: 0.0781 - global_acc: 0.9690 - class_acc: [1.0000 0.9987 0.8822 0.9993]
Epoch 6/40
TRAIN | loss: 0.0626 - global_acc: 0.9781 - class_acc: [0.9995 0.9854 0.9586 0.9686] 
VALID | loss: 0.0343 - global_acc: 0.9891 - class_acc: [1.0000 1.0000 0.9797 0.9775] - BEST!
Epoch 7/40
TRAIN | loss: 0.0515 - global_acc: 0.9825 - class_acc: [0.9991 0.9867 0.9745 0.9696] 
VALID | loss: 0.0218 - global_acc: 0.9925 - class_acc: [1.0000 0.9993 0.9827 0.9883] - BEST!
Epoch 8/40
TRAIN | loss: 0.0506 - global_acc: 0.9833 - class_acc: [1.0000 0.9853 0.9740 0.9740] 
VALID | loss: 0.0181 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9891 0.9875] - BEST!
Epoch 9/40
TRAIN | loss: 0.0477 - global_acc: 0.9849 - class_acc: [1.0000 0.9910 0.9740 0.9738] 
VALID | loss: 0.0308 - global_acc: 0.9894 - class_acc: [1.0000 1.0000 0.9686 0.9904]
Epoch 10/40
TRAIN | loss: 0.0492 - global_acc: 0.9847 - class_acc: [0.9991 0.9884 0.9748 0.9771] 
VALID | loss: 0.0197 - global_acc: 0.9940 - class_acc: [0.9986 0.9994 0.9835 0.9945] - BEST!
Epoch 11/40
TRAIN | loss: 0.0484 - global_acc: 0.9838 - class_acc: [0.9995 0.9865 0.9742 0.9752] 
VALID | loss: 0.0215 - global_acc: 0.9947 - class_acc: [1.0000 0.9993 0.9873 0.9920] - BEST!
Epoch 12/40
TRAIN | loss: 0.0398 - global_acc: 0.9882 - class_acc: [1.0000 0.9910 0.9791 0.9824] 
VALID | loss: 0.0174 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9847 0.9993] - BEST!
Epoch 13/40
TRAIN | loss: 0.0404 - global_acc: 0.9887 - class_acc: [0.9989 0.9900 0.9792 0.9864] 
VALID | loss: 0.0176 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9839 0.9980]
Epoch 14/40
TRAIN | loss: 0.0446 - global_acc: 0.9868 - class_acc: [0.9991 0.9901 0.9770 0.9811] 
VALID | loss: 0.0208 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9862 0.9964]
Epoch 15/40
TRAIN | loss: 0.0357 - global_acc: 0.9898 - class_acc: [0.9998 0.9918 0.9826 0.9855] 
VALID | loss: 0.0176 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9763 1.0000]
Epoch 16/40
TRAIN | loss: 0.0421 - global_acc: 0.9877 - class_acc: [0.9995 0.9874 0.9793 0.9846] 
VALID | loss: 0.0216 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9908 0.9896]
Epoch 17/40
TRAIN | loss: 0.0329 - global_acc: 0.9910 - class_acc: [1.0000 0.9905 0.9858 0.9879] 
VALID | loss: 0.0149 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9966 0.9960] - BEST!
Epoch 18/40
TRAIN | loss: 0.0312 - global_acc: 0.9906 - class_acc: [0.9998 0.9906 0.9851 0.9868] 
VALID | loss: 0.0130 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9959 0.9890]
Epoch 19/40
TRAIN | loss: 0.0291 - global_acc: 0.9924 - class_acc: [1.0000 0.9886 0.9901 0.9906] 
VALID | loss: 0.0182 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9923 0.9871]
Epoch 20/40
TRAIN | loss: 0.0263 - global_acc: 0.9935 - class_acc: [1.0000 0.9930 0.9902 0.9910] 
VALID | loss: 0.0093 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9915 0.9993]
Epoch 21/40
TRAIN | loss: 0.0319 - global_acc: 0.9932 - class_acc: [0.9995 0.9923 0.9900 0.9908] 
VALID | loss: 9.8294 - global_acc: 0.5096 - class_acc: [0.9993 1.0000 0.0062 0.0230]
Epoch 22/40
TRAIN | loss: 0.0256 - global_acc: 0.9938 - class_acc: [1.0000 0.9911 0.9929 0.9910] 
VALID | loss: 0.0081 - global_acc: 0.9981 - class_acc: [0.9993 1.0000 0.9959 0.9972]
Epoch 23/40
TRAIN | loss: 0.0266 - global_acc: 0.9940 - class_acc: [0.9998 0.9925 0.9933 0.9905] 
VALID | loss: 0.0086 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9953 0.9966]
Epoch 24/40
TRAIN | loss: 0.0306 - global_acc: 0.9925 - class_acc: [0.9991 0.9896 0.9910 0.9903] 
VALID | loss: 0.0110 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9927 0.9973]
Epoch 25/40
TRAIN | loss: 0.0283 - global_acc: 0.9940 - class_acc: [0.9998 0.9924 0.9930 0.9908] 
VALID | loss: 0.0162 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9871 0.9987]
Epoch 26/40
TRAIN | loss: 0.0282 - global_acc: 0.9939 - class_acc: [0.9998 0.9912 0.9936 0.9912] 
VALID | loss: 0.0073 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9947 0.9972]
Epoch 27/40
TRAIN | loss: 0.0281 - global_acc: 0.9933 - class_acc: [0.9998 0.9903 0.9940 0.9892] 
VALID | loss: 0.0125 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9900 0.9960]
Epoch 28/40
TRAIN | loss: 0.0256 - global_acc: 0.9950 - class_acc: [0.9998 0.9921 0.9944 0.9934] 
VALID | loss: 0.0103 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9960 0.9979] - BEST!
Epoch 29/40
TRAIN | loss: 0.0219 - global_acc: 0.9953 - class_acc: [1.0000 0.9948 0.9931 0.9935] 
VALID | loss: 0.0110 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9959 0.9959]
Epoch 30/40
TRAIN | loss: 0.0202 - global_acc: 0.9955 - class_acc: [0.9998 0.9915 0.9959 0.9947] 
VALID | loss: 0.0662 - global_acc: 0.9809 - class_acc: [0.9979 1.0000 1.0000 0.9251]
Epoch 31/40
TRAIN | loss: 0.0264 - global_acc: 0.9942 - class_acc: [1.0000 0.9913 0.9918 0.9934] 
VALID | loss: 0.0110 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9940 0.9993]
Epoch 32/40
TRAIN | loss: 0.0232 - global_acc: 0.9951 - class_acc: [1.0000 0.9939 0.9938 0.9925] 
VALID | loss: 0.0118 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9980 0.9959]
Epoch 33/40
TRAIN | loss: 0.0223 - global_acc: 0.9955 - class_acc: [1.0000 0.9934 0.9960 0.9927] 
VALID | loss: 0.0100 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9987 0.9866]
Epoch 34/40
TRAIN | loss: 0.0250 - global_acc: 0.9940 - class_acc: [0.9998 0.9907 0.9926 0.9930] 
VALID | loss: 0.0102 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9979 0.9993] - BEST!
Epoch 35/40
TRAIN | loss: 0.0259 - global_acc: 0.9945 - class_acc: [1.0000 0.9906 0.9957 0.9914] 
VALID | loss: 0.0109 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9972 0.9953]
Epoch 36/40
TRAIN | loss: 0.0261 - global_acc: 0.9942 - class_acc: [0.9995 0.9913 0.9945 0.9915] 
VALID | loss: 0.0179 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 1.0000 0.9828]
Epoch 37/40
TRAIN | loss: 0.0195 - global_acc: 0.9960 - class_acc: [1.0000 0.9938 0.9964 0.9939] 
VALID | loss: 0.0077 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9993 0.9979]
Epoch 38/40
TRAIN | loss: 0.0194 - global_acc: 0.9956 - class_acc: [1.0000 0.9932 0.9961 0.9932] 
VALID | loss: 0.0100 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9967 1.0000]
Epoch 39/40
TRAIN | loss: 0.0208 - global_acc: 0.9948 - class_acc: [1.0000 0.9912 0.9942 0.9938] 
VALID | loss: 0.0114 - global_acc: 0.9980 - class_acc: [0.9986 1.0000 0.9954 0.9979]
Epoch 40/40
TRAIN | loss: 0.0251 - global_acc: 0.9938 - class_acc: [0.9998 0.9901 0.9932 0.9919] 
VALID | loss: 0.0104 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9960 0.9959]


Evaluating...
TEST | loss: 0.0662 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 1.0000 0.9890]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 6
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.6779 - global_acc: 0.7082 - class_acc: [0.7929 0.4560 0.8370 0.7455] 
VALID | loss: 0.2248 - global_acc: 0.9239 - class_acc: [0.9986 0.9959 0.7158 0.9874] - BEST!
Epoch 2/40
TRAIN | loss: 0.1412 - global_acc: 0.9580 - class_acc: [0.9980 0.9601 0.9442 0.9288] 
VALID | loss: 0.1035 - global_acc: 0.9646 - class_acc: [0.9993 1.0000 0.8740 0.9819] - BEST!
Epoch 3/40
TRAIN | loss: 0.1045 - global_acc: 0.9706 - class_acc: [0.9989 0.9758 0.9623 0.9441] 
VALID | loss: 0.0731 - global_acc: 0.9704 - class_acc: [1.0000 0.9993 0.9856 0.8957] - BEST!
Epoch 4/40
TRAIN | loss: 0.0965 - global_acc: 0.9735 - class_acc: [0.9991 0.9757 0.9652 0.9544] 
VALID | loss: 0.0863 - global_acc: 0.9711 - class_acc: [1.0000 1.0000 0.8863 0.9946] - BEST!
Epoch 5/40
TRAIN | loss: 0.0869 - global_acc: 0.9763 - class_acc: [0.9998 0.9796 0.9673 0.9590] 
VALID | loss: 0.0694 - global_acc: 0.9753 - class_acc: [1.0000 1.0000 0.9066 0.9932] - BEST!
Epoch 6/40
TRAIN | loss: 0.0687 - global_acc: 0.9801 - class_acc: [0.9995 0.9832 0.9778 0.9598] 
VALID | loss: 0.0318 - global_acc: 0.9886 - class_acc: [1.0000 0.9993 0.9787 0.9764] - BEST!
Epoch 7/40
TRAIN | loss: 0.0689 - global_acc: 0.9808 - class_acc: [0.9991 0.9820 0.9742 0.9672] 
VALID | loss: 0.0554 - global_acc: 0.9787 - class_acc: [1.0000 1.0000 0.9153 0.9980]
Epoch 8/40
TRAIN | loss: 0.0592 - global_acc: 0.9842 - class_acc: [0.9995 0.9843 0.9782 0.9752] 
VALID | loss: 0.0661 - global_acc: 0.9762 - class_acc: [1.0000 0.9993 0.9965 0.9096]
Epoch 9/40
TRAIN | loss: 0.0552 - global_acc: 0.9836 - class_acc: [0.9989 0.9837 0.9783 0.9738] 
VALID | loss: 0.0353 - global_acc: 0.9881 - class_acc: [1.0000 0.9993 0.9929 0.9599]
Epoch 10/40
TRAIN | loss: 0.0466 - global_acc: 0.9867 - class_acc: [0.9998 0.9853 0.9833 0.9786] 
VALID | loss: 0.0223 - global_acc: 0.9918 - class_acc: [1.0000 1.0000 0.9959 0.9711] - BEST!
Epoch 11/40
TRAIN | loss: 0.0450 - global_acc: 0.9872 - class_acc: [0.9991 0.9845 0.9854 0.9799] 
VALID | loss: 0.0202 - global_acc: 0.9935 - class_acc: [1.0000 0.9993 0.9798 0.9951] - BEST!
Epoch 12/40
TRAIN | loss: 0.0425 - global_acc: 0.9876 - class_acc: [0.9998 0.9845 0.9862 0.9803] 
VALID | loss: 0.0230 - global_acc: 0.9925 - class_acc: [1.0000 1.0000 0.9875 0.9823]
Epoch 13/40
TRAIN | loss: 0.0412 - global_acc: 0.9889 - class_acc: [0.9991 0.9873 0.9832 0.9857] 
VALID | loss: 0.0254 - global_acc: 0.9911 - class_acc: [1.0000 1.0000 0.9666 0.9987]
Epoch 14/40
TRAIN | loss: 0.0398 - global_acc: 0.9887 - class_acc: [0.9991 0.9845 0.9874 0.9837] 
VALID | loss: 0.0174 - global_acc: 0.9952 - class_acc: [0.9986 1.0000 0.9871 0.9953] - BEST!
Epoch 15/40
TRAIN | loss: 0.0387 - global_acc: 0.9881 - class_acc: [0.9984 0.9785 0.9864 0.9889] 
VALID | loss: 0.0577 - global_acc: 0.9828 - class_acc: [1.0000 1.0000 0.9321 0.9987]
Epoch 16/40
TRAIN | loss: 0.0379 - global_acc: 0.9893 - class_acc: [0.9991 0.9828 0.9869 0.9881] 
VALID | loss: 0.0113 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9979 0.9938] - BEST!
Epoch 17/40
TRAIN | loss: 0.0352 - global_acc: 0.9905 - class_acc: [0.9998 0.9850 0.9877 0.9896] 
VALID | loss: 0.0097 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9946 0.9923]
Epoch 18/40
TRAIN | loss: 0.0319 - global_acc: 0.9908 - class_acc: [0.9993 0.9840 0.9908 0.9889] 
VALID | loss: 0.0111 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9967 0.9910]
Epoch 19/40
TRAIN | loss: 0.0339 - global_acc: 0.9907 - class_acc: [0.9984 0.9853 0.9895 0.9896] 
VALID | loss: 0.0161 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9926 0.9965]
Epoch 20/40
TRAIN | loss: 0.0289 - global_acc: 0.9917 - class_acc: [0.9969 0.9846 0.9909 0.9944] 
VALID | loss: 0.0238 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 0.9724 0.9993]
Epoch 21/40
TRAIN | loss: 0.0429 - global_acc: 0.9885 - class_acc: [0.9943 0.9833 0.9876 0.9889] 
VALID | loss: 0.0279 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9748 0.9927]
Epoch 22/40
TRAIN | loss: 0.0376 - global_acc: 0.9888 - class_acc: [0.9961 0.9882 0.9846 0.9862] 
VALID | loss: 0.0256 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9889 0.9993]
Epoch 23/40
TRAIN | loss: 0.0281 - global_acc: 0.9906 - class_acc: [0.9942 0.9851 0.9918 0.9915] 
VALID | loss: 0.0136 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9916 0.9972]
Epoch 24/40
TRAIN | loss: 0.0259 - global_acc: 0.9924 - class_acc: [0.9978 0.9890 0.9921 0.9906] 
VALID | loss: 0.0381 - global_acc: 0.9913 - class_acc: [1.0000 0.9993 0.9664 1.0000]
Epoch 25/40
TRAIN | loss: 0.0285 - global_acc: 0.9898 - class_acc: [0.9929 0.9864 0.9885 0.9914] 
VALID | loss: 0.0098 - global_acc: 0.9978 - class_acc: [1.0000 0.9994 0.9956 0.9958]
Epoch 26/40
TRAIN | loss: 0.0274 - global_acc: 0.9912 - class_acc: [0.9944 0.9846 0.9932 0.9926] 
VALID | loss: 0.0103 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9967 0.9911]
Epoch 27/40
TRAIN | loss: 0.0240 - global_acc: 0.9917 - class_acc: [0.9953 0.9882 0.9899 0.9936] 
VALID | loss: 0.0140 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9965 0.9841]
Epoch 28/40
TRAIN | loss: 0.0226 - global_acc: 0.9919 - class_acc: [0.9946 0.9874 0.9920 0.9938] 
VALID | loss: 0.0332 - global_acc: 0.9867 - class_acc: [1.0000 1.0000 0.9464 1.0000]
Epoch 29/40
TRAIN | loss: 0.0251 - global_acc: 0.9919 - class_acc: [0.9959 0.9880 0.9899 0.9939] 
VALID | loss: 0.0224 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9882 0.9845]
Epoch 30/40
TRAIN | loss: 0.0222 - global_acc: 0.9923 - class_acc: [0.9948 0.9878 0.9930 0.9935] 
VALID | loss: 0.0116 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9926 0.9980]
Epoch 31/40
TRAIN | loss: 0.0298 - global_acc: 0.9906 - class_acc: [0.9938 0.9863 0.9903 0.9920] 
VALID | loss: 0.0125 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9936 0.9959]
Epoch 32/40
TRAIN | loss: 0.0271 - global_acc: 0.9913 - class_acc: [0.9930 0.9872 0.9910 0.9940] 
VALID | loss: 0.0182 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9918 0.9903]
Epoch 33/40
TRAIN | loss: 0.0223 - global_acc: 0.9918 - class_acc: [0.9935 0.9875 0.9919 0.9943] 
VALID | loss: 0.0116 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9966 0.9945]
Epoch 34/40
TRAIN | loss: 0.0175 - global_acc: 0.9944 - class_acc: [0.9968 0.9893 0.9948 0.9968] 
VALID | loss: 0.0182 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9899 0.9980]
Epoch 35/40
TRAIN | loss: 0.0232 - global_acc: 0.9927 - class_acc: [0.9955 0.9863 0.9943 0.9946] 
VALID | loss: 0.0274 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9814 0.9993]
Epoch 36/40
TRAIN | loss: 0.0218 - global_acc: 0.9931 - class_acc: [0.9970 0.9901 0.9925 0.9928] 
VALID | loss: 0.0196 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9884 0.9993]
Epoch 37/40
TRAIN | loss: 0.0227 - global_acc: 0.9932 - class_acc: [0.9964 0.9902 0.9934 0.9926] 
VALID | loss: 0.0477 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9666 1.0000]
Epoch 38/40
TRAIN | loss: 0.0198 - global_acc: 0.9926 - class_acc: [0.9922 0.9854 0.9967 0.9958] 
VALID | loss: 0.0100 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9965 0.9986] - BEST!
Epoch 39/40
TRAIN | loss: 0.0182 - global_acc: 0.9934 - class_acc: [0.9958 0.9868 0.9955 0.9955] 
VALID | loss: 0.0116 - global_acc: 0.9980 - class_acc: [1.0000 0.9993 0.9925 1.0000]
Epoch 40/40
TRAIN | loss: 0.0231 - global_acc: 0.9917 - class_acc: [0.9939 0.9855 0.9950 0.9922] 
VALID | loss: 0.0182 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9904 0.9980]


Evaluating...
TEST | loss: 0.1581 - global_acc: 0.9424 - class_acc: [1.0000 1.0000 1.0000 0.8570]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 7
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5665 - global_acc: 0.7604 - class_acc: [0.8190 0.8330 0.7668 0.6253] 
VALID | loss: 0.1425 - global_acc: 0.9450 - class_acc: [0.9987 0.9993 0.7958 0.9830] - BEST!
Epoch 2/40
TRAIN | loss: 0.1426 - global_acc: 0.9480 - class_acc: [0.9937 0.9670 0.8986 0.9330] 
VALID | loss: 0.0952 - global_acc: 0.9644 - class_acc: [1.0000 1.0000 0.8654 0.9929] - BEST!
Epoch 3/40
TRAIN | loss: 0.1045 - global_acc: 0.9632 - class_acc: [0.9932 0.9724 0.9326 0.9542] 
VALID | loss: 0.0641 - global_acc: 0.9758 - class_acc: [1.0000 0.9993 0.9811 0.9224] - BEST!
Epoch 4/40
TRAIN | loss: 0.0882 - global_acc: 0.9694 - class_acc: [0.9936 0.9754 0.9442 0.9649] 
VALID | loss: 0.0395 - global_acc: 0.9857 - class_acc: [1.0000 1.0000 0.9790 0.9637] - BEST!
Epoch 5/40
TRAIN | loss: 0.0795 - global_acc: 0.9723 - class_acc: [0.9941 0.9790 0.9516 0.9649] 
VALID | loss: 0.0381 - global_acc: 0.9867 - class_acc: [1.0000 0.9986 0.9497 0.9986] - BEST!
Epoch 6/40
TRAIN | loss: 0.0778 - global_acc: 0.9720 - class_acc: [0.9953 0.9753 0.9539 0.9633] 
VALID | loss: 0.0287 - global_acc: 0.9911 - class_acc: [1.0000 1.0000 0.9828 0.9814] - BEST!
Epoch 7/40
TRAIN | loss: 0.0641 - global_acc: 0.9784 - class_acc: [0.9974 0.9825 0.9645 0.9698] 
VALID | loss: 0.0225 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9831 0.9894] - BEST!
Epoch 8/40
TRAIN | loss: 0.0546 - global_acc: 0.9798 - class_acc: [0.9980 0.9830 0.9666 0.9718] 
VALID | loss: 0.0185 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9877 0.9928] - BEST!
Epoch 9/40
TRAIN | loss: 0.0473 - global_acc: 0.9818 - class_acc: [0.9980 0.9826 0.9718 0.9749] 
VALID | loss: 0.0168 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9822 0.9973]
Epoch 10/40
TRAIN | loss: 0.0431 - global_acc: 0.9837 - class_acc: [0.9966 0.9861 0.9729 0.9795] 
VALID | loss: 0.0224 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 0.9959 0.9751]
Epoch 11/40
TRAIN | loss: 0.0413 - global_acc: 0.9846 - class_acc: [0.9984 0.9863 0.9748 0.9785] 
VALID | loss: 0.0155 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9900 0.9979] - BEST!
Epoch 12/40
TRAIN | loss: 0.0375 - global_acc: 0.9858 - class_acc: [0.9978 0.9872 0.9762 0.9816] 
VALID | loss: 0.0784 - global_acc: 0.9750 - class_acc: [1.0000 1.0000 0.8983 0.9993]
Epoch 13/40
TRAIN | loss: 0.0378 - global_acc: 0.9871 - class_acc: [0.9966 0.9896 0.9797 0.9828] 
VALID | loss: 0.0094 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9946 0.9958] - BEST!
Epoch 14/40
TRAIN | loss: 0.0370 - global_acc: 0.9880 - class_acc: [0.9948 0.9930 0.9791 0.9848] 
VALID | loss: 0.0349 - global_acc: 0.9877 - class_acc: [1.0000 1.0000 0.9958 0.9543]
Epoch 15/40
TRAIN | loss: 0.0312 - global_acc: 0.9885 - class_acc: [0.9966 0.9913 0.9805 0.9854] 
VALID | loss: 0.0135 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9914 0.9986]
Epoch 16/40
TRAIN | loss: 0.0409 - global_acc: 0.9859 - class_acc: [0.9939 0.9901 0.9771 0.9832] 
VALID | loss: 0.0377 - global_acc: 0.9913 - class_acc: [1.0000 0.9993 0.9661 0.9993]
Epoch 17/40
TRAIN | loss: 0.0318 - global_acc: 0.9897 - class_acc: [0.9947 0.9923 0.9845 0.9873] 
VALID | loss: 0.0151 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9815 0.9979]
Epoch 18/40
TRAIN | loss: 0.0324 - global_acc: 0.9904 - class_acc: [0.9942 0.9939 0.9877 0.9861] 
VALID | loss: 0.0142 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9968 0.9939]
Epoch 19/40
TRAIN | loss: 0.0268 - global_acc: 0.9914 - class_acc: [0.9920 0.9943 0.9882 0.9912] 
VALID | loss: 0.0308 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9815 0.9904]
Epoch 20/40
TRAIN | loss: 0.0259 - global_acc: 0.9927 - class_acc: [0.9977 0.9955 0.9882 0.9896] 
VALID | loss: 0.0178 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9869 0.9938]
Epoch 21/40
TRAIN | loss: 0.0221 - global_acc: 0.9931 - class_acc: [0.9952 0.9968 0.9890 0.9915] 
VALID | loss: 0.0115 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9986 0.9894]
Epoch 22/40
TRAIN | loss: 0.0270 - global_acc: 0.9924 - class_acc: [0.9954 0.9954 0.9878 0.9910] 
VALID | loss: 0.0087 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9931 0.9973]
Epoch 23/40
TRAIN | loss: 0.0198 - global_acc: 0.9941 - class_acc: [0.9960 0.9974 0.9887 0.9940] 
VALID | loss: 0.0116 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9934 0.9993] - BEST!
Epoch 24/40
TRAIN | loss: 0.0210 - global_acc: 0.9940 - class_acc: [0.9948 0.9966 0.9914 0.9935] 
VALID | loss: 0.0114 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 1.0000 0.9932] - BEST!
Epoch 25/40
TRAIN | loss: 0.0212 - global_acc: 0.9940 - class_acc: [0.9954 0.9970 0.9915 0.9925] 
VALID | loss: 0.0119 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9932 0.9980]
Epoch 26/40
TRAIN | loss: 0.0196 - global_acc: 0.9949 - class_acc: [0.9966 0.9991 0.9925 0.9914] 
VALID | loss: 0.0081 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9974 0.9979] - BEST!
Epoch 27/40
TRAIN | loss: 0.0179 - global_acc: 0.9948 - class_acc: [0.9955 0.9979 0.9909 0.9951] 
VALID | loss: 0.0095 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9960 0.9980]
Epoch 28/40
TRAIN | loss: 0.0191 - global_acc: 0.9948 - class_acc: [0.9953 0.9970 0.9923 0.9945] 
VALID | loss: 0.0095 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9979 0.9922]
Epoch 29/40
TRAIN | loss: 0.0161 - global_acc: 0.9953 - class_acc: [0.9964 0.9978 0.9920 0.9950] 
VALID | loss: 0.0096 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9917 0.9993]
Epoch 30/40
TRAIN | loss: 0.0166 - global_acc: 0.9949 - class_acc: [0.9948 0.9980 0.9905 0.9962] 
VALID | loss: 0.0090 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9932 0.9980]
Epoch 31/40
TRAIN | loss: 0.0224 - global_acc: 0.9936 - class_acc: [0.9942 0.9944 0.9926 0.9934] 
VALID | loss: 0.0456 - global_acc: 0.9849 - class_acc: [1.0000 1.0000 0.9399 0.9980]
Epoch 32/40
TRAIN | loss: 0.0159 - global_acc: 0.9952 - class_acc: [0.9963 0.9978 0.9930 0.9939] 
VALID | loss: 0.0056 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9979 0.9967]
Epoch 33/40
TRAIN | loss: 0.0191 - global_acc: 0.9953 - class_acc: [0.9957 0.9976 0.9929 0.9948] 
VALID | loss: 0.0105 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 1.0000 0.9874]
Epoch 34/40
TRAIN | loss: 0.0241 - global_acc: 0.9951 - class_acc: [0.9953 0.9982 0.9925 0.9943] 
VALID | loss: 0.0260 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9847 1.0000]
Epoch 35/40
TRAIN | loss: 0.0159 - global_acc: 0.9958 - class_acc: [0.9970 0.9977 0.9938 0.9946] 
VALID | loss: 0.0098 - global_acc: 0.9995 - class_acc: [1.0000 1.0000 0.9979 1.0000] - BEST!
Epoch 36/40
TRAIN | loss: 0.0179 - global_acc: 0.9950 - class_acc: [0.9950 0.9977 0.9923 0.9950] 
VALID | loss: 0.0178 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9964 0.9973]
Epoch 37/40
TRAIN | loss: 0.0128 - global_acc: 0.9961 - class_acc: [0.9964 0.9984 0.9938 0.9956] 
VALID | loss: 0.0085 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9980 0.9930]
Epoch 38/40
TRAIN | loss: 0.0120 - global_acc: 0.9959 - class_acc: [0.9957 0.9984 0.9932 0.9964] 
VALID | loss: 0.0075 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9930 1.0000]
Epoch 39/40
TRAIN | loss: 0.0150 - global_acc: 0.9956 - class_acc: [0.9960 0.9978 0.9920 0.9966] 
VALID | loss: 0.0115 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9914 1.0000]
Epoch 40/40
TRAIN | loss: 0.0163 - global_acc: 0.9957 - class_acc: [0.9968 0.9962 0.9938 0.9960] 
VALID | loss: 0.0119 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9979 0.9959]


Evaluating...
TEST | loss: 0.0383 - global_acc: 0.9944 - class_acc: [1.0000 0.9987 1.0000 0.9869]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 8
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5650 - global_acc: 0.7299 - class_acc: [0.9447 0.8739 0.7664 0.3304] 
VALID | loss: 0.3237 - global_acc: 0.8327 - class_acc: [0.9993 1.0000 0.3109 1.0000] - BEST!
Epoch 2/40
TRAIN | loss: 0.1176 - global_acc: 0.9622 - class_acc: [0.9875 0.9873 0.9055 0.9702] 
VALID | loss: 0.2473 - global_acc: 0.8979 - class_acc: [0.9993 1.0000 0.6003 0.9993] - BEST!
Epoch 3/40
TRAIN | loss: 0.0796 - global_acc: 0.9769 - class_acc: [0.9915 0.9907 0.9420 0.9841] 
VALID | loss: 0.1348 - global_acc: 0.9445 - class_acc: [1.0000 1.0000 0.7653 0.9993] - BEST!
Epoch 4/40
TRAIN | loss: 0.0627 - global_acc: 0.9822 - class_acc: [0.9886 0.9947 0.9587 0.9868] 
VALID | loss: 0.1685 - global_acc: 0.9331 - class_acc: [0.9993 1.0000 0.7342 1.0000]
Epoch 5/40
TRAIN | loss: 0.0537 - global_acc: 0.9850 - class_acc: [0.9917 0.9928 0.9683 0.9874] 
VALID | loss: 0.0428 - global_acc: 0.9828 - class_acc: [1.0000 0.9993 0.9371 0.9966] - BEST!
Epoch 6/40
TRAIN | loss: 0.0482 - global_acc: 0.9855 - class_acc: [0.9913 0.9923 0.9678 0.9903] 
VALID | loss: 0.1314 - global_acc: 0.9511 - class_acc: [0.9986 1.0000 0.8039 0.9993]
Epoch 7/40
TRAIN | loss: 0.0356 - global_acc: 0.9908 - class_acc: [0.9934 0.9957 0.9808 0.9931] 
VALID | loss: 0.0500 - global_acc: 0.9828 - class_acc: [1.0000 1.0000 0.9337 0.9993]
Epoch 8/40
TRAIN | loss: 0.0401 - global_acc: 0.9898 - class_acc: [0.9918 0.9940 0.9802 0.9930] 
VALID | loss: 0.0663 - global_acc: 0.9738 - class_acc: [0.9993 1.0000 0.8999 0.9993]
Epoch 9/40
TRAIN | loss: 0.0316 - global_acc: 0.9921 - class_acc: [0.9957 0.9958 0.9829 0.9938] 
VALID | loss: 0.0462 - global_acc: 0.9826 - class_acc: [1.0000 1.0000 0.9300 1.0000]
Epoch 10/40
TRAIN | loss: 0.0356 - global_acc: 0.9910 - class_acc: [0.9924 0.9944 0.9830 0.9942] 
VALID | loss: 0.0759 - global_acc: 0.9690 - class_acc: [1.0000 0.9993 0.8759 1.0000]
Epoch 11/40
TRAIN | loss: 0.0299 - global_acc: 0.9922 - class_acc: [0.9941 0.9947 0.9869 0.9935] 
VALID | loss: 0.0223 - global_acc: 0.9910 - class_acc: [1.0000 1.0000 0.9646 1.0000] - BEST!
Epoch 12/40
TRAIN | loss: 0.0309 - global_acc: 0.9921 - class_acc: [0.9925 0.9945 0.9864 0.9948] 
VALID | loss: 0.0825 - global_acc: 0.9678 - class_acc: [1.0000 1.0000 0.8743 1.0000]
Epoch 13/40
TRAIN | loss: 0.0222 - global_acc: 0.9930 - class_acc: [0.9964 0.9968 0.9848 0.9937] 
VALID | loss: 0.0622 - global_acc: 0.9762 - class_acc: [1.0000 1.0000 0.9033 1.0000]
Epoch 14/40
TRAIN | loss: 0.0198 - global_acc: 0.9948 - class_acc: [0.9956 0.9953 0.9919 0.9966] 
VALID | loss: 0.0551 - global_acc: 0.9787 - class_acc: [0.9993 1.0000 0.9174 1.0000]
Epoch 15/40
TRAIN | loss: 0.0252 - global_acc: 0.9936 - class_acc: [0.9943 0.9953 0.9895 0.9953] 
VALID | loss: 0.0280 - global_acc: 0.9911 - class_acc: [1.0000 1.0000 0.9654 0.9993] - BEST!
Epoch 16/40
TRAIN | loss: 0.0249 - global_acc: 0.9939 - class_acc: [0.9956 0.9953 0.9900 0.9946] 
VALID | loss: 0.1372 - global_acc: 0.9479 - class_acc: [1.0000 1.0000 0.7932 1.0000]
Epoch 17/40
TRAIN | loss: 0.0189 - global_acc: 0.9943 - class_acc: [0.9956 0.9942 0.9915 0.9960] 
VALID | loss: 0.0285 - global_acc: 0.9900 - class_acc: [0.9993 1.0000 0.9611 0.9993]
Epoch 18/40
TRAIN | loss: 0.0249 - global_acc: 0.9939 - class_acc: [0.9940 0.9946 0.9899 0.9970] 
VALID | loss: 0.0194 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9722 1.0000] - BEST!
Epoch 19/40
TRAIN | loss: 0.0228 - global_acc: 0.9935 - class_acc: [0.9929 0.9950 0.9905 0.9955] 
VALID | loss: 0.0435 - global_acc: 0.9857 - class_acc: [1.0000 1.0000 0.9426 1.0000]
Epoch 20/40
TRAIN | loss: 0.0161 - global_acc: 0.9957 - class_acc: [0.9950 0.9963 0.9943 0.9973] 
VALID | loss: 0.0317 - global_acc: 0.9879 - class_acc: [1.0000 1.0000 0.9525 0.9993]
Epoch 21/40
TRAIN | loss: 0.0175 - global_acc: 0.9952 - class_acc: [0.9961 0.9976 0.9908 0.9963] 
VALID | loss: 0.0137 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9834 0.9993] - BEST!
Epoch 22/40
TRAIN | loss: 0.0183 - global_acc: 0.9949 - class_acc: [0.9962 0.9963 0.9917 0.9955] 
VALID | loss: 0.0291 - global_acc: 0.9911 - class_acc: [1.0000 1.0000 0.9629 1.0000]
Epoch 23/40
TRAIN | loss: 0.0150 - global_acc: 0.9971 - class_acc: [0.9962 0.9966 0.9973 0.9981] 
VALID | loss: 0.0261 - global_acc: 0.9903 - class_acc: [1.0000 1.0000 0.9606 0.9993]
Epoch 24/40
TRAIN | loss: 0.0193 - global_acc: 0.9955 - class_acc: [0.9947 0.9973 0.9942 0.9957] 
VALID | loss: 0.0270 - global_acc: 0.9915 - class_acc: [1.0000 1.0000 0.9671 0.9993]
Epoch 25/40
TRAIN | loss: 0.0190 - global_acc: 0.9955 - class_acc: [0.9955 0.9962 0.9937 0.9965] 
VALID | loss: 0.1146 - global_acc: 0.9590 - class_acc: [1.0000 1.0000 0.8394 1.0000]
Epoch 26/40
TRAIN | loss: 0.0160 - global_acc: 0.9961 - class_acc: [0.9954 0.9978 0.9943 0.9970] 
VALID | loss: 0.0475 - global_acc: 0.9828 - class_acc: [1.0000 1.0000 0.9316 1.0000]
Epoch 27/40
TRAIN | loss: 0.0149 - global_acc: 0.9965 - class_acc: [0.9962 0.9986 0.9939 0.9972] 
VALID | loss: 0.0230 - global_acc: 0.9922 - class_acc: [1.0000 1.0000 0.9682 1.0000]
Epoch 28/40
TRAIN | loss: 0.0160 - global_acc: 0.9966 - class_acc: [0.9964 0.9975 0.9948 0.9977] 
VALID | loss: 0.0493 - global_acc: 0.9847 - class_acc: [1.0000 1.0000 0.9393 1.0000]
Epoch 29/40
TRAIN | loss: 0.0138 - global_acc: 0.9963 - class_acc: [0.9962 0.9961 0.9952 0.9975] 
VALID | loss: 0.0306 - global_acc: 0.9908 - class_acc: [1.0000 1.0000 0.9635 1.0000]
Epoch 30/40
TRAIN | loss: 0.0156 - global_acc: 0.9964 - class_acc: [0.9959 0.9973 0.9952 0.9970] 
VALID | loss: 0.0171 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9796 1.0000]
Epoch 31/40
TRAIN | loss: 0.0139 - global_acc: 0.9971 - class_acc: [0.9975 0.9986 0.9940 0.9980] 
VALID | loss: 0.0174 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9801 0.9993]
Epoch 32/40
TRAIN | loss: 0.0140 - global_acc: 0.9969 - class_acc: [0.9968 0.9980 0.9953 0.9975] 
VALID | loss: 0.0959 - global_acc: 0.9687 - class_acc: [1.0000 1.0000 0.8725 1.0000]
Epoch 33/40
TRAIN | loss: 0.0196 - global_acc: 0.9963 - class_acc: [0.9954 0.9966 0.9964 0.9968] 
VALID | loss: 0.2740 - global_acc: 0.9547 - class_acc: [1.0000 1.0000 0.9597 0.8601]
Epoch 34/40
TRAIN | loss: 0.0129 - global_acc: 0.9965 - class_acc: [0.9961 0.9960 0.9969 0.9970] 
VALID | loss: 0.0778 - global_acc: 0.9763 - class_acc: [1.0000 1.0000 0.9049 1.0000]
Epoch 35/40
TRAIN | loss: 0.0140 - global_acc: 0.9963 - class_acc: [0.9943 0.9969 0.9966 0.9975] 
VALID | loss: 0.0158 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9811 0.9993]
Epoch 36/40
TRAIN | loss: 0.0106 - global_acc: 0.9974 - class_acc: [0.9977 0.9980 0.9965 0.9976] 
VALID | loss: 0.0259 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9748 1.0000]
Epoch 37/40
TRAIN | loss: 0.0122 - global_acc: 0.9971 - class_acc: [0.9975 0.9982 0.9952 0.9973] 
VALID | loss: 0.0257 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9736 1.0000]
Epoch 38/40
TRAIN | loss: 0.0182 - global_acc: 0.9952 - class_acc: [0.9955 0.9970 0.9932 0.9952] 
VALID | loss: 0.0226 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9862 1.0000] - BEST!
Epoch 39/40
TRAIN | loss: 0.0122 - global_acc: 0.9968 - class_acc: [0.9978 0.9975 0.9962 0.9958] 
VALID | loss: 0.0072 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9973 0.9955] - BEST!
Epoch 40/40
TRAIN | loss: 0.0091 - global_acc: 0.9974 - class_acc: [0.9973 0.9980 0.9966 0.9977] 
VALID | loss: 0.0049 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9960 0.9993] - BEST!


Evaluating...
TEST | loss: 5.5445 - global_acc: 0.7145 - class_acc: [0.0000 1.0000 0.9990 0.2935]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 9
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5195 - global_acc: 0.7590 - class_acc: [0.8679 0.9794 0.4337 0.7552] 
VALID | loss: 0.1549 - global_acc: 0.9357 - class_acc: [0.9980 1.0000 0.9720 0.7675] - BEST!
Epoch 2/40
TRAIN | loss: 0.1087 - global_acc: 0.9673 - class_acc: [0.9856 0.9807 0.9628 0.9405] 
VALID | loss: 0.0580 - global_acc: 0.9779 - class_acc: [0.9987 1.0000 0.9841 0.9244] - BEST!
Epoch 3/40
TRAIN | loss: 0.0744 - global_acc: 0.9780 - class_acc: [0.9896 0.9823 0.9779 0.9619] 
VALID | loss: 0.1019 - global_acc: 0.9602 - class_acc: [1.0000 1.0000 0.9952 0.8440]
Epoch 4/40
TRAIN | loss: 0.0544 - global_acc: 0.9844 - class_acc: [0.9915 0.9831 0.9877 0.9750] 
VALID | loss: 0.0413 - global_acc: 0.9864 - class_acc: [1.0000 1.0000 0.9959 0.9497] - BEST!
Epoch 5/40
TRAIN | loss: 0.0603 - global_acc: 0.9808 - class_acc: [0.9895 0.9804 0.9831 0.9703] 
VALID | loss: 0.0331 - global_acc: 0.9888 - class_acc: [0.9993 1.0000 0.9870 0.9677] - BEST!
Epoch 6/40
TRAIN | loss: 0.0520 - global_acc: 0.9845 - class_acc: [0.9893 0.9832 0.9864 0.9792] 
VALID | loss: 0.0352 - global_acc: 0.9894 - class_acc: [1.0000 1.0000 0.9925 0.9638] - BEST!
Epoch 7/40
TRAIN | loss: 0.0405 - global_acc: 0.9888 - class_acc: [0.9943 0.9874 0.9906 0.9829] 
VALID | loss: 0.0235 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9980 0.9748] - BEST!
Epoch 8/40
TRAIN | loss: 0.0425 - global_acc: 0.9878 - class_acc: [0.9897 0.9867 0.9911 0.9837] 
VALID | loss: 0.0295 - global_acc: 0.9917 - class_acc: [1.0000 1.0000 0.9881 0.9779]
Epoch 9/40
TRAIN | loss: 0.0377 - global_acc: 0.9891 - class_acc: [0.9954 0.9906 0.9890 0.9814] 
VALID | loss: 0.0205 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9902 0.9892] - BEST!
Epoch 10/40
TRAIN | loss: 0.0355 - global_acc: 0.9904 - class_acc: [0.9928 0.9888 0.9927 0.9870] 
VALID | loss: 0.0246 - global_acc: 0.9925 - class_acc: [0.9993 1.0000 0.9926 0.9782]
Epoch 11/40
TRAIN | loss: 0.0329 - global_acc: 0.9912 - class_acc: [0.9905 0.9914 0.9957 0.9869] 
VALID | loss: 0.0152 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9953 0.9817]
Epoch 12/40
TRAIN | loss: 0.0355 - global_acc: 0.9901 - class_acc: [0.9914 0.9915 0.9918 0.9860] 
VALID | loss: 0.0260 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9993 0.9725]
Epoch 13/40
TRAIN | loss: 0.0274 - global_acc: 0.9927 - class_acc: [0.9921 0.9949 0.9968 0.9871] 
VALID | loss: 0.0172 - global_acc: 0.9951 - class_acc: [0.9993 1.0000 0.9986 0.9823] - BEST!
Epoch 14/40
TRAIN | loss: 0.0281 - global_acc: 0.9919 - class_acc: [0.9908 0.9948 0.9950 0.9870] 
VALID | loss: 0.0149 - global_acc: 0.9957 - class_acc: [1.0000 0.9993 0.9958 0.9878] - BEST!
Epoch 15/40
TRAIN | loss: 0.0252 - global_acc: 0.9923 - class_acc: [0.9928 0.9939 0.9953 0.9875] 
VALID | loss: 0.0159 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 1.0000 0.9831]
Epoch 16/40
TRAIN | loss: 0.0324 - global_acc: 0.9905 - class_acc: [0.9914 0.9950 0.9925 0.9830] 
VALID | loss: 0.0326 - global_acc: 0.9910 - class_acc: [0.9986 1.0000 1.0000 0.9648]
Epoch 17/40
TRAIN | loss: 0.0212 - global_acc: 0.9937 - class_acc: [0.9947 0.9932 0.9968 0.9901] 
VALID | loss: 0.0323 - global_acc: 0.9905 - class_acc: [1.0000 1.0000 1.0000 0.9624]
Epoch 18/40
TRAIN | loss: 0.0300 - global_acc: 0.9913 - class_acc: [0.9934 0.9935 0.9934 0.9848] 
VALID | loss: 0.0349 - global_acc: 0.9884 - class_acc: [1.0000 1.0000 0.9993 0.9536]
Epoch 19/40
TRAIN | loss: 0.0289 - global_acc: 0.9915 - class_acc: [0.9921 0.9932 0.9933 0.9873] 
VALID | loss: 0.0104 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 1.0000 0.9904] - BEST!
Epoch 20/40
TRAIN | loss: 0.0290 - global_acc: 0.9921 - class_acc: [0.9912 0.9948 0.9951 0.9873] 
VALID | loss: 0.0301 - global_acc: 0.9918 - class_acc: [1.0000 1.0000 0.9994 0.9676]
Epoch 21/40
TRAIN | loss: 0.0236 - global_acc: 0.9925 - class_acc: [0.9922 0.9943 0.9941 0.9894] 
VALID | loss: 0.0201 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 1.0000 0.9717]
Epoch 22/40
TRAIN | loss: 0.0236 - global_acc: 0.9927 - class_acc: [0.9924 0.9954 0.9943 0.9887] 
VALID | loss: 0.0085 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9993 0.9897]
Epoch 23/40
TRAIN | loss: 0.0240 - global_acc: 0.9925 - class_acc: [0.9935 0.9944 0.9947 0.9873] 
VALID | loss: 0.0077 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9994 0.9917] - BEST!
Epoch 24/40
TRAIN | loss: 0.0238 - global_acc: 0.9925 - class_acc: [0.9936 0.9939 0.9933 0.9891] 
VALID | loss: 0.0260 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9993 0.9735]
Epoch 25/40
TRAIN | loss: 0.0207 - global_acc: 0.9934 - class_acc: [0.9945 0.9950 0.9939 0.9900] 
VALID | loss: 0.0134 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9993 0.9863]
Epoch 26/40
TRAIN | loss: 0.0200 - global_acc: 0.9935 - class_acc: [0.9939 0.9956 0.9957 0.9889] 
VALID | loss: 0.0184 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9993 0.9896]
Epoch 27/40
TRAIN | loss: 0.0232 - global_acc: 0.9926 - class_acc: [0.9955 0.9925 0.9931 0.9891] 
VALID | loss: 0.0228 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9979 0.9776]
Epoch 28/40
TRAIN | loss: 0.0179 - global_acc: 0.9947 - class_acc: [0.9982 0.9952 0.9948 0.9906] 
VALID | loss: 0.0581 - global_acc: 0.9830 - class_acc: [1.0000 1.0000 1.0000 0.9329]
Epoch 29/40
TRAIN | loss: 0.0156 - global_acc: 0.9944 - class_acc: [0.9973 0.9950 0.9945 0.9911] 
VALID | loss: 0.0107 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9973 0.9879]
Epoch 30/40
TRAIN | loss: 0.0158 - global_acc: 0.9947 - class_acc: [0.9943 0.9946 0.9959 0.9939] 
VALID | loss: 0.0058 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9980 0.9946] - BEST!
Epoch 31/40
TRAIN | loss: 0.0173 - global_acc: 0.9946 - class_acc: [0.9955 0.9967 0.9957 0.9903] 
VALID | loss: 0.0236 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9986 0.9776]
Epoch 32/40
TRAIN | loss: 0.0206 - global_acc: 0.9935 - class_acc: [0.9941 0.9961 0.9939 0.9901] 
VALID | loss: 0.0106 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9993 0.9904]
Epoch 33/40
TRAIN | loss: 0.0183 - global_acc: 0.9938 - class_acc: [0.9956 0.9959 0.9921 0.9914] 
VALID | loss: 0.0453 - global_acc: 0.9879 - class_acc: [1.0000 0.9993 1.0000 0.9516]
Epoch 34/40
TRAIN | loss: 0.0189 - global_acc: 0.9935 - class_acc: [0.9941 0.9943 0.9943 0.9915] 
VALID | loss: 0.0070 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9961 0.9957]
Epoch 35/40
TRAIN | loss: 0.0165 - global_acc: 0.9948 - class_acc: [0.9943 0.9973 0.9946 0.9932] 
VALID | loss: 0.0107 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 1.0000 0.9905]
Epoch 36/40
TRAIN | loss: 0.0143 - global_acc: 0.9948 - class_acc: [0.9970 0.9960 0.9938 0.9926] 
VALID | loss: 0.0221 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9986 0.9825]
Epoch 37/40
TRAIN | loss: 0.0171 - global_acc: 0.9944 - class_acc: [0.9963 0.9957 0.9931 0.9927] 
VALID | loss: 0.0287 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 1.0000 0.9709]
Epoch 38/40
TRAIN | loss: 0.0148 - global_acc: 0.9944 - class_acc: [0.9952 0.9973 0.9932 0.9920] 
VALID | loss: 0.0063 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9972 0.9952]
Epoch 39/40
TRAIN | loss: 0.0150 - global_acc: 0.9945 - class_acc: [0.9942 0.9964 0.9945 0.9928] 
VALID | loss: 0.0102 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 1.0000 0.9898]
Epoch 40/40
TRAIN | loss: 0.0172 - global_acc: 0.9949 - class_acc: [0.9956 0.9953 0.9945 0.9941] 
VALID | loss: 0.0061 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9993 0.9945] - BEST!


Evaluating...
TEST | loss: 0.1556 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9990 0.9836]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 10
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5483 - global_acc: 0.7690 - class_acc: [0.7824 0.8696 0.6916 0.7354] 
VALID | loss: 0.1084 - global_acc: 0.9549 - class_acc: [0.9987 1.0000 0.9679 0.8554] - BEST!
Epoch 2/40
TRAIN | loss: 0.1231 - global_acc: 0.9596 - class_acc: [0.9973 0.9689 0.9261 0.9458] 
VALID | loss: 0.0598 - global_acc: 0.9782 - class_acc: [0.9993 0.9993 0.9357 0.9772] - BEST!
Epoch 3/40
TRAIN | loss: 0.0809 - global_acc: 0.9742 - class_acc: [0.9982 0.9834 0.9546 0.9604] 
VALID | loss: 0.0517 - global_acc: 0.9794 - class_acc: [1.0000 1.0000 0.9294 0.9868] - BEST!
Epoch 4/40
TRAIN | loss: 0.0717 - global_acc: 0.9763 - class_acc: [0.9980 0.9815 0.9614 0.9642] 
VALID | loss: 0.0321 - global_acc: 0.9894 - class_acc: [1.0000 1.0000 0.9707 0.9879] - BEST!
Epoch 5/40
TRAIN | loss: 0.0546 - global_acc: 0.9817 - class_acc: [0.9984 0.9852 0.9709 0.9721] 
VALID | loss: 0.0416 - global_acc: 0.9859 - class_acc: [0.9987 0.9986 0.9940 0.9514]
Epoch 6/40
TRAIN | loss: 0.0491 - global_acc: 0.9830 - class_acc: [0.9989 0.9881 0.9742 0.9708] 
VALID | loss: 0.0264 - global_acc: 0.9910 - class_acc: [1.0000 0.9993 0.9892 0.9760] - BEST!
Epoch 7/40
TRAIN | loss: 0.0458 - global_acc: 0.9858 - class_acc: [0.9991 0.9884 0.9772 0.9790] 
VALID | loss: 0.0282 - global_acc: 0.9906 - class_acc: [1.0000 1.0000 0.9713 0.9912]
Epoch 8/40
TRAIN | loss: 0.0397 - global_acc: 0.9891 - class_acc: [0.9998 0.9914 0.9833 0.9816] 
VALID | loss: 0.0150 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9873 0.9939] - BEST!
Epoch 9/40
TRAIN | loss: 0.0425 - global_acc: 0.9873 - class_acc: [1.0000 0.9906 0.9787 0.9798] 
VALID | loss: 0.0132 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9925 0.9871]
Epoch 10/40
TRAIN | loss: 0.0395 - global_acc: 0.9879 - class_acc: [0.9991 0.9918 0.9825 0.9783] 
VALID | loss: 0.0249 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9746 0.9980]
Epoch 11/40
TRAIN | loss: 0.0310 - global_acc: 0.9896 - class_acc: [1.0000 0.9927 0.9821 0.9839] 
VALID | loss: 0.0142 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9965 0.9853] - BEST!
Epoch 12/40
TRAIN | loss: 0.0368 - global_acc: 0.9891 - class_acc: [0.9977 0.9924 0.9821 0.9844] 
VALID | loss: 0.0199 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9827 0.9892]
Epoch 13/40
TRAIN | loss: 0.0358 - global_acc: 0.9901 - class_acc: [0.9996 0.9921 0.9803 0.9884] 
VALID | loss: 0.0125 - global_acc: 0.9961 - class_acc: [0.9993 1.0000 0.9954 0.9896] - BEST!
Epoch 14/40
TRAIN | loss: 0.0435 - global_acc: 0.9889 - class_acc: [0.9987 0.9946 0.9793 0.9829] 
VALID | loss: 0.0296 - global_acc: 0.9896 - class_acc: [1.0000 1.0000 0.9600 0.9986]
Epoch 15/40
TRAIN | loss: 0.0355 - global_acc: 0.9912 - class_acc: [0.9991 0.9943 0.9820 0.9889] 
VALID | loss: 0.0151 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9951 0.9973] - BEST!
Epoch 16/40
TRAIN | loss: 0.0259 - global_acc: 0.9921 - class_acc: [1.0000 0.9942 0.9863 0.9880] 
VALID | loss: 0.0107 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9939 0.9936]
Epoch 17/40
TRAIN | loss: 0.0201 - global_acc: 0.9943 - class_acc: [1.0000 0.9964 0.9895 0.9912] 
VALID | loss: 0.0099 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9883 0.9993]
Epoch 18/40
TRAIN | loss: 0.0271 - global_acc: 0.9922 - class_acc: [0.9998 0.9945 0.9861 0.9881] 
VALID | loss: 0.0166 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9815 0.9993]
Epoch 19/40
TRAIN | loss: 0.0210 - global_acc: 0.9947 - class_acc: [1.0000 0.9959 0.9909 0.9921] 
VALID | loss: 0.0084 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9965 0.9934]
Epoch 20/40
TRAIN | loss: 0.0283 - global_acc: 0.9913 - class_acc: [0.9984 0.9951 0.9849 0.9869] 
VALID | loss: 0.0174 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9940 0.9886]
Epoch 21/40
TRAIN | loss: 0.0282 - global_acc: 0.9927 - class_acc: [0.9998 0.9940 0.9863 0.9907] 
VALID | loss: 0.0109 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9959 0.9927]
Epoch 22/40
TRAIN | loss: 0.0234 - global_acc: 0.9931 - class_acc: [1.0000 0.9959 0.9879 0.9883] 
VALID | loss: 0.0174 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9799 0.9993]
Epoch 23/40
TRAIN | loss: 0.0180 - global_acc: 0.9951 - class_acc: [0.9998 0.9963 0.9916 0.9924] 
VALID | loss: 0.0182 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9817 1.0000]
Epoch 24/40
TRAIN | loss: 0.0151 - global_acc: 0.9964 - class_acc: [1.0000 0.9975 0.9927 0.9952] 
VALID | loss: 0.0106 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9939 0.9966]
Epoch 25/40
TRAIN | loss: 0.0192 - global_acc: 0.9946 - class_acc: [0.9998 0.9957 0.9896 0.9930] 
VALID | loss: 0.0102 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9926 0.9966]
Epoch 26/40
TRAIN | loss: 0.0213 - global_acc: 0.9940 - class_acc: [1.0000 0.9961 0.9883 0.9918] 
VALID | loss: 0.0138 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9919 0.9986]
Epoch 27/40
TRAIN | loss: 0.0158 - global_acc: 0.9957 - class_acc: [0.9998 0.9968 0.9913 0.9949] 
VALID | loss: 0.0105 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9909 0.9973]
Epoch 28/40
TRAIN | loss: 0.0219 - global_acc: 0.9943 - class_acc: [0.9998 0.9961 0.9897 0.9920] 
VALID | loss: 0.0234 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9822 1.0000]
Epoch 29/40
TRAIN | loss: 0.0177 - global_acc: 0.9955 - class_acc: [0.9998 0.9969 0.9914 0.9941] 
VALID | loss: 0.0108 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9950 0.9967]
Epoch 30/40
TRAIN | loss: 0.0161 - global_acc: 0.9954 - class_acc: [0.9996 0.9960 0.9933 0.9927] 
VALID | loss: 0.0120 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9931 0.9973]
Epoch 31/40
TRAIN | loss: 0.0165 - global_acc: 0.9950 - class_acc: [1.0000 0.9967 0.9897 0.9936] 
VALID | loss: 0.0041 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9993 0.9973] - BEST!
Epoch 32/40
TRAIN | loss: 0.0172 - global_acc: 0.9957 - class_acc: [0.9998 0.9975 0.9923 0.9934] 
VALID | loss: 0.0197 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9841 1.0000]
Epoch 33/40
TRAIN | loss: 0.0197 - global_acc: 0.9957 - class_acc: [0.9998 0.9968 0.9917 0.9946] 
VALID | loss: 0.0045 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9980 0.9993] - BEST!
Epoch 34/40
TRAIN | loss: 0.0146 - global_acc: 0.9964 - class_acc: [1.0000 0.9973 0.9926 0.9955] 
VALID | loss: 0.0085 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9979 0.9933]
Epoch 35/40
TRAIN | loss: 0.0133 - global_acc: 0.9967 - class_acc: [1.0000 0.9989 0.9926 0.9954] 
VALID | loss: 0.0061 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9993 0.9979]
Epoch 36/40
TRAIN | loss: 0.0137 - global_acc: 0.9971 - class_acc: [0.9998 0.9975 0.9945 0.9964] 
VALID | loss: 0.0169 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9843 0.9993]
Epoch 37/40
TRAIN | loss: 0.0165 - global_acc: 0.9965 - class_acc: [1.0000 0.9966 0.9951 0.9945] 
VALID | loss: 0.0147 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9879 0.9993]
Epoch 38/40
TRAIN | loss: 0.0137 - global_acc: 0.9969 - class_acc: [1.0000 0.9982 0.9928 0.9966] 
VALID | loss: 0.0085 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9959 0.9993]
Epoch 39/40
TRAIN | loss: 0.0186 - global_acc: 0.9959 - class_acc: [1.0000 0.9982 0.9917 0.9935] 
VALID | loss: 0.0344 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9788 0.9993]
Epoch 40/40
TRAIN | loss: 0.0160 - global_acc: 0.9963 - class_acc: [0.9998 0.9967 0.9937 0.9948] 
VALID | loss: 0.0085 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9961 0.9960]


Evaluating...
TEST | loss: 0.1963 - global_acc: 0.9811 - class_acc: [0.0000 1.0000 0.9938 0.9591]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 11
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5333 - global_acc: 0.7826 - class_acc: [0.7934 0.7734 0.8850 0.6731] 
VALID | loss: 0.2127 - global_acc: 0.9200 - class_acc: [1.0000 1.0000 0.6858 0.9966] - BEST!
Epoch 2/40
TRAIN | loss: 0.1251 - global_acc: 0.9581 - class_acc: [0.9986 0.9685 0.9255 0.9398] 
VALID | loss: 0.0692 - global_acc: 0.9777 - class_acc: [1.0000 1.0000 0.9540 0.9564] - BEST!
Epoch 3/40
TRAIN | loss: 0.0977 - global_acc: 0.9694 - class_acc: [0.9995 0.9748 0.9488 0.9536] 
VALID | loss: 0.0680 - global_acc: 0.9753 - class_acc: [1.0000 1.0000 0.9123 0.9893]
Epoch 4/40
TRAIN | loss: 0.0793 - global_acc: 0.9753 - class_acc: [0.9987 0.9803 0.9586 0.9629] 
VALID | loss: 0.0623 - global_acc: 0.9763 - class_acc: [1.0000 1.0000 0.9151 0.9906]
Epoch 5/40
TRAIN | loss: 0.0733 - global_acc: 0.9771 - class_acc: [0.9993 0.9794 0.9606 0.9690] 
VALID | loss: 0.0358 - global_acc: 0.9891 - class_acc: [1.0000 0.9993 0.9686 0.9884] - BEST!
Epoch 6/40
TRAIN | loss: 0.0660 - global_acc: 0.9794 - class_acc: [0.9991 0.9809 0.9666 0.9716] 
VALID | loss: 0.0568 - global_acc: 0.9787 - class_acc: [1.0000 1.0000 0.9201 0.9932]
Epoch 7/40
TRAIN | loss: 0.0611 - global_acc: 0.9823 - class_acc: [0.9991 0.9836 0.9672 0.9790] 
VALID | loss: 0.0478 - global_acc: 0.9843 - class_acc: [1.0000 0.9986 0.9508 0.9878]
Epoch 8/40
TRAIN | loss: 0.0618 - global_acc: 0.9830 - class_acc: [0.9995 0.9844 0.9720 0.9763] 
VALID | loss: 0.2597 - global_acc: 0.9178 - class_acc: [0.9993 1.0000 0.6761 0.9993]
Epoch 9/40
TRAIN | loss: 0.0538 - global_acc: 0.9847 - class_acc: [0.9996 0.9860 0.9705 0.9822] 
VALID | loss: 0.0298 - global_acc: 0.9915 - class_acc: [1.0000 1.0000 0.9727 0.9930] - BEST!
Epoch 10/40
TRAIN | loss: 0.0510 - global_acc: 0.9862 - class_acc: [0.9998 0.9886 0.9732 0.9833] 
VALID | loss: 0.0325 - global_acc: 0.9935 - class_acc: [1.0000 1.0000 0.9889 0.9855] - BEST!
Epoch 11/40
TRAIN | loss: 0.0503 - global_acc: 0.9858 - class_acc: [0.9993 0.9869 0.9743 0.9828] 
VALID | loss: 0.0267 - global_acc: 0.9910 - class_acc: [1.0000 0.9993 0.9753 0.9891]
Epoch 12/40
TRAIN | loss: 0.0536 - global_acc: 0.9853 - class_acc: [0.9993 0.9884 0.9698 0.9840] 
VALID | loss: 0.0192 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9945 0.9921] - BEST!
Epoch 13/40
TRAIN | loss: 0.0492 - global_acc: 0.9867 - class_acc: [0.9995 0.9883 0.9735 0.9857] 
VALID | loss: 0.0130 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9993 0.9910] - BEST!
Epoch 14/40
TRAIN | loss: 0.0382 - global_acc: 0.9892 - class_acc: [0.9998 0.9922 0.9773 0.9869] 
VALID | loss: 0.0102 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9938 0.9952]
Epoch 15/40
TRAIN | loss: 0.0362 - global_acc: 0.9897 - class_acc: [0.9998 0.9907 0.9818 0.9863] 
VALID | loss: 0.0177 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9870 0.9916]
Epoch 16/40
TRAIN | loss: 0.0415 - global_acc: 0.9894 - class_acc: [1.0000 0.9907 0.9794 0.9873] 
VALID | loss: 0.0188 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9954 0.9930]
Epoch 17/40
TRAIN | loss: 0.0378 - global_acc: 0.9909 - class_acc: [1.0000 0.9925 0.9833 0.9877] 
VALID | loss: 0.0349 - global_acc: 0.9872 - class_acc: [1.0000 1.0000 0.9494 1.0000]
Epoch 18/40
TRAIN | loss: 0.0323 - global_acc: 0.9922 - class_acc: [1.0000 0.9933 0.9853 0.9902] 
VALID | loss: 0.0099 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9952 0.9979] - BEST!
Epoch 19/40
TRAIN | loss: 0.0345 - global_acc: 0.9915 - class_acc: [1.0000 0.9926 0.9870 0.9866] 
VALID | loss: 0.0124 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9913 0.9993]
Epoch 20/40
TRAIN | loss: 0.0359 - global_acc: 0.9917 - class_acc: [0.9995 0.9943 0.9859 0.9871] 
VALID | loss: 0.0111 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9953 0.9973]
Epoch 21/40
TRAIN | loss: 0.0314 - global_acc: 0.9925 - class_acc: [0.9998 0.9942 0.9890 0.9871] 
VALID | loss: 0.0098 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9948 0.9966]
Epoch 22/40
TRAIN | loss: 0.0311 - global_acc: 0.9925 - class_acc: [0.9993 0.9951 0.9894 0.9865] 
VALID | loss: 0.0341 - global_acc: 0.9884 - class_acc: [1.0000 1.0000 0.9541 1.0000]
Epoch 23/40
TRAIN | loss: 0.0246 - global_acc: 0.9938 - class_acc: [0.9995 0.9969 0.9916 0.9871] 
VALID | loss: 0.0072 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9980 0.9960] - BEST!
Epoch 24/40
TRAIN | loss: 0.0418 - global_acc: 0.9894 - class_acc: [0.9991 0.9920 0.9838 0.9829] 
VALID | loss: 0.0325 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9947 0.9772]
Epoch 25/40
TRAIN | loss: 0.0328 - global_acc: 0.9922 - class_acc: [0.9995 0.9950 0.9884 0.9860] 
VALID | loss: 0.0277 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9862 0.9972]
Epoch 26/40
TRAIN | loss: 0.0301 - global_acc: 0.9931 - class_acc: [1.0000 0.9917 0.9912 0.9893] 
VALID | loss: 0.0301 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9728 1.0000]
Epoch 27/40
TRAIN | loss: 0.0233 - global_acc: 0.9939 - class_acc: [1.0000 0.9954 0.9902 0.9902] 
VALID | loss: 0.0151 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9864 0.9993]
Epoch 28/40
TRAIN | loss: 0.0313 - global_acc: 0.9936 - class_acc: [1.0000 0.9946 0.9919 0.9879] 
VALID | loss: 0.0092 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9973 0.9952]
Epoch 29/40
TRAIN | loss: 0.0236 - global_acc: 0.9942 - class_acc: [1.0000 0.9947 0.9924 0.9898] 
VALID | loss: 0.0171 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9979 0.9972] - BEST!
Epoch 30/40
TRAIN | loss: 0.0231 - global_acc: 0.9950 - class_acc: [0.9998 0.9962 0.9939 0.9900] 
VALID | loss: 0.0128 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9968 0.9986]
Epoch 31/40
TRAIN | loss: 0.0231 - global_acc: 0.9941 - class_acc: [1.0000 0.9940 0.9936 0.9889] 
VALID | loss: 0.0082 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9953 0.9993]
Epoch 32/40
TRAIN | loss: 0.0270 - global_acc: 0.9931 - class_acc: [0.9991 0.9939 0.9912 0.9883] 
VALID | loss: 0.0118 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9986 0.9923]
Epoch 33/40
TRAIN | loss: 0.0234 - global_acc: 0.9944 - class_acc: [0.9993 0.9959 0.9929 0.9897] 
VALID | loss: 0.0083 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9979 0.9966]
Epoch 34/40
TRAIN | loss: 0.0309 - global_acc: 0.9933 - class_acc: [0.9989 0.9924 0.9921 0.9899] 
VALID | loss: 0.0136 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9986 0.9951]
Epoch 35/40
TRAIN | loss: 0.0246 - global_acc: 0.9940 - class_acc: [0.9998 0.9943 0.9939 0.9882] 
VALID | loss: 0.0121 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9972 0.9972]
Epoch 36/40
TRAIN | loss: 0.0252 - global_acc: 0.9937 - class_acc: [0.9991 0.9957 0.9930 0.9869] 
VALID | loss: 0.0191 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9958 0.9980]
Epoch 37/40
TRAIN | loss: 0.0169 - global_acc: 0.9955 - class_acc: [0.9998 0.9952 0.9955 0.9915] 
VALID | loss: 0.0075 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9993 0.9947]
Epoch 38/40
TRAIN | loss: 0.0165 - global_acc: 0.9954 - class_acc: [0.9996 0.9949 0.9932 0.9939] 
VALID | loss: 0.0194 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9987 0.9832]
Epoch 39/40
TRAIN | loss: 0.0217 - global_acc: 0.9938 - class_acc: [0.9982 0.9956 0.9927 0.9885] 
VALID | loss: 0.0063 - global_acc: 0.9995 - class_acc: [1.0000 1.0000 0.9986 0.9993] - BEST!
Epoch 40/40
TRAIN | loss: 0.0200 - global_acc: 0.9940 - class_acc: [0.9982 0.9950 0.9930 0.9896] 
VALID | loss: 0.0076 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9973 0.9979]


Evaluating...
TEST | loss: 0.1658 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9985 0.9865]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 12
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5145 - global_acc: 0.8019 - class_acc: [0.9554 0.6814 0.7874 0.7821] 
VALID | loss: 0.1408 - global_acc: 0.9517 - class_acc: [1.0000 0.9993 0.9125 0.8947] - BEST!
Epoch 2/40
TRAIN | loss: 0.1458 - global_acc: 0.9453 - class_acc: [0.9328 0.9964 0.9207 0.9310] 
VALID | loss: 0.0854 - global_acc: 0.9661 - class_acc: [1.0000 1.0000 0.9874 0.8802] - BEST!
Epoch 3/40
TRAIN | loss: 0.0987 - global_acc: 0.9581 - class_acc: [0.9401 0.9954 0.9475 0.9501] 
VALID | loss: 0.0894 - global_acc: 0.9670 - class_acc: [1.0000 1.0000 0.8853 0.9895] - BEST!
Epoch 4/40
TRAIN | loss: 0.0956 - global_acc: 0.9576 - class_acc: [0.9494 0.9769 0.9477 0.9561] 
VALID | loss: 0.0547 - global_acc: 0.9808 - class_acc: [1.0000 0.9993 0.9343 0.9895] - BEST!
Epoch 5/40
TRAIN | loss: 0.0875 - global_acc: 0.9628 - class_acc: [0.9528 0.9799 0.9565 0.9621] 
VALID | loss: 0.0373 - global_acc: 0.9903 - class_acc: [1.0000 1.0000 0.9671 0.9946] - BEST!
Epoch 6/40
TRAIN | loss: 0.0841 - global_acc: 0.9625 - class_acc: [0.9639 0.9665 0.9577 0.9617] 
VALID | loss: 0.0308 - global_acc: 0.9915 - class_acc: [1.0000 1.0000 0.9739 0.9918] - BEST!
Epoch 7/40
TRAIN | loss: 0.0737 - global_acc: 0.9686 - class_acc: [0.9708 0.9684 0.9656 0.9694] 
VALID | loss: 0.0309 - global_acc: 0.9905 - class_acc: [1.0000 1.0000 0.9920 0.9702]
Epoch 8/40
TRAIN | loss: 0.0734 - global_acc: 0.9679 - class_acc: [0.9602 0.9747 0.9676 0.9691] 
VALID | loss: 0.0513 - global_acc: 0.9796 - class_acc: [1.0000 0.9987 0.9958 0.9250]
Epoch 9/40
TRAIN | loss: 0.0649 - global_acc: 0.9747 - class_acc: [0.9763 0.9763 0.9736 0.9727] 
VALID | loss: 0.0167 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9985 0.9789] - BEST!
Epoch 10/40
TRAIN | loss: 0.0615 - global_acc: 0.9793 - class_acc: [0.9954 0.9726 0.9730 0.9765] 
VALID | loss: 0.0202 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9819 0.9965] - BEST!
Epoch 11/40
TRAIN | loss: 0.0633 - global_acc: 0.9791 - class_acc: [0.9986 0.9747 0.9717 0.9714] 
VALID | loss: 0.0217 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9872 0.9925] - BEST!
Epoch 12/40
TRAIN | loss: 0.0512 - global_acc: 0.9824 - class_acc: [0.9976 0.9689 0.9802 0.9821] 
VALID | loss: 0.0210 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9939 0.9797]
Epoch 13/40
TRAIN | loss: 0.0570 - global_acc: 0.9798 - class_acc: [0.9977 0.9707 0.9735 0.9772] 
VALID | loss: 0.0201 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9952 0.9912] - BEST!
Epoch 14/40
TRAIN | loss: 0.0518 - global_acc: 0.9795 - class_acc: [0.9954 0.9655 0.9795 0.9780] 
VALID | loss: 0.0361 - global_acc: 0.9867 - class_acc: [1.0000 1.0000 0.9966 0.9488]
Epoch 15/40
TRAIN | loss: 0.0526 - global_acc: 0.9815 - class_acc: [0.9968 0.9704 0.9799 0.9791] 
VALID | loss: 0.0238 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9905 0.9960]
Epoch 16/40
TRAIN | loss: 0.0495 - global_acc: 0.9828 - class_acc: [0.9982 0.9708 0.9813 0.9801] 
VALID | loss: 0.0110 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9924 1.0000] - BEST!
Epoch 17/40
TRAIN | loss: 0.0539 - global_acc: 0.9809 - class_acc: [0.9975 0.9668 0.9834 0.9762] 
VALID | loss: 0.0207 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9919 0.9906]
Epoch 18/40
TRAIN | loss: 0.0549 - global_acc: 0.9799 - class_acc: [0.9970 0.9659 0.9789 0.9780] 
VALID | loss: 0.0292 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9837 0.9950]
Epoch 19/40
TRAIN | loss: 0.0469 - global_acc: 0.9822 - class_acc: [0.9982 0.9695 0.9811 0.9800] 
VALID | loss: 0.0304 - global_acc: 0.9925 - class_acc: [1.0000 1.0000 0.9696 1.0000]
Epoch 20/40
TRAIN | loss: 0.0482 - global_acc: 0.9825 - class_acc: [0.9991 0.9722 0.9776 0.9810] 
VALID | loss: 0.0143 - global_acc: 0.9974 - class_acc: [0.9993 1.0000 0.9946 0.9959]
Epoch 21/40
TRAIN | loss: 0.0500 - global_acc: 0.9821 - class_acc: [0.9993 0.9676 0.9814 0.9804] 
VALID | loss: 0.0257 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9933 0.9980]
Epoch 22/40
TRAIN | loss: 0.0477 - global_acc: 0.9822 - class_acc: [0.9986 0.9654 0.9851 0.9793] 
VALID | loss: 0.0201 - global_acc: 0.9942 - class_acc: [0.9993 1.0000 0.9788 0.9993]
Epoch 23/40
TRAIN | loss: 0.0473 - global_acc: 0.9825 - class_acc: [0.9993 0.9668 0.9828 0.9805] 
VALID | loss: 0.0149 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9952 0.9972] - BEST!
Epoch 24/40
TRAIN | loss: 0.0479 - global_acc: 0.9829 - class_acc: [0.9984 0.9717 0.9816 0.9801] 
VALID | loss: 0.0167 - global_acc: 0.9959 - class_acc: [0.9993 1.0000 0.9940 0.9907]
Epoch 25/40
TRAIN | loss: 0.0521 - global_acc: 0.9795 - class_acc: [0.9954 0.9663 0.9815 0.9750] 
VALID | loss: 0.0273 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9937 0.9971]
Epoch 26/40
TRAIN | loss: 0.0467 - global_acc: 0.9825 - class_acc: [0.9991 0.9685 0.9830 0.9793] 
VALID | loss: 0.0213 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9993 0.9739]
Epoch 27/40
TRAIN | loss: 0.0451 - global_acc: 0.9826 - class_acc: [0.9986 0.9696 0.9836 0.9790] 
VALID | loss: 0.0148 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9939 0.9946]
Epoch 28/40
TRAIN | loss: 0.0511 - global_acc: 0.9841 - class_acc: [0.9998 0.9717 0.9832 0.9815] 
VALID | loss: 0.0207 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9958 0.9808]
Epoch 29/40
TRAIN | loss: 0.0441 - global_acc: 0.9830 - class_acc: [0.9993 0.9686 0.9835 0.9809] 
VALID | loss: 0.0150 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9954 0.9957]
Epoch 30/40
TRAIN | loss: 0.0423 - global_acc: 0.9840 - class_acc: [0.9986 0.9698 0.9878 0.9803] 
VALID | loss: 0.0118 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9973 0.9973] - BEST!
Epoch 31/40
TRAIN | loss: 0.0409 - global_acc: 0.9850 - class_acc: [0.9993 0.9679 0.9895 0.9835] 
VALID | loss: 0.0134 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9980 0.9946]
Epoch 32/40
TRAIN | loss: 0.0416 - global_acc: 0.9849 - class_acc: [1.0000 0.9693 0.9892 0.9811] 
VALID | loss: 0.1083 - global_acc: 0.9779 - class_acc: [1.0000 1.0000 0.9508 0.9624]
Epoch 33/40
TRAIN | loss: 0.0393 - global_acc: 0.9858 - class_acc: [0.9996 0.9684 0.9902 0.9850] 
VALID | loss: 0.0191 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9993 0.9878]
Epoch 34/40
TRAIN | loss: 0.0434 - global_acc: 0.9842 - class_acc: [0.9998 0.9704 0.9871 0.9799] 
VALID | loss: 0.0151 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9993 0.9917]
Epoch 35/40
TRAIN | loss: 0.0443 - global_acc: 0.9835 - class_acc: [0.9995 0.9706 0.9854 0.9784] 
VALID | loss: 0.0256 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9797 1.0000]
Epoch 36/40
TRAIN | loss: 0.0369 - global_acc: 0.9863 - class_acc: [1.0000 0.9728 0.9898 0.9825] 
VALID | loss: 0.0120 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9980 0.9918]
Epoch 37/40
TRAIN | loss: 0.0380 - global_acc: 0.9858 - class_acc: [0.9998 0.9673 0.9906 0.9851] 
VALID | loss: 0.0100 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9973 0.9980] - BEST!
Epoch 38/40
TRAIN | loss: 0.0400 - global_acc: 0.9844 - class_acc: [1.0000 0.9671 0.9927 0.9779] 
VALID | loss: 0.0082 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9993 0.9954]
Epoch 39/40
TRAIN | loss: 0.0406 - global_acc: 0.9839 - class_acc: [0.9991 0.9674 0.9886 0.9816] 
VALID | loss: 0.0175 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9967 0.9972]
Epoch 40/40
TRAIN | loss: 0.0378 - global_acc: 0.9849 - class_acc: [0.9998 0.9632 0.9915 0.9851] 
VALID | loss: 12.0770 - global_acc: 0.5181 - class_acc: [1.0000 1.0000 0.0654 0.0035]


Evaluating...
TEST | loss: 0.0354 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 1.0000 0.9895]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 13
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5656 - global_acc: 0.7773 - class_acc: [0.8074 0.6619 0.7498 0.8899] 
VALID | loss: 0.1807 - global_acc: 0.9372 - class_acc: [0.9973 1.0000 0.7626 0.9925] - BEST!
Epoch 2/40
TRAIN | loss: 0.1120 - global_acc: 0.9655 - class_acc: [0.9980 0.9764 0.9432 0.9439] 
VALID | loss: 0.0801 - global_acc: 0.9697 - class_acc: [1.0000 0.9987 0.9327 0.9435] - BEST!
Epoch 3/40
TRAIN | loss: 0.0920 - global_acc: 0.9730 - class_acc: [0.9989 0.9761 0.9566 0.9602] 
VALID | loss: 0.0555 - global_acc: 0.9794 - class_acc: [1.0000 1.0000 0.9612 0.9574] - BEST!
Epoch 4/40
TRAIN | loss: 0.0746 - global_acc: 0.9779 - class_acc: [0.9987 0.9808 0.9675 0.9642] 
VALID | loss: 0.0430 - global_acc: 0.9872 - class_acc: [1.0000 0.9993 0.9630 0.9858] - BEST!
Epoch 5/40
TRAIN | loss: 0.0650 - global_acc: 0.9808 - class_acc: [0.9989 0.9846 0.9686 0.9705] 
VALID | loss: 0.0381 - global_acc: 0.9893 - class_acc: [1.0000 0.9986 0.9660 0.9921] - BEST!
Epoch 6/40
TRAIN | loss: 0.0594 - global_acc: 0.9843 - class_acc: [0.9993 0.9838 0.9758 0.9781] 
VALID | loss: 1.7045 - global_acc: 0.7277 - class_acc: [0.9993 1.0000 0.5491 0.3763]
Epoch 7/40
TRAIN | loss: 0.0522 - global_acc: 0.9867 - class_acc: [0.9993 0.9856 0.9807 0.9810] 
VALID | loss: 0.0561 - global_acc: 0.9799 - class_acc: [1.0000 1.0000 0.9177 1.0000]
Epoch 8/40
TRAIN | loss: 0.0421 - global_acc: 0.9897 - class_acc: [0.9995 0.9911 0.9829 0.9857] 
VALID | loss: 0.0167 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9898 0.9980] - BEST!
Epoch 9/40
TRAIN | loss: 0.0421 - global_acc: 0.9891 - class_acc: [0.9995 0.9923 0.9804 0.9840] 
VALID | loss: 0.0160 - global_acc: 0.9946 - class_acc: [1.0000 0.9993 0.9888 0.9899]
Epoch 10/40
TRAIN | loss: 0.0349 - global_acc: 0.9913 - class_acc: [0.9995 0.9927 0.9859 0.9873] 
VALID | loss: 0.0193 - global_acc: 0.9935 - class_acc: [1.0000 1.0000 0.9750 0.9986]
Epoch 11/40
TRAIN | loss: 0.0407 - global_acc: 0.9905 - class_acc: [0.9996 0.9927 0.9830 0.9863] 
VALID | loss: 0.0168 - global_acc: 0.9944 - class_acc: [1.0000 0.9973 0.9873 0.9928]
Epoch 12/40
TRAIN | loss: 0.0351 - global_acc: 0.9911 - class_acc: [0.9995 0.9916 0.9854 0.9879] 
VALID | loss: 0.0168 - global_acc: 0.9956 - class_acc: [1.0000 0.9973 0.9873 0.9979]
Epoch 13/40
TRAIN | loss: 0.0284 - global_acc: 0.9930 - class_acc: [1.0000 0.9941 0.9886 0.9893] 
VALID | loss: 0.0141 - global_acc: 0.9947 - class_acc: [1.0000 0.9993 0.9906 0.9891]
Epoch 14/40
TRAIN | loss: 0.0335 - global_acc: 0.9918 - class_acc: [0.9993 0.9934 0.9860 0.9886] 
VALID | loss: 0.0257 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9788 0.9987]
Epoch 15/40
TRAIN | loss: 0.0327 - global_acc: 0.9918 - class_acc: [0.9986 0.9933 0.9857 0.9897] 
VALID | loss: 0.0206 - global_acc: 0.9952 - class_acc: [1.0000 0.9993 0.9852 0.9966]
Epoch 16/40
TRAIN | loss: 0.0301 - global_acc: 0.9937 - class_acc: [0.9998 0.9919 0.9908 0.9923] 
VALID | loss: 0.0608 - global_acc: 0.9803 - class_acc: [1.0000 1.0000 0.9217 0.9993]
Epoch 17/40
TRAIN | loss: 0.0313 - global_acc: 0.9926 - class_acc: [0.9995 0.9915 0.9891 0.9901] 
VALID | loss: 0.0236 - global_acc: 0.9951 - class_acc: [1.0000 0.9959 0.9860 0.9986]
Epoch 18/40
TRAIN | loss: 0.0208 - global_acc: 0.9942 - class_acc: [0.9998 0.9966 0.9897 0.9906] 
VALID | loss: 0.0136 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9933 0.9959] - BEST!
Epoch 19/40
TRAIN | loss: 0.0200 - global_acc: 0.9947 - class_acc: [1.0000 0.9944 0.9916 0.9927] 
VALID | loss: 0.0226 - global_acc: 0.9923 - class_acc: [1.0000 0.9993 0.9709 0.9987]
Epoch 20/40
TRAIN | loss: 0.0274 - global_acc: 0.9926 - class_acc: [0.9995 0.9904 0.9871 0.9935] 
VALID | loss: 0.0194 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9835 0.9993]
Epoch 21/40
TRAIN | loss: 0.0246 - global_acc: 0.9936 - class_acc: [0.9996 0.9939 0.9885 0.9923] 
VALID | loss: 0.0447 - global_acc: 0.9886 - class_acc: [1.0000 1.0000 0.9536 1.0000]
Epoch 22/40
TRAIN | loss: 0.0278 - global_acc: 0.9925 - class_acc: [0.9998 0.9918 0.9864 0.9919] 
VALID | loss: 0.0327 - global_acc: 0.9925 - class_acc: [1.0000 0.9993 0.9708 0.9993]
Epoch 23/40
TRAIN | loss: 0.0223 - global_acc: 0.9940 - class_acc: [0.9998 0.9943 0.9886 0.9931] 
VALID | loss: 0.0099 - global_acc: 0.9980 - class_acc: [1.0000 0.9993 0.9943 0.9980] - BEST!
Epoch 24/40
TRAIN | loss: 0.0290 - global_acc: 0.9937 - class_acc: [0.9998 0.9927 0.9900 0.9924] 
VALID | loss: 0.0112 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9913 0.9980]
Epoch 25/40
TRAIN | loss: 0.0212 - global_acc: 0.9948 - class_acc: [0.9995 0.9949 0.9903 0.9947] 
VALID | loss: 0.0083 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9986 0.9980] - BEST!
Epoch 26/40
TRAIN | loss: 0.0171 - global_acc: 0.9956 - class_acc: [0.9998 0.9938 0.9931 0.9956] 
VALID | loss: 0.0296 - global_acc: 0.9910 - class_acc: [1.0000 1.0000 0.9649 0.9993]
Epoch 27/40
TRAIN | loss: 0.0243 - global_acc: 0.9931 - class_acc: [0.9986 0.9950 0.9880 0.9908] 
VALID | loss: 0.0215 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9865 0.9952]
Epoch 28/40
TRAIN | loss: 0.0227 - global_acc: 0.9943 - class_acc: [0.9991 0.9934 0.9905 0.9944] 
VALID | loss: 0.0285 - global_acc: 0.9929 - class_acc: [1.0000 0.9993 0.9726 0.9993]
Epoch 29/40
TRAIN | loss: 0.0186 - global_acc: 0.9952 - class_acc: [0.9998 0.9973 0.9911 0.9924] 
VALID | loss: 0.0085 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9972 0.9973]
Epoch 30/40
TRAIN | loss: 0.0182 - global_acc: 0.9952 - class_acc: [0.9998 0.9947 0.9925 0.9941] 
VALID | loss: 0.0222 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9870 0.9993]
Epoch 31/40
TRAIN | loss: 0.0196 - global_acc: 0.9944 - class_acc: [0.9993 0.9955 0.9889 0.9938] 
VALID | loss: 0.0133 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9933 0.9986]
Epoch 32/40
TRAIN | loss: 0.0184 - global_acc: 0.9957 - class_acc: [1.0000 0.9948 0.9932 0.9948] 
VALID | loss: 0.0054 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9973 0.9979]
Epoch 33/40
TRAIN | loss: 0.0170 - global_acc: 0.9959 - class_acc: [1.0000 0.9954 0.9929 0.9951] 
VALID | loss: 0.0244 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9861 0.9979]
Epoch 34/40
TRAIN | loss: 0.0170 - global_acc: 0.9957 - class_acc: [0.9996 0.9950 0.9928 0.9955] 
VALID | loss: 0.0126 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9938 0.9993]
Epoch 35/40
TRAIN | loss: 0.0152 - global_acc: 0.9963 - class_acc: [0.9995 0.9956 0.9940 0.9959] 
VALID | loss: 0.0138 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9855 1.0000]
Epoch 36/40
TRAIN | loss: 0.0161 - global_acc: 0.9955 - class_acc: [0.9995 0.9958 0.9917 0.9950] 
VALID | loss: 0.0123 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9939 0.9980]
Epoch 37/40
TRAIN | loss: 0.0162 - global_acc: 0.9951 - class_acc: [0.9995 0.9957 0.9919 0.9935] 
VALID | loss: 0.0321 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9817 0.9993]
Epoch 38/40
TRAIN | loss: 0.0165 - global_acc: 0.9958 - class_acc: [0.9998 0.9948 0.9932 0.9954] 
VALID | loss: 0.0088 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9965 1.0000]
Epoch 39/40
TRAIN | loss: 0.0176 - global_acc: 0.9951 - class_acc: [0.9991 0.9938 0.9939 0.9934] 
VALID | loss: 0.0122 - global_acc: 0.9985 - class_acc: [1.0000 0.9993 0.9965 0.9980]
Epoch 40/40
TRAIN | loss: 0.0158 - global_acc: 0.9955 - class_acc: [0.9989 0.9940 0.9937 0.9954] 
VALID | loss: 0.0153 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9927 1.0000]


Evaluating...
TEST | loss: 0.0184 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 1.0000 0.9903]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 14
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5592 - global_acc: 0.7791 - class_acc: [0.8615 0.7415 0.8880 0.6289] 
VALID | loss: 0.1957 - global_acc: 0.9229 - class_acc: [0.9993 0.9993 0.7041 0.9861] - BEST!
Epoch 2/40
TRAIN | loss: 0.1334 - global_acc: 0.9556 - class_acc: [0.9977 0.9723 0.9246 0.9272] 
VALID | loss: 0.1470 - global_acc: 0.9433 - class_acc: [1.0000 1.0000 0.7902 0.9873] - BEST!
Epoch 3/40
TRAIN | loss: 0.0895 - global_acc: 0.9688 - class_acc: [0.9993 0.9773 0.9434 0.9562] 
VALID | loss: 0.0478 - global_acc: 0.9838 - class_acc: [1.0000 1.0000 0.9842 0.9530] - BEST!
Epoch 4/40
TRAIN | loss: 0.0718 - global_acc: 0.9762 - class_acc: [0.9986 0.9845 0.9574 0.9651] 
VALID | loss: 0.0475 - global_acc: 0.9857 - class_acc: [1.0000 1.0000 0.9545 0.9894] - BEST!
Epoch 5/40
TRAIN | loss: 0.0618 - global_acc: 0.9795 - class_acc: [0.9993 0.9861 0.9637 0.9689] 
VALID | loss: 0.0282 - global_acc: 0.9901 - class_acc: [1.0000 0.9993 0.9920 0.9695] - BEST!
Epoch 6/40
TRAIN | loss: 0.0557 - global_acc: 0.9807 - class_acc: [0.9996 0.9896 0.9639 0.9691] 
VALID | loss: 0.0319 - global_acc: 0.9906 - class_acc: [1.0000 0.9993 0.9858 0.9762] - BEST!
Epoch 7/40
TRAIN | loss: 0.0502 - global_acc: 0.9829 - class_acc: [1.0000 0.9874 0.9738 0.9703] 
VALID | loss: 0.0591 - global_acc: 0.9845 - class_acc: [1.0000 1.0000 0.9391 0.9980]
Epoch 8/40
TRAIN | loss: 0.0616 - global_acc: 0.9795 - class_acc: [0.9973 0.9874 0.9645 0.9691] 
VALID | loss: 0.0414 - global_acc: 0.9891 - class_acc: [1.0000 1.0000 0.9617 0.9946]
Epoch 9/40
TRAIN | loss: 0.0459 - global_acc: 0.9848 - class_acc: [0.9998 0.9906 0.9737 0.9751] 
VALID | loss: 0.0245 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9749 0.9972] - BEST!
Epoch 10/40
TRAIN | loss: 0.0388 - global_acc: 0.9877 - class_acc: [0.9998 0.9935 0.9777 0.9799] 
VALID | loss: 0.0220 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9826 1.0000] - BEST!
Epoch 11/40
TRAIN | loss: 0.0418 - global_acc: 0.9887 - class_acc: [0.9996 0.9913 0.9812 0.9829] 
VALID | loss: 0.0302 - global_acc: 0.9922 - class_acc: [1.0000 1.0000 0.9753 0.9939]
Epoch 12/40
TRAIN | loss: 0.0341 - global_acc: 0.9899 - class_acc: [0.9998 0.9920 0.9844 0.9832] 
VALID | loss: 0.0134 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9959 0.9945] - BEST!
Epoch 13/40
TRAIN | loss: 0.0345 - global_acc: 0.9906 - class_acc: [0.9998 0.9919 0.9848 0.9855] 
VALID | loss: 0.0172 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9966 0.9815]
Epoch 14/40
TRAIN | loss: 0.0322 - global_acc: 0.9914 - class_acc: [0.9995 0.9930 0.9850 0.9883] 
VALID | loss: 0.0571 - global_acc: 0.9881 - class_acc: [1.0000 1.0000 0.9887 0.9611]
Epoch 15/40
TRAIN | loss: 0.0333 - global_acc: 0.9913 - class_acc: [0.9998 0.9925 0.9844 0.9889] 
VALID | loss: 0.0137 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9937 0.9934]
Epoch 16/40
TRAIN | loss: 0.0309 - global_acc: 0.9918 - class_acc: [1.0000 0.9943 0.9841 0.9884] 
VALID | loss: 0.0149 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9953 0.9919]
Epoch 17/40
TRAIN | loss: 0.0310 - global_acc: 0.9927 - class_acc: [0.9995 0.9954 0.9866 0.9896] 
VALID | loss: 0.0157 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9892 1.0000]
Epoch 18/40
TRAIN | loss: 0.0304 - global_acc: 0.9927 - class_acc: [0.9995 0.9935 0.9891 0.9888] 
VALID | loss: 0.0201 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9833 1.0000]
Epoch 19/40
TRAIN | loss: 0.0287 - global_acc: 0.9935 - class_acc: [0.9998 0.9932 0.9904 0.9906] 
VALID | loss: 0.0097 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9986 0.9921] - BEST!
Epoch 20/40
TRAIN | loss: 0.0314 - global_acc: 0.9930 - class_acc: [0.9991 0.9924 0.9884 0.9918] 
VALID | loss: 0.0201 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9916 0.9986]
Epoch 21/40
TRAIN | loss: 0.0223 - global_acc: 0.9953 - class_acc: [1.0000 0.9941 0.9935 0.9936] 
VALID | loss: 0.0176 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9878 0.9986]
Epoch 22/40
TRAIN | loss: 0.0224 - global_acc: 0.9950 - class_acc: [0.9998 0.9957 0.9910 0.9931] 
VALID | loss: 0.0109 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9944 0.9965] - BEST!
Epoch 23/40
TRAIN | loss: 0.0176 - global_acc: 0.9964 - class_acc: [1.0000 0.9949 0.9947 0.9961] 
VALID | loss: 0.0117 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9972 0.9973] - BEST!
Epoch 24/40
TRAIN | loss: 0.0232 - global_acc: 0.9948 - class_acc: [0.9998 0.9939 0.9915 0.9940] 
VALID | loss: 0.0069 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 1.0000 0.9958] - BEST!
Epoch 25/40
TRAIN | loss: 0.0221 - global_acc: 0.9948 - class_acc: [1.0000 0.9945 0.9916 0.9930] 
VALID | loss: 0.0110 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9904 0.9973]
Epoch 26/40
TRAIN | loss: 0.0281 - global_acc: 0.9940 - class_acc: [0.9996 0.9935 0.9897 0.9931] 
VALID | loss: 0.0139 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9933 1.0000]
Epoch 27/40
TRAIN | loss: 0.0209 - global_acc: 0.9956 - class_acc: [1.0000 0.9950 0.9934 0.9941] 
VALID | loss: 0.0153 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9918 0.9986]
Epoch 28/40
TRAIN | loss: 0.0221 - global_acc: 0.9952 - class_acc: [1.0000 0.9939 0.9936 0.9934] 
VALID | loss: 0.0213 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9812 0.9973]
Epoch 29/40
TRAIN | loss: 0.0233 - global_acc: 0.9954 - class_acc: [0.9998 0.9957 0.9935 0.9928] 
VALID | loss: 0.0404 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9725 1.0000]
Epoch 30/40
TRAIN | loss: 0.0178 - global_acc: 0.9967 - class_acc: [0.9998 0.9975 0.9948 0.9948] 
VALID | loss: 0.0060 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9993 0.9945]
Epoch 31/40
TRAIN | loss: 0.0163 - global_acc: 0.9965 - class_acc: [1.0000 0.9961 0.9941 0.9957] 
VALID | loss: 0.0146 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9940 0.9973]
Epoch 32/40
TRAIN | loss: 0.0192 - global_acc: 0.9954 - class_acc: [1.0000 0.9950 0.9927 0.9939] 
VALID | loss: 0.0110 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9905 1.0000]
Epoch 33/40
TRAIN | loss: 0.0203 - global_acc: 0.9959 - class_acc: [0.9995 0.9952 0.9939 0.9949] 
VALID | loss: 0.0320 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9717 1.0000]
Epoch 34/40
TRAIN | loss: 0.0161 - global_acc: 0.9963 - class_acc: [1.0000 0.9948 0.9941 0.9963] 
VALID | loss: 0.0083 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9986 0.9987] - BEST!
Epoch 35/40
TRAIN | loss: 0.0209 - global_acc: 0.9957 - class_acc: [0.9998 0.9943 0.9945 0.9944] 
VALID | loss: 0.0190 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9845 1.0000]
Epoch 36/40
TRAIN | loss: 0.0184 - global_acc: 0.9962 - class_acc: [1.0000 0.9939 0.9954 0.9954] 
VALID | loss: 0.0592 - global_acc: 0.9792 - class_acc: [1.0000 1.0000 0.9182 1.0000]
Epoch 37/40
TRAIN | loss: 0.0205 - global_acc: 0.9961 - class_acc: [0.9996 0.9953 0.9951 0.9945] 
VALID | loss: 0.0140 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9896 1.0000]
Epoch 38/40
TRAIN | loss: 0.0172 - global_acc: 0.9969 - class_acc: [1.0000 0.9964 0.9961 0.9950] 
VALID | loss: 0.0171 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9959 0.9966]
Epoch 39/40
TRAIN | loss: 0.0182 - global_acc: 0.9960 - class_acc: [1.0000 0.9957 0.9939 0.9942] 
VALID | loss: 0.0161 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9966 0.9859]
Epoch 40/40
TRAIN | loss: 0.0189 - global_acc: 0.9961 - class_acc: [0.9995 0.9934 0.9946 0.9971] 
VALID | loss: 0.0075 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9980 0.9993]


Evaluating...
TEST | loss: 0.0236 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 1.0000 0.9911]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 15
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5451 - global_acc: 0.7764 - class_acc: [0.8246 0.7321 0.7815 0.7676] 
VALID | loss: 0.0913 - global_acc: 0.9649 - class_acc: [0.9986 0.9954 0.9162 0.9490] - BEST!
Epoch 2/40
TRAIN | loss: 0.1370 - global_acc: 0.9538 - class_acc: [0.9967 0.9523 0.9278 0.9400] 
VALID | loss: 0.0646 - global_acc: 0.9765 - class_acc: [1.0000 1.0000 0.9217 0.9830] - BEST!
Epoch 3/40
TRAIN | loss: 0.1026 - global_acc: 0.9664 - class_acc: [0.9984 0.9612 0.9455 0.9603] 
VALID | loss: 0.0421 - global_acc: 0.9843 - class_acc: [1.0000 1.0000 0.9507 0.9872] - BEST!
Epoch 4/40
TRAIN | loss: 0.0910 - global_acc: 0.9707 - class_acc: [0.9982 0.9680 0.9557 0.9618] 
VALID | loss: 0.0465 - global_acc: 0.9823 - class_acc: [1.0000 1.0000 0.9924 0.9361]
Epoch 5/40
TRAIN | loss: 0.0861 - global_acc: 0.9712 - class_acc: [1.0000 0.9692 0.9514 0.9640] 
VALID | loss: 0.0549 - global_acc: 0.9779 - class_acc: [0.9993 1.0000 0.9953 0.9153]
Epoch 6/40
TRAIN | loss: 0.0777 - global_acc: 0.9735 - class_acc: [0.9991 0.9645 0.9580 0.9723] 
VALID | loss: 0.0482 - global_acc: 0.9825 - class_acc: [0.9986 1.0000 0.9960 0.9356]
Epoch 7/40
TRAIN | loss: 0.0760 - global_acc: 0.9741 - class_acc: [1.0000 0.9654 0.9637 0.9678] 
VALID | loss: 0.0359 - global_acc: 0.9869 - class_acc: [0.9993 1.0000 0.9509 0.9979] - BEST!
Epoch 8/40
TRAIN | loss: 0.0651 - global_acc: 0.9759 - class_acc: [0.9988 0.9657 0.9630 0.9766] 
VALID | loss: 0.0334 - global_acc: 0.9894 - class_acc: [1.0000 1.0000 0.9613 0.9967] - BEST!
Epoch 9/40
TRAIN | loss: 0.0711 - global_acc: 0.9761 - class_acc: [0.9996 0.9682 0.9639 0.9723] 
VALID | loss: 0.0357 - global_acc: 0.9881 - class_acc: [1.0000 1.0000 0.9519 0.9993]
Epoch 10/40
TRAIN | loss: 0.0636 - global_acc: 0.9786 - class_acc: [0.9996 0.9666 0.9696 0.9779] 
VALID | loss: 0.0239 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9792 0.9979] - BEST!
Epoch 11/40
TRAIN | loss: 0.0553 - global_acc: 0.9803 - class_acc: [1.0000 0.9653 0.9757 0.9800] 
VALID | loss: 0.0193 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9771 0.9954]
Epoch 12/40
TRAIN | loss: 0.0606 - global_acc: 0.9789 - class_acc: [0.9996 0.9654 0.9712 0.9787] 
VALID | loss: 0.0182 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9837 0.9966] - BEST!
Epoch 13/40
TRAIN | loss: 0.0541 - global_acc: 0.9821 - class_acc: [0.9993 0.9682 0.9785 0.9828] 
VALID | loss: 0.0112 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9980 0.9869] - BEST!
Epoch 14/40
TRAIN | loss: 0.0480 - global_acc: 0.9847 - class_acc: [0.9998 0.9716 0.9834 0.9844] 
VALID | loss: 0.0097 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9921 0.9966] - BEST!
Epoch 15/40
TRAIN | loss: 0.0498 - global_acc: 0.9839 - class_acc: [0.9996 0.9666 0.9823 0.9869] 
VALID | loss: 0.0111 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9972 0.9871]
Epoch 16/40
TRAIN | loss: 0.0510 - global_acc: 0.9838 - class_acc: [1.0000 0.9655 0.9848 0.9848] 
VALID | loss: 0.0208 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9771 0.9993]
Epoch 17/40
TRAIN | loss: 0.0492 - global_acc: 0.9851 - class_acc: [0.9998 0.9669 0.9854 0.9882] 
VALID | loss: 0.0172 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9863 0.9993]
Epoch 18/40
TRAIN | loss: 0.0465 - global_acc: 0.9850 - class_acc: [0.9998 0.9630 0.9898 0.9879] 
VALID | loss: 0.0146 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9993 0.9825]
Epoch 19/40
TRAIN | loss: 0.0440 - global_acc: 0.9858 - class_acc: [0.9995 0.9672 0.9883 0.9881] 
VALID | loss: 0.0149 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9979 0.9898]
Epoch 20/40
TRAIN | loss: 0.0423 - global_acc: 0.9874 - class_acc: [0.9998 0.9711 0.9909 0.9880] 
VALID | loss: 0.1622 - global_acc: 0.9353 - class_acc: [1.0000 1.0000 0.7379 1.0000]
Epoch 21/40
TRAIN | loss: 0.0440 - global_acc: 0.9856 - class_acc: [1.0000 0.9643 0.9915 0.9876] 
VALID | loss: 0.0153 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9846 1.0000]
Epoch 22/40
TRAIN | loss: 0.0513 - global_acc: 0.9860 - class_acc: [0.9993 0.9698 0.9912 0.9842] 
VALID | loss: 0.0279 - global_acc: 0.9922 - class_acc: [1.0000 1.0000 0.9993 0.9683]
Epoch 23/40
TRAIN | loss: 0.0393 - global_acc: 0.9882 - class_acc: [1.0000 0.9707 0.9929 0.9899] 
VALID | loss: 0.0123 - global_acc: 0.9968 - class_acc: [1.0000 0.9993 0.9884 0.9993]
Epoch 24/40
TRAIN | loss: 0.0431 - global_acc: 0.9877 - class_acc: [1.0000 0.9696 0.9932 0.9880] 
VALID | loss: 0.0259 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 1.0000 0.9712]
Epoch 25/40
TRAIN | loss: 0.0463 - global_acc: 0.9846 - class_acc: [0.9998 0.9595 0.9915 0.9873] 
VALID | loss: 0.0251 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9813 1.0000]
Epoch 26/40
TRAIN | loss: 0.0414 - global_acc: 0.9877 - class_acc: [0.9998 0.9693 0.9935 0.9886] 
VALID | loss: 0.0149 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 1.0000 0.9848]
Epoch 27/40
TRAIN | loss: 0.0415 - global_acc: 0.9872 - class_acc: [1.0000 0.9657 0.9936 0.9896] 
VALID | loss: 0.0140 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9973 0.9973] - BEST!
Epoch 28/40
TRAIN | loss: 0.0360 - global_acc: 0.9899 - class_acc: [0.9998 0.9727 0.9958 0.9917] 
VALID | loss: 0.0107 - global_acc: 0.9985 - class_acc: [1.0000 0.9993 0.9986 0.9959]
Epoch 29/40
TRAIN | loss: 0.0379 - global_acc: 0.9887 - class_acc: [1.0000 0.9706 0.9957 0.9890] 
VALID | loss: 0.0095 - global_acc: 0.9988 - class_acc: [0.9993 1.0000 0.9987 0.9972] - BEST!
Epoch 30/40
TRAIN | loss: 0.0427 - global_acc: 0.9870 - class_acc: [0.9995 0.9669 0.9941 0.9873] 
VALID | loss: 0.0144 - global_acc: 0.9978 - class_acc: [1.0000 0.9993 0.9933 0.9986]
Epoch 31/40
TRAIN | loss: 0.0409 - global_acc: 0.9883 - class_acc: [0.9996 0.9672 0.9950 0.9913] 
VALID | loss: 0.0180 - global_acc: 0.9980 - class_acc: [1.0000 0.9980 0.9945 0.9993]
Epoch 32/40
TRAIN | loss: 0.0397 - global_acc: 0.9879 - class_acc: [1.0000 0.9665 0.9969 0.9884] 
VALID | loss: 0.0136 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 1.0000 0.9877]
Epoch 33/40
TRAIN | loss: 0.0318 - global_acc: 0.9898 - class_acc: [0.9998 0.9697 0.9973 0.9924] 
VALID | loss: 0.0060 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9993 0.9951]
Epoch 34/40
TRAIN | loss: 0.0423 - global_acc: 0.9871 - class_acc: [0.9995 0.9654 0.9950 0.9881] 
VALID | loss: 0.0177 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9980 0.9804]
Epoch 35/40
TRAIN | loss: 0.0360 - global_acc: 0.9889 - class_acc: [0.9998 0.9694 0.9955 0.9908] 
VALID | loss: 0.0105 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9980 0.9926]
Epoch 36/40
TRAIN | loss: 0.0525 - global_acc: 0.9855 - class_acc: [0.9984 0.9655 0.9910 0.9874] 
VALID | loss: 0.0099 - global_acc: 0.9985 - class_acc: [1.0000 0.9993 0.9966 0.9980]
Epoch 37/40
TRAIN | loss: 0.0384 - global_acc: 0.9880 - class_acc: [1.0000 0.9666 0.9961 0.9889] 
VALID | loss: 0.0082 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9972 0.9967]
Epoch 38/40
TRAIN | loss: 0.0329 - global_acc: 0.9895 - class_acc: [1.0000 0.9698 0.9968 0.9914] 
VALID | loss: 0.0173 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9993 0.9912]
Epoch 39/40
TRAIN | loss: 0.0401 - global_acc: 0.9878 - class_acc: [0.9998 0.9640 0.9965 0.9901] 
VALID | loss: 0.0198 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9994 0.9966] - BEST!
Epoch 40/40
TRAIN | loss: 0.0406 - global_acc: 0.9869 - class_acc: [1.0000 0.9621 0.9959 0.9898] 
VALID | loss: 0.0112 - global_acc: 0.9997 - class_acc: [1.0000 1.0000 1.0000 0.9987] - BEST!


Evaluating...
TEST | loss: 0.0085 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 1.0000 0.9924]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 16
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5654 - global_acc: 0.7107 - class_acc: [0.9269 0.8903 0.4658 0.5591] 
VALID | loss: 0.2168 - global_acc: 0.9254 - class_acc: [0.9945 1.0000 0.9347 0.7764] - BEST!
Epoch 2/40
TRAIN | loss: 0.1585 - global_acc: 0.9513 - class_acc: [0.9866 0.9823 0.9465 0.8918] 
VALID | loss: 0.1420 - global_acc: 0.9375 - class_acc: [1.0000 1.0000 0.9953 0.7429] - BEST!
Epoch 3/40
TRAIN | loss: 0.0946 - global_acc: 0.9718 - class_acc: [0.9936 0.9884 0.9750 0.9303] 
VALID | loss: 0.0905 - global_acc: 0.9643 - class_acc: [0.9986 1.0000 0.9916 0.8680] - BEST!
Epoch 4/40
TRAIN | loss: 0.0681 - global_acc: 0.9791 - class_acc: [0.9931 0.9882 0.9820 0.9536] 
VALID | loss: 0.0515 - global_acc: 0.9801 - class_acc: [1.0000 1.0000 0.9939 0.9259] - BEST!
Epoch 5/40
TRAIN | loss: 0.0588 - global_acc: 0.9838 - class_acc: [0.9950 0.9853 0.9844 0.9706] 
VALID | loss: 0.0603 - global_acc: 0.9763 - class_acc: [1.0000 0.9993 0.9959 0.9109]
Epoch 6/40
TRAIN | loss: 0.0536 - global_acc: 0.9858 - class_acc: [0.9942 0.9904 0.9854 0.9729] 
VALID | loss: 0.0886 - global_acc: 0.9622 - class_acc: [1.0000 1.0000 0.9986 0.8491]
Epoch 7/40
TRAIN | loss: 0.0428 - global_acc: 0.9884 - class_acc: [0.9954 0.9894 0.9913 0.9772] 
VALID | loss: 0.0842 - global_acc: 0.9651 - class_acc: [1.0000 1.0000 0.9986 0.8637]
Epoch 8/40
TRAIN | loss: 0.0402 - global_acc: 0.9887 - class_acc: [0.9953 0.9896 0.9922 0.9775] 
VALID | loss: 0.0287 - global_acc: 0.9893 - class_acc: [1.0000 0.9987 0.9980 0.9589] - BEST!
Epoch 9/40
TRAIN | loss: 0.0352 - global_acc: 0.9909 - class_acc: [0.9961 0.9927 0.9935 0.9813] 
VALID | loss: 0.0455 - global_acc: 0.9820 - class_acc: [1.0000 1.0000 0.9973 0.9305]
Epoch 10/40
TRAIN | loss: 0.0363 - global_acc: 0.9914 - class_acc: [0.9968 0.9929 0.9959 0.9800] 
VALID | loss: 0.0395 - global_acc: 0.9842 - class_acc: [1.0000 1.0000 0.9993 0.9372]
Epoch 11/40
TRAIN | loss: 0.0352 - global_acc: 0.9905 - class_acc: [0.9963 0.9931 0.9917 0.9808] 
VALID | loss: 0.0407 - global_acc: 0.9838 - class_acc: [0.9986 1.0000 0.9952 0.9432]
Epoch 12/40
TRAIN | loss: 0.0291 - global_acc: 0.9914 - class_acc: [0.9960 0.9934 0.9945 0.9816] 
VALID | loss: 0.0417 - global_acc: 0.9814 - class_acc: [1.0000 1.0000 1.0000 0.9241]
Epoch 13/40
TRAIN | loss: 0.0234 - global_acc: 0.9934 - class_acc: [0.9963 0.9939 0.9962 0.9871] 
VALID | loss: 0.0798 - global_acc: 0.9689 - class_acc: [1.0000 1.0000 0.9986 0.8783]
Epoch 14/40
TRAIN | loss: 0.0303 - global_acc: 0.9919 - class_acc: [0.9959 0.9908 0.9950 0.9859] 
VALID | loss: 0.0296 - global_acc: 0.9888 - class_acc: [1.0000 1.0000 0.9966 0.9589]
Epoch 15/40
TRAIN | loss: 0.0284 - global_acc: 0.9923 - class_acc: [0.9967 0.9918 0.9930 0.9875] 
VALID | loss: 0.0189 - global_acc: 0.9932 - class_acc: [0.9993 1.0000 1.0000 0.9723] - BEST!
Epoch 16/40
TRAIN | loss: 0.0226 - global_acc: 0.9948 - class_acc: [0.9956 0.9954 0.9968 0.9915] 
VALID | loss: 0.0749 - global_acc: 0.9685 - class_acc: [1.0000 1.0000 0.9993 0.8763]
Epoch 17/40
TRAIN | loss: 0.0241 - global_acc: 0.9938 - class_acc: [0.9973 0.9933 0.9950 0.9898] 
VALID | loss: 0.0496 - global_acc: 0.9803 - class_acc: [1.0000 1.0000 0.9993 0.9222]
Epoch 18/40
TRAIN | loss: 0.0244 - global_acc: 0.9947 - class_acc: [0.9975 0.9950 0.9966 0.9899] 
VALID | loss: 0.0221 - global_acc: 0.9927 - class_acc: [0.9993 1.0000 1.0000 0.9717]
Epoch 19/40
TRAIN | loss: 0.0235 - global_acc: 0.9951 - class_acc: [0.9968 0.9957 0.9969 0.9909] 
VALID | loss: 0.0314 - global_acc: 0.9886 - class_acc: [1.0000 1.0000 0.9965 0.9572]
Epoch 20/40
TRAIN | loss: 0.0206 - global_acc: 0.9955 - class_acc: [0.9970 0.9950 0.9973 0.9927] 
VALID | loss: 0.0460 - global_acc: 0.9823 - class_acc: [1.0000 1.0000 1.0000 0.9309]
Epoch 21/40
TRAIN | loss: 0.0243 - global_acc: 0.9951 - class_acc: [0.9967 0.9950 0.9969 0.9915] 
VALID | loss: 0.0624 - global_acc: 0.9762 - class_acc: [0.9993 1.0000 0.9986 0.9106]
Epoch 22/40
TRAIN | loss: 0.0235 - global_acc: 0.9945 - class_acc: [0.9966 0.9939 0.9962 0.9913] 
VALID | loss: 0.0145 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 1.0000 0.9805] - BEST!
Epoch 23/40
TRAIN | loss: 0.0231 - global_acc: 0.9943 - class_acc: [0.9966 0.9940 0.9950 0.9916] 
VALID | loss: 0.0646 - global_acc: 0.9734 - class_acc: [1.0000 1.0000 1.0000 0.8925]
Epoch 24/40
TRAIN | loss: 0.0207 - global_acc: 0.9949 - class_acc: [0.9968 0.9959 0.9948 0.9922] 
VALID | loss: 0.0451 - global_acc: 0.9849 - class_acc: [1.0000 1.0000 1.0000 0.9393]
Epoch 25/40
TRAIN | loss: 0.0150 - global_acc: 0.9964 - class_acc: [0.9975 0.9950 0.9977 0.9955] 
VALID | loss: 0.0930 - global_acc: 0.9660 - class_acc: [1.0000 0.9973 1.0000 0.8650]
Epoch 26/40
TRAIN | loss: 0.0190 - global_acc: 0.9953 - class_acc: [0.9959 0.9950 0.9964 0.9939] 
VALID | loss: 0.0227 - global_acc: 0.9917 - class_acc: [1.0000 1.0000 1.0000 0.9667]
Epoch 27/40
TRAIN | loss: 0.0168 - global_acc: 0.9959 - class_acc: [0.9968 0.9964 0.9970 0.9933] 
VALID | loss: 0.0356 - global_acc: 0.9884 - class_acc: [1.0000 1.0000 1.0000 0.9527]
Epoch 28/40
TRAIN | loss: 0.0143 - global_acc: 0.9968 - class_acc: [0.9975 0.9975 0.9968 0.9953] 
VALID | loss: 0.0185 - global_acc: 0.9935 - class_acc: [1.0000 1.0000 1.0000 0.9738]
Epoch 29/40
TRAIN | loss: 0.0142 - global_acc: 0.9964 - class_acc: [0.9966 0.9960 0.9968 0.9962] 
VALID | loss: 0.1029 - global_acc: 0.9634 - class_acc: [1.0000 1.0000 0.9986 0.8501]
Epoch 30/40
TRAIN | loss: 0.0135 - global_acc: 0.9970 - class_acc: [0.9975 0.9975 0.9975 0.9955] 
VALID | loss: 0.0278 - global_acc: 0.9908 - class_acc: [1.0000 1.0000 1.0000 0.9630]
Epoch 31/40
TRAIN | loss: 0.0166 - global_acc: 0.9963 - class_acc: [0.9968 0.9963 0.9971 0.9951] 
VALID | loss: 0.0902 - global_acc: 0.9660 - class_acc: [1.0000 1.0000 1.0000 0.8612]
Epoch 32/40
TRAIN | loss: 0.0164 - global_acc: 0.9960 - class_acc: [0.9977 0.9959 0.9973 0.9933] 
VALID | loss: 0.0292 - global_acc: 0.9901 - class_acc: [1.0000 1.0000 1.0000 0.9617]
Epoch 33/40
TRAIN | loss: 0.0138 - global_acc: 0.9960 - class_acc: [0.9969 0.9948 0.9980 0.9945] 
VALID | loss: 0.0243 - global_acc: 0.9910 - class_acc: [1.0000 1.0000 1.0000 0.9648]
Epoch 34/40
TRAIN | loss: 0.0217 - global_acc: 0.9942 - class_acc: [0.9940 0.9937 0.9964 0.9925] 
VALID | loss: 0.0869 - global_acc: 0.9668 - class_acc: [1.0000 1.0000 1.0000 0.8714]
Epoch 35/40
TRAIN | loss: 0.0137 - global_acc: 0.9969 - class_acc: [0.9975 0.9962 0.9979 0.9960] 
VALID | loss: 0.0103 - global_acc: 0.9969 - class_acc: [1.0000 0.9993 0.9993 0.9894] - BEST!
Epoch 36/40
TRAIN | loss: 0.0118 - global_acc: 0.9969 - class_acc: [0.9977 0.9973 0.9977 0.9947] 
VALID | loss: 0.0158 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 1.0000 0.9777]
Epoch 37/40
TRAIN | loss: 0.0147 - global_acc: 0.9964 - class_acc: [0.9973 0.9964 0.9973 0.9946] 
VALID | loss: 0.0156 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9993 0.9845]
Epoch 38/40
TRAIN | loss: 0.0124 - global_acc: 0.9968 - class_acc: [0.9984 0.9962 0.9977 0.9949] 
VALID | loss: 0.0225 - global_acc: 0.9922 - class_acc: [1.0000 1.0000 1.0000 0.9688]
Epoch 39/40
TRAIN | loss: 0.0124 - global_acc: 0.9966 - class_acc: [0.9984 0.9968 0.9964 0.9947] 
VALID | loss: 0.0055 - global_acc: 0.9991 - class_acc: [0.9993 1.0000 0.9979 0.9993] - BEST!
Epoch 40/40
TRAIN | loss: 0.0142 - global_acc: 0.9964 - class_acc: [0.9971 0.9979 0.9963 0.9944] 
VALID | loss: 0.3518 - global_acc: 0.9469 - class_acc: [1.0000 1.0000 0.7959 0.9926]


Evaluating...
TEST | loss: 1.2073 - global_acc: 0.8429 - class_acc: [1.0000 1.0000 0.8091 0.7672]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 17
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5297 - global_acc: 0.7991 - class_acc: [0.9224 0.6844 0.8630 0.7253] 
VALID | loss: 0.1740 - global_acc: 0.9394 - class_acc: [0.9987 1.0000 0.7550 0.9931] - BEST!
Epoch 2/40
TRAIN | loss: 0.0910 - global_acc: 0.9726 - class_acc: [0.9984 0.9796 0.9548 0.9579] 
VALID | loss: 0.0441 - global_acc: 0.9849 - class_acc: [0.9993 1.0000 0.9777 0.9632] - BEST!
Epoch 3/40
TRAIN | loss: 0.0661 - global_acc: 0.9801 - class_acc: [0.9995 0.9839 0.9668 0.9703] 
VALID | loss: 0.0628 - global_acc: 0.9762 - class_acc: [0.9986 0.9993 0.9932 0.9128]
Epoch 4/40
TRAIN | loss: 0.0546 - global_acc: 0.9843 - class_acc: [0.9993 0.9833 0.9781 0.9768] 
VALID | loss: 0.0281 - global_acc: 0.9908 - class_acc: [1.0000 0.9993 0.9749 0.9905] - BEST!
Epoch 5/40
TRAIN | loss: 0.0499 - global_acc: 0.9849 - class_acc: [0.9991 0.9825 0.9798 0.9782] 
VALID | loss: 0.0456 - global_acc: 0.9859 - class_acc: [1.0000 0.9993 0.9937 0.9526]
Epoch 6/40
TRAIN | loss: 0.0470 - global_acc: 0.9865 - class_acc: [0.9995 0.9862 0.9811 0.9794] 
VALID | loss: 0.0344 - global_acc: 0.9877 - class_acc: [1.0000 0.9986 0.9536 0.9986]
Epoch 7/40
TRAIN | loss: 0.0370 - global_acc: 0.9887 - class_acc: [0.9993 0.9881 0.9826 0.9847] 
VALID | loss: 0.0193 - global_acc: 0.9944 - class_acc: [0.9993 1.0000 0.9881 0.9901] - BEST!
Epoch 8/40
TRAIN | loss: 0.0389 - global_acc: 0.9891 - class_acc: [0.9998 0.9894 0.9833 0.9839] 
VALID | loss: 0.0209 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9979 0.9778]
Epoch 9/40
TRAIN | loss: 0.0366 - global_acc: 0.9898 - class_acc: [0.9998 0.9880 0.9867 0.9845] 
VALID | loss: 0.0143 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9857 0.9980] - BEST!
Epoch 10/40
TRAIN | loss: 0.0360 - global_acc: 0.9913 - class_acc: [0.9996 0.9913 0.9872 0.9871] 
VALID | loss: 0.0120 - global_acc: 0.9966 - class_acc: [1.0000 0.9993 0.9896 0.9973] - BEST!
Epoch 11/40
TRAIN | loss: 0.0273 - global_acc: 0.9929 - class_acc: [0.9998 0.9910 0.9909 0.9898] 
VALID | loss: 0.0174 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9861 0.9884]
Epoch 12/40
TRAIN | loss: 0.0362 - global_acc: 0.9911 - class_acc: [0.9996 0.9918 0.9875 0.9854] 
VALID | loss: 0.0135 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9987 0.9825]
Epoch 13/40
TRAIN | loss: 0.0302 - global_acc: 0.9929 - class_acc: [0.9998 0.9916 0.9907 0.9893] 
VALID | loss: 0.0440 - global_acc: 0.9838 - class_acc: [1.0000 1.0000 0.9385 0.9973]
Epoch 14/40
TRAIN | loss: 0.0301 - global_acc: 0.9930 - class_acc: [0.9995 0.9899 0.9916 0.9910] 
VALID | loss: 0.0865 - global_acc: 0.9784 - class_acc: [1.0000 1.0000 0.9167 1.0000]
Epoch 15/40
TRAIN | loss: 0.0290 - global_acc: 0.9926 - class_acc: [0.9998 0.9902 0.9902 0.9904] 
VALID | loss: 0.0101 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9959 0.9940] - BEST!
Epoch 16/40
TRAIN | loss: 0.0258 - global_acc: 0.9936 - class_acc: [0.9995 0.9926 0.9922 0.9900] 
VALID | loss: 0.0177 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9837 1.0000]
Epoch 17/40
TRAIN | loss: 0.0262 - global_acc: 0.9941 - class_acc: [0.9998 0.9937 0.9920 0.9909] 
VALID | loss: 0.0135 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9952 0.9859]
Epoch 18/40
TRAIN | loss: 0.0333 - global_acc: 0.9926 - class_acc: [0.9998 0.9918 0.9901 0.9888] 
VALID | loss: 0.0115 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9910 0.9973]
Epoch 19/40
TRAIN | loss: 0.0258 - global_acc: 0.9946 - class_acc: [0.9998 0.9945 0.9916 0.9922] 
VALID | loss: 0.0129 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9853 0.9993]
Epoch 20/40
TRAIN | loss: 0.0271 - global_acc: 0.9938 - class_acc: [1.0000 0.9947 0.9909 0.9893] 
VALID | loss: 0.0507 - global_acc: 0.9847 - class_acc: [1.0000 1.0000 0.9399 1.0000]
Epoch 21/40
TRAIN | loss: 0.0229 - global_acc: 0.9950 - class_acc: [0.9998 0.9947 0.9929 0.9925] 
VALID | loss: 0.0131 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9864 0.9986]
Epoch 22/40
TRAIN | loss: 0.0236 - global_acc: 0.9952 - class_acc: [1.0000 0.9948 0.9927 0.9933] 
VALID | loss: 0.0111 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9927 0.9972] - BEST!
Epoch 23/40
TRAIN | loss: 0.0249 - global_acc: 0.9941 - class_acc: [0.9995 0.9938 0.9925 0.9906] 
VALID | loss: 0.0171 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9840 1.0000]
Epoch 24/40
TRAIN | loss: 0.0206 - global_acc: 0.9959 - class_acc: [1.0000 0.9967 0.9921 0.9946] 
VALID | loss: 0.0090 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9940 0.9986] - BEST!
Epoch 25/40
TRAIN | loss: 0.0219 - global_acc: 0.9951 - class_acc: [0.9996 0.9959 0.9917 0.9933] 
VALID | loss: 0.0079 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9993 0.9933] - BEST!
Epoch 26/40
TRAIN | loss: 0.0239 - global_acc: 0.9951 - class_acc: [1.0000 0.9934 0.9934 0.9937] 
VALID | loss: 0.0110 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9918 0.9986]
Epoch 27/40
TRAIN | loss: 0.0233 - global_acc: 0.9955 - class_acc: [0.9998 0.9943 0.9935 0.9945] 
VALID | loss: 0.0093 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9939 0.9979]
Epoch 28/40
TRAIN | loss: 0.0199 - global_acc: 0.9960 - class_acc: [0.9993 0.9954 0.9951 0.9941] 
VALID | loss: 0.0737 - global_acc: 0.9731 - class_acc: [1.0000 1.0000 0.9833 0.9098]
Epoch 29/40
TRAIN | loss: 0.0259 - global_acc: 0.9935 - class_acc: [0.9998 0.9933 0.9898 0.9913] 
VALID | loss: 0.0066 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9979 0.9979] - BEST!
Epoch 30/40
TRAIN | loss: 0.0216 - global_acc: 0.9959 - class_acc: [0.9998 0.9949 0.9944 0.9943] 
VALID | loss: 0.0049 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9973 0.9979]
Epoch 31/40
TRAIN | loss: 0.0218 - global_acc: 0.9951 - class_acc: [0.9995 0.9941 0.9930 0.9936] 
VALID | loss: 0.0174 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9832 0.9993]
Epoch 32/40
TRAIN | loss: 0.0165 - global_acc: 0.9965 - class_acc: [1.0000 0.9959 0.9935 0.9967] 
VALID | loss: 0.0058 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9966 0.9980]
Epoch 33/40
TRAIN | loss: 0.0213 - global_acc: 0.9949 - class_acc: [0.9998 0.9935 0.9920 0.9944] 
VALID | loss: 0.0083 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9953 0.9979]
Epoch 34/40
TRAIN | loss: 0.0179 - global_acc: 0.9961 - class_acc: [0.9998 0.9946 0.9947 0.9955] 
VALID | loss: 0.0048 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9952 1.0000]
Epoch 35/40
TRAIN | loss: 0.0206 - global_acc: 0.9959 - class_acc: [1.0000 0.9939 0.9938 0.9960] 
VALID | loss: 0.0081 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9952 1.0000]
Epoch 36/40
TRAIN | loss: 0.0198 - global_acc: 0.9962 - class_acc: [1.0000 0.9955 0.9948 0.9945] 
VALID | loss: 0.0105 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9986 0.9901]
Epoch 37/40
TRAIN | loss: 0.0220 - global_acc: 0.9957 - class_acc: [1.0000 0.9948 0.9939 0.9940] 
VALID | loss: 0.0066 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9986 0.9968]
Epoch 38/40
TRAIN | loss: 0.0193 - global_acc: 0.9963 - class_acc: [0.9998 0.9945 0.9955 0.9955] 
VALID | loss: 0.0136 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9876 1.0000]
Epoch 39/40
TRAIN | loss: 0.0168 - global_acc: 0.9968 - class_acc: [1.0000 0.9959 0.9959 0.9955] 
VALID | loss: 0.0049 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9973 1.0000] - BEST!
Epoch 40/40
TRAIN | loss: 0.0148 - global_acc: 0.9967 - class_acc: [0.9996 0.9943 0.9964 0.9965] 
VALID | loss: 0.0087 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9905 0.9986]


Evaluating...
TEST | loss: 0.0188 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9990 0.9924]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 18
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5631 - global_acc: 0.7811 - class_acc: [0.8076 0.6343 0.8110 0.8682] 
VALID | loss: 0.1347 - global_acc: 0.9532 - class_acc: [1.0000 0.9986 0.8355 0.9772] - BEST!
Epoch 2/40
TRAIN | loss: 0.1060 - global_acc: 0.9703 - class_acc: [0.9991 0.9706 0.9460 0.9662] 
VALID | loss: 0.0862 - global_acc: 0.9685 - class_acc: [0.9993 1.0000 0.9143 0.9611] - BEST!
Epoch 3/40
TRAIN | loss: 0.0710 - global_acc: 0.9799 - class_acc: [0.9986 0.9860 0.9640 0.9709] 
VALID | loss: 0.0580 - global_acc: 0.9779 - class_acc: [1.0000 1.0000 0.9299 0.9845] - BEST!
Epoch 4/40
TRAIN | loss: 0.0641 - global_acc: 0.9834 - class_acc: [0.9981 0.9873 0.9700 0.9783] 
VALID | loss: 0.0888 - global_acc: 0.9707 - class_acc: [0.9993 0.9987 0.9903 0.8898]
Epoch 5/40
TRAIN | loss: 0.0581 - global_acc: 0.9858 - class_acc: [0.9995 0.9880 0.9776 0.9781] 
VALID | loss: 0.0522 - global_acc: 0.9814 - class_acc: [1.0000 1.0000 0.9384 0.9883] - BEST!
Epoch 6/40
TRAIN | loss: 0.0442 - global_acc: 0.9876 - class_acc: [0.9993 0.9886 0.9793 0.9834] 
VALID | loss: 0.0230 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9828 0.9855] - BEST!
Epoch 7/40
TRAIN | loss: 0.0472 - global_acc: 0.9879 - class_acc: [0.9995 0.9863 0.9818 0.9840] 
VALID | loss: 0.0220 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9833 0.9890] - BEST!
Epoch 8/40
TRAIN | loss: 0.0415 - global_acc: 0.9896 - class_acc: [0.9998 0.9896 0.9833 0.9855] 
VALID | loss: 0.0263 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9827 0.9891]
Epoch 9/40
TRAIN | loss: 0.0359 - global_acc: 0.9914 - class_acc: [0.9991 0.9898 0.9889 0.9882] 
VALID | loss: 0.0410 - global_acc: 0.9876 - class_acc: [1.0000 1.0000 0.9590 0.9916]
Epoch 10/40
TRAIN | loss: 0.0390 - global_acc: 0.9905 - class_acc: [0.9993 0.9894 0.9854 0.9878] 
VALID | loss: 0.0308 - global_acc: 0.9925 - class_acc: [1.0000 1.0000 0.9724 0.9972]
Epoch 11/40
TRAIN | loss: 0.0349 - global_acc: 0.9918 - class_acc: [1.0000 0.9903 0.9873 0.9893] 
VALID | loss: 0.0155 - global_acc: 0.9947 - class_acc: [1.0000 0.9993 0.9979 0.9815] - BEST!
Epoch 12/40
TRAIN | loss: 0.0345 - global_acc: 0.9918 - class_acc: [1.0000 0.9905 0.9876 0.9890] 
VALID | loss: 0.0508 - global_acc: 0.9826 - class_acc: [1.0000 1.0000 0.9300 1.0000]
Epoch 13/40
TRAIN | loss: 0.0288 - global_acc: 0.9930 - class_acc: [0.9998 0.9921 0.9920 0.9882] 
VALID | loss: 0.0826 - global_acc: 0.9741 - class_acc: [1.0000 1.0000 0.9993 0.9001]
Epoch 14/40
TRAIN | loss: 0.0356 - global_acc: 0.9914 - class_acc: [0.9998 0.9883 0.9899 0.9876] 
VALID | loss: 0.0327 - global_acc: 0.9894 - class_acc: [1.0000 1.0000 0.9596 0.9980]
Epoch 15/40
TRAIN | loss: 0.0334 - global_acc: 0.9917 - class_acc: [1.0000 0.9909 0.9895 0.9863] 
VALID | loss: 0.0195 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9931 0.9973] - BEST!
Epoch 16/40
TRAIN | loss: 0.0337 - global_acc: 0.9929 - class_acc: [1.0000 0.9887 0.9923 0.9906] 
VALID | loss: 0.0088 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9979 0.9953] - BEST!
Epoch 17/40
TRAIN | loss: 0.0293 - global_acc: 0.9930 - class_acc: [0.9998 0.9903 0.9911 0.9909] 
VALID | loss: 0.0694 - global_acc: 0.9794 - class_acc: [0.9993 1.0000 0.9187 0.9993]
Epoch 18/40
TRAIN | loss: 0.0314 - global_acc: 0.9936 - class_acc: [0.9996 0.9892 0.9934 0.9921] 
VALID | loss: 0.0176 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9993 0.9785]
Epoch 19/40
TRAIN | loss: 0.0266 - global_acc: 0.9942 - class_acc: [0.9998 0.9928 0.9931 0.9910] 
VALID | loss: 0.0132 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9882 0.9994]
Epoch 20/40
TRAIN | loss: 0.0232 - global_acc: 0.9948 - class_acc: [1.0000 0.9912 0.9938 0.9939] 
VALID | loss: 0.0081 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9986 0.9905]
Epoch 21/40
TRAIN | loss: 0.0310 - global_acc: 0.9933 - class_acc: [0.9998 0.9893 0.9909 0.9932] 
VALID | loss: 0.0243 - global_acc: 0.9939 - class_acc: [0.9987 1.0000 0.9854 0.9913]
Epoch 22/40
TRAIN | loss: 0.0313 - global_acc: 0.9927 - class_acc: [0.9995 0.9890 0.9926 0.9900] 
VALID | loss: 0.0157 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9907 0.9986]
Epoch 23/40
TRAIN | loss: 0.0249 - global_acc: 0.9940 - class_acc: [1.0000 0.9906 0.9936 0.9915] 
VALID | loss: 0.0099 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9967 0.9959]
Epoch 24/40
TRAIN | loss: 0.0232 - global_acc: 0.9948 - class_acc: [1.0000 0.9923 0.9928 0.9942] 
VALID | loss: 0.0122 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9980 0.9931]
Epoch 25/40
TRAIN | loss: 0.0292 - global_acc: 0.9941 - class_acc: [0.9998 0.9922 0.9917 0.9927] 
VALID | loss: 0.0159 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9824 0.9979]
Epoch 26/40
TRAIN | loss: 0.0276 - global_acc: 0.9940 - class_acc: [0.9993 0.9899 0.9936 0.9930] 
VALID | loss: 0.0138 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9959 0.9894]
Epoch 27/40
TRAIN | loss: 0.0272 - global_acc: 0.9933 - class_acc: [0.9998 0.9889 0.9914 0.9929] 
VALID | loss: 0.0098 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9972 0.9953]
Epoch 28/40
TRAIN | loss: 0.0268 - global_acc: 0.9939 - class_acc: [1.0000 0.9913 0.9906 0.9936] 
VALID | loss: 0.0089 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9973 1.0000] - BEST!
Epoch 29/40
TRAIN | loss: 0.0221 - global_acc: 0.9952 - class_acc: [1.0000 0.9927 0.9940 0.9943] 
VALID | loss: 0.0114 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9959 0.9953]
Epoch 30/40
TRAIN | loss: 0.0216 - global_acc: 0.9955 - class_acc: [1.0000 0.9932 0.9941 0.9948] 
VALID | loss: 0.0135 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9917 1.0000]
Epoch 31/40
TRAIN | loss: 0.0236 - global_acc: 0.9944 - class_acc: [0.9993 0.9912 0.9934 0.9936] 
VALID | loss: 0.0236 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9784 0.9993]
Epoch 32/40
TRAIN | loss: 0.0227 - global_acc: 0.9952 - class_acc: [0.9998 0.9921 0.9946 0.9944] 
VALID | loss: 0.0375 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9758 1.0000]
Epoch 33/40
TRAIN | loss: 0.0253 - global_acc: 0.9943 - class_acc: [0.9996 0.9907 0.9937 0.9930] 
VALID | loss: 0.0271 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9822 0.9987]
Epoch 34/40
TRAIN | loss: 0.0231 - global_acc: 0.9953 - class_acc: [0.9995 0.9916 0.9936 0.9965] 
VALID | loss: 0.0185 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9958 0.9953]
Epoch 35/40
TRAIN | loss: 0.0205 - global_acc: 0.9959 - class_acc: [1.0000 0.9927 0.9957 0.9953] 
VALID | loss: 0.0168 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9946 0.9979]
Epoch 36/40
TRAIN | loss: 0.0254 - global_acc: 0.9944 - class_acc: [0.9991 0.9907 0.9950 0.9931] 
VALID | loss: 0.0273 - global_acc: 0.9954 - class_acc: [1.0000 0.9993 0.9829 0.9993]
Epoch 37/40
TRAIN | loss: 0.0211 - global_acc: 0.9955 - class_acc: [1.0000 0.9935 0.9941 0.9942] 
VALID | loss: 0.0130 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9973 0.9993]
Epoch 38/40
TRAIN | loss: 0.0244 - global_acc: 0.9942 - class_acc: [1.0000 0.9884 0.9949 0.9934] 
VALID | loss: 0.0108 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9993 0.9939]
Epoch 39/40
TRAIN | loss: 0.0184 - global_acc: 0.9958 - class_acc: [0.9995 0.9922 0.9953 0.9961] 
VALID | loss: 0.0090 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9973 0.9993]
Epoch 40/40
TRAIN | loss: 0.0229 - global_acc: 0.9946 - class_acc: [0.9998 0.9920 0.9939 0.9925] 
VALID | loss: 0.0174 - global_acc: 0.9985 - class_acc: [1.0000 0.9993 0.9952 0.9994]


Evaluating...
TEST | loss: 0.6043 - global_acc: 0.9226 - class_acc: [0.5000 1.0000 0.9949 0.8127]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 19
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5967 - global_acc: 0.7270 - class_acc: [0.9090 0.4682 0.8413 0.6892] 
VALID | loss: 0.1422 - global_acc: 0.9530 - class_acc: [0.9986 1.0000 0.9563 0.8592] - BEST!
Epoch 2/40
TRAIN | loss: 0.1219 - global_acc: 0.9628 - class_acc: [0.9661 0.9987 0.9418 0.9437] 
VALID | loss: 0.0764 - global_acc: 0.9712 - class_acc: [1.0000 1.0000 0.9246 0.9606] - BEST!
Epoch 3/40
TRAIN | loss: 0.0898 - global_acc: 0.9710 - class_acc: [0.9652 0.9980 0.9614 0.9590] 
VALID | loss: 0.1823 - global_acc: 0.9106 - class_acc: [0.9968 1.0000 0.6376 0.9972]
Epoch 4/40
TRAIN | loss: 0.0695 - global_acc: 0.9805 - class_acc: [0.9781 0.9984 0.9712 0.9741] 
VALID | loss: 0.0713 - global_acc: 0.9729 - class_acc: [0.9993 1.0000 0.8935 0.9973] - BEST!
Epoch 5/40
TRAIN | loss: 0.0628 - global_acc: 0.9820 - class_acc: [0.9777 0.9993 0.9754 0.9753] 
VALID | loss: 0.2695 - global_acc: 0.9081 - class_acc: [1.0000 1.0000 0.7308 0.9001]
Epoch 6/40
TRAIN | loss: 0.0619 - global_acc: 0.9838 - class_acc: [0.9779 0.9987 0.9782 0.9801] 
VALID | loss: 0.0480 - global_acc: 0.9808 - class_acc: [1.0000 1.0000 0.9951 0.9249] - BEST!
Epoch 7/40
TRAIN | loss: 0.0492 - global_acc: 0.9863 - class_acc: [0.9841 0.9995 0.9796 0.9823] 
VALID | loss: 0.0232 - global_acc: 0.9925 - class_acc: [0.9993 1.0000 0.9726 0.9986] - BEST!
Epoch 8/40
TRAIN | loss: 0.0507 - global_acc: 0.9860 - class_acc: [0.9802 0.9988 0.9824 0.9828] 
VALID | loss: 0.0602 - global_acc: 0.9808 - class_acc: [0.9961 1.0000 0.9966 0.9306]
Epoch 9/40
TRAIN | loss: 0.0451 - global_acc: 0.9875 - class_acc: [0.9837 0.9995 0.9819 0.9851] 
VALID | loss: 0.0170 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9903 0.9918] - BEST!
Epoch 10/40
TRAIN | loss: 0.0439 - global_acc: 0.9876 - class_acc: [0.9831 0.9995 0.9852 0.9828] 
VALID | loss: 0.0207 - global_acc: 0.9952 - class_acc: [0.9986 1.0000 0.9842 0.9980]
Epoch 11/40
TRAIN | loss: 0.0428 - global_acc: 0.9896 - class_acc: [0.9838 0.9986 0.9871 0.9889] 
VALID | loss: 0.0370 - global_acc: 0.9893 - class_acc: [0.9932 1.0000 0.9901 0.9746]
Epoch 12/40
TRAIN | loss: 0.0443 - global_acc: 0.9883 - class_acc: [0.9822 0.9989 0.9877 0.9845] 
VALID | loss: 0.0235 - global_acc: 0.9952 - class_acc: [0.9960 1.0000 0.9871 0.9980]
Epoch 13/40
TRAIN | loss: 0.0365 - global_acc: 0.9902 - class_acc: [0.9831 0.9995 0.9889 0.9894] 
VALID | loss: 0.0527 - global_acc: 0.9804 - class_acc: [1.0000 1.0000 0.9234 1.0000]
Epoch 14/40
TRAIN | loss: 0.0336 - global_acc: 0.9896 - class_acc: [0.9834 0.9995 0.9900 0.9855] 
VALID | loss: 0.0181 - global_acc: 0.9946 - class_acc: [0.9987 1.0000 0.9873 0.9923]
Epoch 15/40
TRAIN | loss: 0.0373 - global_acc: 0.9891 - class_acc: [0.9833 0.9996 0.9884 0.9850] 
VALID | loss: 0.0207 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9795 1.0000]
Epoch 16/40
TRAIN | loss: 0.0305 - global_acc: 0.9910 - class_acc: [0.9846 0.9995 0.9905 0.9893] 
VALID | loss: 0.0167 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9828 0.9974]
Epoch 17/40
TRAIN | loss: 0.0360 - global_acc: 0.9894 - class_acc: [0.9843 0.9993 0.9853 0.9893] 
VALID | loss: 0.0709 - global_acc: 0.9697 - class_acc: [1.0000 1.0000 0.8826 1.0000]
Epoch 18/40
TRAIN | loss: 0.0330 - global_acc: 0.9912 - class_acc: [0.9842 0.9996 0.9890 0.9920] 
VALID | loss: 2.5982 - global_acc: 0.6914 - class_acc: [1.0000 1.0000 0.1535 0.6169]
Epoch 19/40
TRAIN | loss: 0.0321 - global_acc: 0.9908 - class_acc: [0.9842 0.9995 0.9877 0.9916] 
VALID | loss: 0.0193 - global_acc: 0.9968 - class_acc: [0.9993 1.0000 0.9906 0.9973] - BEST!
Epoch 20/40
TRAIN | loss: 0.0383 - global_acc: 0.9905 - class_acc: [0.9813 0.9993 0.9907 0.9906] 
VALID | loss: 0.0202 - global_acc: 0.9952 - class_acc: [0.9966 1.0000 0.9951 0.9893]
Epoch 21/40
TRAIN | loss: 0.0292 - global_acc: 0.9917 - class_acc: [0.9841 0.9995 0.9912 0.9917] 
VALID | loss: 0.0253 - global_acc: 0.9903 - class_acc: [0.9993 1.0000 0.9972 0.9642]
Epoch 22/40
TRAIN | loss: 0.0271 - global_acc: 0.9929 - class_acc: [0.9855 0.9998 0.9919 0.9941] 
VALID | loss: 0.0157 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9909 1.0000] - BEST!
Epoch 23/40
TRAIN | loss: 0.0289 - global_acc: 0.9914 - class_acc: [0.9847 1.0000 0.9891 0.9919] 
VALID | loss: 0.0139 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9897 0.9933]
Epoch 24/40
TRAIN | loss: 0.0313 - global_acc: 0.9908 - class_acc: [0.9812 0.9995 0.9909 0.9913] 
VALID | loss: 0.0233 - global_acc: 0.9923 - class_acc: [1.0000 1.0000 0.9925 0.9769]
Epoch 25/40
TRAIN | loss: 0.0282 - global_acc: 0.9925 - class_acc: [0.9858 0.9991 0.9899 0.9949] 
VALID | loss: 0.0191 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9898 0.9980]
Epoch 26/40
TRAIN | loss: 0.0321 - global_acc: 0.9909 - class_acc: [0.9821 0.9996 0.9900 0.9916] 
VALID | loss: 0.0116 - global_acc: 0.9971 - class_acc: [0.9993 1.0000 0.9966 0.9926]
Epoch 27/40
TRAIN | loss: 0.0257 - global_acc: 0.9922 - class_acc: [0.9849 0.9998 0.9914 0.9927] 
VALID | loss: 0.0120 - global_acc: 0.9968 - class_acc: [0.9972 1.0000 0.9932 0.9965]
Epoch 28/40
TRAIN | loss: 0.0311 - global_acc: 0.9901 - class_acc: [0.9805 0.9995 0.9889 0.9917] 
VALID | loss: 0.0103 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9930 1.0000] - BEST!
Epoch 29/40
TRAIN | loss: 0.0260 - global_acc: 0.9923 - class_acc: [0.9807 0.9998 0.9950 0.9937] 
VALID | loss: 0.0108 - global_acc: 0.9971 - class_acc: [0.9973 1.0000 0.9966 0.9947]
Epoch 30/40
TRAIN | loss: 0.0250 - global_acc: 0.9926 - class_acc: [0.9849 1.0000 0.9913 0.9943] 
VALID | loss: 0.0162 - global_acc: 0.9959 - class_acc: [0.9986 1.0000 0.9864 0.9987]
Epoch 31/40
TRAIN | loss: 0.0242 - global_acc: 0.9930 - class_acc: [0.9870 1.0000 0.9909 0.9939] 
VALID | loss: 0.0108 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9980 0.9878]
Epoch 32/40
TRAIN | loss: 0.0266 - global_acc: 0.9920 - class_acc: [0.9845 0.9998 0.9929 0.9910] 
VALID | loss: 0.0113 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9913 0.9993]
Epoch 33/40
TRAIN | loss: 0.0207 - global_acc: 0.9929 - class_acc: [0.9828 0.9998 0.9944 0.9948] 
VALID | loss: 0.0198 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9805 0.9993]
Epoch 34/40
TRAIN | loss: 0.0273 - global_acc: 0.9926 - class_acc: [0.9859 0.9993 0.9923 0.9931] 
VALID | loss: 0.0103 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9937 0.9972]
Epoch 35/40
TRAIN | loss: 0.0312 - global_acc: 0.9910 - class_acc: [0.9790 0.9995 0.9926 0.9929] 
VALID | loss: 0.0124 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9938 0.9919]
Epoch 36/40
TRAIN | loss: 0.0251 - global_acc: 0.9932 - class_acc: [0.9860 0.9998 0.9923 0.9948] 
VALID | loss: 0.0186 - global_acc: 0.9976 - class_acc: [0.9986 1.0000 0.9916 1.0000]
Epoch 37/40
TRAIN | loss: 0.0210 - global_acc: 0.9925 - class_acc: [0.9812 0.9998 0.9933 0.9962] 
VALID | loss: 0.0103 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9936 0.9904]
Epoch 38/40
TRAIN | loss: 0.0246 - global_acc: 0.9919 - class_acc: [0.9841 0.9982 0.9925 0.9929] 
VALID | loss: 0.0261 - global_acc: 0.9961 - class_acc: [0.9993 1.0000 0.9857 0.9993]
Epoch 39/40
TRAIN | loss: 0.0194 - global_acc: 0.9930 - class_acc: [0.9855 0.9991 0.9931 0.9944] 
VALID | loss: 0.0224 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9986 0.9781]
Epoch 40/40
TRAIN | loss: 0.0233 - global_acc: 0.9925 - class_acc: [0.9859 0.9984 0.9933 0.9920] 
VALID | loss: 0.0142 - global_acc: 0.9978 - class_acc: [0.9993 1.0000 0.9917 1.0000]


Evaluating...
TEST | loss: 0.0763 - global_acc: 0.9864 - class_acc: [1.0000 1.0000 0.9995 0.9667]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 20
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5954 - global_acc: 0.7455 - class_acc: [0.8452 0.5161 0.8092 0.8100] 
VALID | loss: 0.1241 - global_acc: 0.9520 - class_acc: [0.9987 0.9987 0.8364 0.9698] - BEST!
Epoch 2/40
TRAIN | loss: 0.1078 - global_acc: 0.9649 - class_acc: [0.9986 0.9653 0.9434 0.9519] 
VALID | loss: 0.1248 - global_acc: 0.9578 - class_acc: [1.0000 1.0000 0.8488 0.9902] - BEST!
Epoch 3/40
TRAIN | loss: 0.0757 - global_acc: 0.9767 - class_acc: [0.9993 0.9828 0.9604 0.9644] 
VALID | loss: 0.0503 - global_acc: 0.9806 - class_acc: [1.0000 1.0000 0.9388 0.9842] - BEST!
Epoch 4/40
TRAIN | loss: 0.0632 - global_acc: 0.9811 - class_acc: [0.9986 0.9867 0.9668 0.9721] 
VALID | loss: 0.0485 - global_acc: 0.9823 - class_acc: [1.0000 1.0000 0.9330 0.9958] - BEST!
Epoch 5/40
TRAIN | loss: 0.0538 - global_acc: 0.9842 - class_acc: [0.9993 0.9911 0.9745 0.9709] 
VALID | loss: 0.0249 - global_acc: 0.9911 - class_acc: [0.9986 1.0000 0.9886 0.9772] - BEST!
Epoch 6/40
TRAIN | loss: 0.0467 - global_acc: 0.9872 - class_acc: [0.9989 0.9908 0.9810 0.9782] 
VALID | loss: 0.0670 - global_acc: 0.9750 - class_acc: [1.0000 1.0000 0.9884 0.9104]
Epoch 7/40
TRAIN | loss: 0.0460 - global_acc: 0.9871 - class_acc: [0.9995 0.9907 0.9795 0.9784] 
VALID | loss: 0.0278 - global_acc: 0.9913 - class_acc: [1.0000 1.0000 0.9743 0.9911] - BEST!
Epoch 8/40
TRAIN | loss: 0.0392 - global_acc: 0.9903 - class_acc: [0.9998 0.9925 0.9838 0.9853] 
VALID | loss: 0.0225 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9845 0.9885] - BEST!
Epoch 9/40
TRAIN | loss: 0.0353 - global_acc: 0.9914 - class_acc: [0.9996 0.9948 0.9855 0.9855] 
VALID | loss: 0.0262 - global_acc: 0.9911 - class_acc: [1.0000 0.9986 0.9744 0.9918]
Epoch 10/40
TRAIN | loss: 0.0450 - global_acc: 0.9897 - class_acc: [0.9998 0.9918 0.9835 0.9836] 
VALID | loss: 0.0169 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9910 0.9887] - BEST!
Epoch 11/40
TRAIN | loss: 0.0329 - global_acc: 0.9919 - class_acc: [0.9996 0.9942 0.9872 0.9864] 
VALID | loss: 0.0244 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9987 0.9679]
Epoch 12/40
TRAIN | loss: 0.0392 - global_acc: 0.9913 - class_acc: [0.9998 0.9930 0.9854 0.9869] 
VALID | loss: 0.0428 - global_acc: 0.9867 - class_acc: [1.0000 1.0000 0.9953 0.9519]
Epoch 13/40
TRAIN | loss: 0.0263 - global_acc: 0.9935 - class_acc: [1.0000 0.9949 0.9892 0.9901] 
VALID | loss: 0.0151 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9835 0.9972] - BEST!
Epoch 14/40
TRAIN | loss: 0.0285 - global_acc: 0.9939 - class_acc: [0.9998 0.9951 0.9897 0.9908] 
VALID | loss: 0.0345 - global_acc: 0.9881 - class_acc: [1.0000 1.0000 0.9546 0.9979]
Epoch 15/40
TRAIN | loss: 0.0281 - global_acc: 0.9938 - class_acc: [0.9993 0.9936 0.9911 0.9910] 
VALID | loss: 0.0140 - global_acc: 0.9971 - class_acc: [0.9993 1.0000 0.9903 0.9986] - BEST!
Epoch 16/40
TRAIN | loss: 0.0311 - global_acc: 0.9936 - class_acc: [1.0000 0.9958 0.9884 0.9903] 
VALID | loss: 0.0228 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9712 1.0000]
Epoch 17/40
TRAIN | loss: 0.0220 - global_acc: 0.9947 - class_acc: [0.9991 0.9950 0.9907 0.9939] 
VALID | loss: 0.0132 - global_acc: 0.9976 - class_acc: [1.0000 0.9993 0.9921 0.9993] - BEST!
Epoch 18/40
TRAIN | loss: 0.0220 - global_acc: 0.9956 - class_acc: [1.0000 0.9967 0.9924 0.9933] 
VALID | loss: 0.0227 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9737 0.9973]
Epoch 19/40
TRAIN | loss: 0.0283 - global_acc: 0.9942 - class_acc: [0.9998 0.9965 0.9886 0.9916] 
VALID | loss: 0.0102 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9939 0.9959]
Epoch 20/40
TRAIN | loss: 0.0215 - global_acc: 0.9953 - class_acc: [0.9995 0.9957 0.9930 0.9930] 
VALID | loss: 0.0230 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9816 0.9986]
Epoch 21/40
TRAIN | loss: 0.0231 - global_acc: 0.9951 - class_acc: [1.0000 0.9947 0.9929 0.9926] 
VALID | loss: 0.0080 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9993 0.9910]
Epoch 22/40
TRAIN | loss: 0.0219 - global_acc: 0.9951 - class_acc: [0.9998 0.9952 0.9929 0.9927] 
VALID | loss: 0.0144 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 1.0000 0.9813]
Epoch 23/40
TRAIN | loss: 0.0236 - global_acc: 0.9955 - class_acc: [1.0000 0.9948 0.9926 0.9946] 
VALID | loss: 0.0115 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9986 0.9891]
Epoch 24/40
TRAIN | loss: 0.0248 - global_acc: 0.9947 - class_acc: [0.9998 0.9948 0.9923 0.9920] 
VALID | loss: 0.0076 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9980 0.9958] - BEST!
Epoch 25/40
TRAIN | loss: 0.0213 - global_acc: 0.9952 - class_acc: [0.9993 0.9957 0.9936 0.9923] 
VALID | loss: 0.0108 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9939 0.9930]
Epoch 26/40
TRAIN | loss: 0.0252 - global_acc: 0.9954 - class_acc: [1.0000 0.9954 0.9932 0.9929] 
VALID | loss: 0.0246 - global_acc: 0.9901 - class_acc: [1.0000 1.0000 0.9993 0.9619]
Epoch 27/40
TRAIN | loss: 0.0280 - global_acc: 0.9947 - class_acc: [0.9998 0.9932 0.9927 0.9932] 
VALID | loss: 0.0102 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9929 0.9993]
Epoch 28/40
TRAIN | loss: 0.0215 - global_acc: 0.9952 - class_acc: [0.9995 0.9953 0.9921 0.9940] 
VALID | loss: 0.0089 - global_acc: 0.9973 - class_acc: [1.0000 1.0000 0.9979 0.9913]
Epoch 29/40
TRAIN | loss: 0.0196 - global_acc: 0.9957 - class_acc: [1.0000 0.9943 0.9948 0.9937] 
VALID | loss: 0.0132 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9904 0.9979]
Epoch 30/40
TRAIN | loss: 0.0217 - global_acc: 0.9956 - class_acc: [0.9998 0.9957 0.9951 0.9918] 
VALID | loss: 0.0101 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9961 0.9959]
Epoch 31/40
TRAIN | loss: 0.0216 - global_acc: 0.9957 - class_acc: [0.9998 0.9955 0.9938 0.9939] 
VALID | loss: 0.0112 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9952 0.9987]
Epoch 32/40
TRAIN | loss: 0.0210 - global_acc: 0.9967 - class_acc: [1.0000 0.9962 0.9963 0.9943] 
VALID | loss: 0.0075 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9980 0.9952]
Epoch 33/40
TRAIN | loss: 0.0215 - global_acc: 0.9960 - class_acc: [1.0000 0.9954 0.9944 0.9942] 
VALID | loss: 0.0109 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9953 0.9980]
Epoch 34/40
TRAIN | loss: 0.0208 - global_acc: 0.9958 - class_acc: [0.9995 0.9954 0.9931 0.9952] 
VALID | loss: 0.0130 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9973 0.9892]
Epoch 35/40
TRAIN | loss: 0.0161 - global_acc: 0.9968 - class_acc: [1.0000 0.9962 0.9950 0.9959] 
VALID | loss: 0.0149 - global_acc: 0.9942 - class_acc: [1.0000 1.0000 0.9993 0.9770]
Epoch 36/40
TRAIN | loss: 0.0164 - global_acc: 0.9965 - class_acc: [0.9998 0.9977 0.9943 0.9942] 
VALID | loss: 0.0365 - global_acc: 0.9898 - class_acc: [1.0000 1.0000 0.9609 0.9973]
Epoch 37/40
TRAIN | loss: 0.0216 - global_acc: 0.9958 - class_acc: [0.9993 0.9953 0.9949 0.9936] 
VALID | loss: 0.0333 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9967 0.9972]
Epoch 38/40
TRAIN | loss: 0.0187 - global_acc: 0.9962 - class_acc: [1.0000 0.9954 0.9953 0.9941] 
VALID | loss: 0.0123 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9916 0.9960]
Epoch 39/40
TRAIN | loss: 0.0214 - global_acc: 0.9963 - class_acc: [1.0000 0.9942 0.9954 0.9955] 
VALID | loss: 0.0091 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9993 0.9856]
Epoch 40/40
TRAIN | loss: 0.0192 - global_acc: 0.9963 - class_acc: [0.9998 0.9952 0.9962 0.9941] 
VALID | loss: 0.0176 - global_acc: 0.9939 - class_acc: [1.0000 0.9987 1.0000 0.9771]


Evaluating...
TEST | loss: 0.2233 - global_acc: 0.9691 - class_acc: [0.0000 0.9974 1.0000 0.9258]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 21
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.4887 - global_acc: 0.8031 - class_acc: [0.7755 0.8456 0.8976 0.6938] 
VALID | loss: 0.1460 - global_acc: 0.9394 - class_acc: [1.0000 1.0000 0.7581 0.9952] - BEST!
Epoch 2/40
TRAIN | loss: 0.1117 - global_acc: 0.9656 - class_acc: [0.9991 0.9778 0.9350 0.9505] 
VALID | loss: 0.0661 - global_acc: 0.9769 - class_acc: [0.9993 1.0000 0.9336 0.9757] - BEST!
Epoch 3/40
TRAIN | loss: 0.0911 - global_acc: 0.9708 - class_acc: [0.9979 0.9794 0.9448 0.9613] 
VALID | loss: 0.0664 - global_acc: 0.9745 - class_acc: [1.0000 1.0000 0.9207 0.9783]
Epoch 4/40
TRAIN | loss: 0.0776 - global_acc: 0.9747 - class_acc: [0.9995 0.9811 0.9498 0.9678] 
VALID | loss: 0.0551 - global_acc: 0.9792 - class_acc: [0.9987 1.0000 0.9272 0.9891] - BEST!
Epoch 5/40
TRAIN | loss: 0.0579 - global_acc: 0.9819 - class_acc: [1.0000 0.9867 0.9654 0.9758] 
VALID | loss: 0.0487 - global_acc: 0.9837 - class_acc: [1.0000 1.0000 0.9421 0.9920] - BEST!
Epoch 6/40
TRAIN | loss: 0.0599 - global_acc: 0.9812 - class_acc: [0.9996 0.9835 0.9660 0.9752] 
VALID | loss: 0.0276 - global_acc: 0.9923 - class_acc: [1.0000 1.0000 0.9804 0.9889] - BEST!
Epoch 7/40
TRAIN | loss: 0.0553 - global_acc: 0.9821 - class_acc: [0.9993 0.9849 0.9657 0.9784] 
VALID | loss: 0.0257 - global_acc: 0.9913 - class_acc: [1.0000 0.9987 0.9742 0.9923]
Epoch 8/40
TRAIN | loss: 0.0524 - global_acc: 0.9833 - class_acc: [0.9984 0.9851 0.9707 0.9792] 
VALID | loss: 0.0424 - global_acc: 0.9835 - class_acc: [1.0000 1.0000 0.9368 0.9987]
Epoch 9/40
TRAIN | loss: 0.0447 - global_acc: 0.9863 - class_acc: [0.9989 0.9867 0.9734 0.9863] 
VALID | loss: 0.1467 - global_acc: 0.9603 - class_acc: [1.0000 1.0000 0.9628 0.8853]
Epoch 10/40
TRAIN | loss: 0.0464 - global_acc: 0.9851 - class_acc: [0.9998 0.9876 0.9683 0.9845] 
VALID | loss: 0.0154 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9869 0.9957] - BEST!
Epoch 11/40
TRAIN | loss: 0.0430 - global_acc: 0.9862 - class_acc: [0.9996 0.9885 0.9739 0.9825] 
VALID | loss: 0.0185 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 0.9780 0.9986]
Epoch 12/40
TRAIN | loss: 0.0410 - global_acc: 0.9859 - class_acc: [0.9998 0.9889 0.9714 0.9835] 
VALID | loss: 0.0676 - global_acc: 0.9799 - class_acc: [1.0000 1.0000 0.9290 0.9911]
Epoch 13/40
TRAIN | loss: 0.0315 - global_acc: 0.9898 - class_acc: [1.0000 0.9926 0.9793 0.9875] 
VALID | loss: 0.0118 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9883 0.9965] - BEST!
Epoch 14/40
TRAIN | loss: 0.0331 - global_acc: 0.9898 - class_acc: [0.9993 0.9910 0.9799 0.9890] 
VALID | loss: 0.0388 - global_acc: 0.9854 - class_acc: [1.0000 1.0000 0.9993 0.9419]
Epoch 15/40
TRAIN | loss: 0.0310 - global_acc: 0.9898 - class_acc: [0.9991 0.9937 0.9801 0.9865] 
VALID | loss: 0.2568 - global_acc: 0.9425 - class_acc: [0.9993 0.9979 0.8164 0.9540]
Epoch 16/40
TRAIN | loss: 0.0297 - global_acc: 0.9905 - class_acc: [0.9995 0.9926 0.9819 0.9878] 
VALID | loss: 0.0082 - global_acc: 0.9976 - class_acc: [1.0000 0.9993 0.9979 0.9935] - BEST!
Epoch 17/40
TRAIN | loss: 0.0310 - global_acc: 0.9915 - class_acc: [0.9998 0.9938 0.9833 0.9895] 
VALID | loss: 0.0192 - global_acc: 0.9935 - class_acc: [1.0000 1.0000 0.9967 0.9774]
Epoch 18/40
TRAIN | loss: 0.0289 - global_acc: 0.9929 - class_acc: [0.9993 0.9937 0.9877 0.9910] 
VALID | loss: 0.0149 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9914 0.9993]
Epoch 19/40
TRAIN | loss: 0.0271 - global_acc: 0.9928 - class_acc: [0.9998 0.9928 0.9880 0.9906] 
VALID | loss: 0.0160 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9906 0.9980]
Epoch 20/40
TRAIN | loss: 0.0247 - global_acc: 0.9939 - class_acc: [0.9991 0.9951 0.9920 0.9895] 
VALID | loss: 0.0147 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9974 0.9813]
Epoch 21/40
TRAIN | loss: 0.0241 - global_acc: 0.9936 - class_acc: [1.0000 0.9948 0.9902 0.9899] 
VALID | loss: 0.0123 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9945 0.9951]
Epoch 22/40
TRAIN | loss: 0.0273 - global_acc: 0.9926 - class_acc: [0.9986 0.9926 0.9901 0.9890] 
VALID | loss: 0.0438 - global_acc: 0.9864 - class_acc: [1.0000 1.0000 0.9473 0.9993]
Epoch 23/40
TRAIN | loss: 0.0222 - global_acc: 0.9947 - class_acc: [0.9993 0.9931 0.9925 0.9936] 
VALID | loss: 0.0089 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9980 0.9936] - BEST!
Epoch 24/40
TRAIN | loss: 0.0214 - global_acc: 0.9938 - class_acc: [1.0000 0.9936 0.9902 0.9913] 
VALID | loss: 0.0110 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9959 0.9911]
Epoch 25/40
TRAIN | loss: 0.0192 - global_acc: 0.9952 - class_acc: [0.9998 0.9941 0.9942 0.9930] 
VALID | loss: 0.0101 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9877 1.0000]
Epoch 26/40
TRAIN | loss: 0.0189 - global_acc: 0.9956 - class_acc: [0.9995 0.9950 0.9925 0.9954] 
VALID | loss: 0.0087 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9986 0.9925]
Epoch 27/40
TRAIN | loss: 0.0230 - global_acc: 0.9950 - class_acc: [1.0000 0.9933 0.9941 0.9927] 
VALID | loss: 0.0236 - global_acc: 0.9925 - class_acc: [1.0000 1.0000 0.9694 1.0000]
Epoch 28/40
TRAIN | loss: 0.0186 - global_acc: 0.9966 - class_acc: [0.9998 0.9967 0.9954 0.9944] 
VALID | loss: 0.0117 - global_acc: 0.9963 - class_acc: [1.0000 0.9993 0.9986 0.9874]
Epoch 29/40
TRAIN | loss: 0.0145 - global_acc: 0.9966 - class_acc: [0.9998 0.9963 0.9956 0.9947] 
VALID | loss: 0.0045 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9961 0.9980] - BEST!
Epoch 30/40
TRAIN | loss: 0.0197 - global_acc: 0.9955 - class_acc: [0.9998 0.9947 0.9942 0.9934] 
VALID | loss: 0.0205 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 0.9951 0.9753]
Epoch 31/40
TRAIN | loss: 0.0149 - global_acc: 0.9968 - class_acc: [0.9998 0.9959 0.9971 0.9943] 
VALID | loss: 0.0063 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9958 0.9944]
Epoch 32/40
TRAIN | loss: 0.0172 - global_acc: 0.9959 - class_acc: [0.9998 0.9948 0.9955 0.9934] 
VALID | loss: 0.0065 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9959 0.9952]
Epoch 33/40
TRAIN | loss: 0.0187 - global_acc: 0.9959 - class_acc: [0.9998 0.9955 0.9937 0.9945] 
VALID | loss: 0.0764 - global_acc: 0.9765 - class_acc: [1.0000 1.0000 0.9082 0.9980]
Epoch 34/40
TRAIN | loss: 0.0229 - global_acc: 0.9955 - class_acc: [0.9993 0.9949 0.9948 0.9928] 
VALID | loss: 0.0160 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9980 0.9833]
Epoch 35/40
TRAIN | loss: 0.0156 - global_acc: 0.9964 - class_acc: [0.9998 0.9959 0.9959 0.9941] 
VALID | loss: 0.0169 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9953 0.9924]
Epoch 36/40
TRAIN | loss: 0.0197 - global_acc: 0.9957 - class_acc: [1.0000 0.9941 0.9946 0.9945] 
VALID | loss: 0.0055 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9986 0.9966] - BEST!
Epoch 37/40
TRAIN | loss: 0.0153 - global_acc: 0.9970 - class_acc: [1.0000 0.9973 0.9956 0.9950] 
VALID | loss: 0.0117 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9939 0.9980]
Epoch 38/40
TRAIN | loss: 0.0204 - global_acc: 0.9959 - class_acc: [0.9991 0.9939 0.9959 0.9945] 
VALID | loss: 0.0110 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9959 0.9981]
Epoch 39/40
TRAIN | loss: 0.0168 - global_acc: 0.9960 - class_acc: [0.9993 0.9938 0.9957 0.9952] 
VALID | loss: 0.0086 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9973 0.9987] - BEST!
Epoch 40/40
TRAIN | loss: 0.0151 - global_acc: 0.9964 - class_acc: [0.9995 0.9951 0.9959 0.9952] 
VALID | loss: 0.0118 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9946 0.9979]


Evaluating...
TEST | loss: 0.1192 - global_acc: 0.9527 - class_acc: [1.0000 1.0000 0.9990 0.8836]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 22
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5835 - global_acc: 0.7332 - class_acc: [0.9568 0.8637 0.5492 0.5598] 
VALID | loss: 0.1747 - global_acc: 0.9411 - class_acc: [0.9980 0.9986 0.7741 0.9763] - BEST!
Epoch 2/40
TRAIN | loss: 0.1389 - global_acc: 0.9596 - class_acc: [0.9861 0.9830 0.9594 0.9093] 
VALID | loss: 0.1285 - global_acc: 0.9491 - class_acc: [0.9993 1.0000 0.9902 0.8040] - BEST!
Epoch 3/40
TRAIN | loss: 0.0946 - global_acc: 0.9722 - class_acc: [0.9879 0.9859 0.9756 0.9396] 
VALID | loss: 0.0629 - global_acc: 0.9772 - class_acc: [0.9979 1.0000 0.9764 0.9350] - BEST!
Epoch 4/40
TRAIN | loss: 0.0786 - global_acc: 0.9767 - class_acc: [0.9857 0.9859 0.9781 0.9571] 
VALID | loss: 0.0516 - global_acc: 0.9806 - class_acc: [0.9973 1.0000 0.9447 0.9813] - BEST!
Epoch 5/40
TRAIN | loss: 0.0654 - global_acc: 0.9825 - class_acc: [0.9917 0.9881 0.9839 0.9661] 
VALID | loss: 0.0306 - global_acc: 0.9896 - class_acc: [1.0000 1.0000 0.9810 0.9781] - BEST!
Epoch 6/40
TRAIN | loss: 0.0534 - global_acc: 0.9850 - class_acc: [0.9885 0.9893 0.9874 0.9750] 
VALID | loss: 0.0699 - global_acc: 0.9751 - class_acc: [0.9993 1.0000 0.9965 0.9089]
Epoch 7/40
TRAIN | loss: 0.0513 - global_acc: 0.9859 - class_acc: [0.9893 0.9888 0.9895 0.9759] 
VALID | loss: 0.0250 - global_acc: 0.9932 - class_acc: [0.9993 1.0000 0.9870 0.9865] - BEST!
Epoch 8/40
TRAIN | loss: 0.0476 - global_acc: 0.9877 - class_acc: [0.9917 0.9914 0.9906 0.9771] 
VALID | loss: 0.0320 - global_acc: 0.9881 - class_acc: [1.0000 1.0000 0.9677 0.9854]
Epoch 9/40
TRAIN | loss: 0.0391 - global_acc: 0.9885 - class_acc: [0.9936 0.9904 0.9903 0.9798] 
VALID | loss: 0.0576 - global_acc: 0.9814 - class_acc: [0.9959 1.0000 0.9958 0.9349]
Epoch 10/40
TRAIN | loss: 0.0442 - global_acc: 0.9893 - class_acc: [0.9927 0.9897 0.9907 0.9840] 
VALID | loss: 0.0250 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9900 0.9873] - BEST!
Epoch 11/40
TRAIN | loss: 0.0326 - global_acc: 0.9911 - class_acc: [0.9942 0.9928 0.9925 0.9849] 
VALID | loss: 0.0273 - global_acc: 0.9886 - class_acc: [1.0000 0.9993 0.9570 0.9980]
Epoch 12/40
TRAIN | loss: 0.0333 - global_acc: 0.9913 - class_acc: [0.9966 0.9901 0.9929 0.9855] 
VALID | loss: 0.0191 - global_acc: 0.9934 - class_acc: [0.9993 1.0000 0.9900 0.9843]
Epoch 13/40
TRAIN | loss: 0.0303 - global_acc: 0.9919 - class_acc: [0.9948 0.9904 0.9930 0.9893] 
VALID | loss: 0.0200 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 0.9724 0.9993]
Epoch 14/40
TRAIN | loss: 0.0291 - global_acc: 0.9921 - class_acc: [0.9957 0.9922 0.9933 0.9871] 
VALID | loss: 0.0530 - global_acc: 0.9831 - class_acc: [1.0000 1.0000 0.9980 0.9350]
Epoch 15/40
TRAIN | loss: 0.0269 - global_acc: 0.9933 - class_acc: [0.9956 0.9943 0.9944 0.9887] 
VALID | loss: 0.0186 - global_acc: 0.9966 - class_acc: [1.0000 0.9993 0.9960 0.9912] - BEST!
Epoch 16/40
TRAIN | loss: 0.0246 - global_acc: 0.9942 - class_acc: [0.9956 0.9949 0.9959 0.9904] 
VALID | loss: 0.0142 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9946 0.9902]
Epoch 17/40
TRAIN | loss: 0.0235 - global_acc: 0.9944 - class_acc: [0.9968 0.9957 0.9943 0.9910] 
VALID | loss: 0.0292 - global_acc: 0.9923 - class_acc: [1.0000 1.0000 0.9993 0.9691]
Epoch 18/40
TRAIN | loss: 0.0239 - global_acc: 0.9943 - class_acc: [0.9973 0.9951 0.9946 0.9900] 
VALID | loss: 0.0116 - global_acc: 0.9971 - class_acc: [0.9994 1.0000 0.9950 0.9939] - BEST!
Epoch 19/40
TRAIN | loss: 0.0214 - global_acc: 0.9944 - class_acc: [0.9968 0.9937 0.9959 0.9913] 
VALID | loss: 0.0213 - global_acc: 0.9932 - class_acc: [0.9994 0.9993 0.9798 0.9945]
Epoch 20/40
TRAIN | loss: 0.0189 - global_acc: 0.9951 - class_acc: [0.9979 0.9941 0.9952 0.9931] 
VALID | loss: 0.0103 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9891 0.9993]
Epoch 21/40
TRAIN | loss: 0.0174 - global_acc: 0.9954 - class_acc: [0.9964 0.9945 0.9959 0.9948] 
VALID | loss: 0.0122 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9973 0.9886]
Epoch 22/40
TRAIN | loss: 0.0218 - global_acc: 0.9946 - class_acc: [0.9968 0.9925 0.9959 0.9932] 
VALID | loss: 0.0189 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9993 0.9826]
Epoch 23/40
TRAIN | loss: 0.0214 - global_acc: 0.9944 - class_acc: [0.9961 0.9937 0.9950 0.9926] 
VALID | loss: 0.0128 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9948 0.9899]
Epoch 24/40
TRAIN | loss: 0.0190 - global_acc: 0.9949 - class_acc: [0.9975 0.9937 0.9949 0.9936] 
VALID | loss: 0.0078 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9973 0.9946] - BEST!
Epoch 25/40
TRAIN | loss: 0.0192 - global_acc: 0.9956 - class_acc: [0.9989 0.9942 0.9952 0.9940] 
VALID | loss: 0.0112 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9980 0.9918]
Epoch 26/40
TRAIN | loss: 0.0121 - global_acc: 0.9969 - class_acc: [0.9984 0.9962 0.9977 0.9953] 
VALID | loss: 0.0051 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9980 0.9980] - BEST!
Epoch 27/40
TRAIN | loss: 0.0166 - global_acc: 0.9962 - class_acc: [0.9970 0.9953 0.9961 0.9964] 
VALID | loss: 0.0064 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9966 0.9993]
Epoch 28/40
TRAIN | loss: 0.0234 - global_acc: 0.9944 - class_acc: [0.9962 0.9957 0.9926 0.9931] 
VALID | loss: 0.0120 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9880 0.9993]
Epoch 29/40
TRAIN | loss: 0.0163 - global_acc: 0.9965 - class_acc: [0.9989 0.9982 0.9952 0.9939] 
VALID | loss: 0.0112 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9979 0.9940]
Epoch 30/40
TRAIN | loss: 0.0142 - global_acc: 0.9966 - class_acc: [0.9967 0.9948 0.9986 0.9964] 
VALID | loss: 0.0059 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9959 0.9973]
Epoch 31/40
TRAIN | loss: 0.0169 - global_acc: 0.9959 - class_acc: [0.9971 0.9949 0.9966 0.9951] 
VALID | loss: 0.0121 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9993 0.9926]
Epoch 32/40
TRAIN | loss: 0.0127 - global_acc: 0.9973 - class_acc: [0.9975 0.9975 0.9985 0.9958] 
VALID | loss: 0.0109 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9993 0.9904]
Epoch 33/40
TRAIN | loss: 0.0138 - global_acc: 0.9966 - class_acc: [0.9986 0.9950 0.9973 0.9954] 
VALID | loss: 0.0101 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9852 1.0000]
Epoch 34/40
TRAIN | loss: 0.0114 - global_acc: 0.9971 - class_acc: [0.9972 0.9976 0.9977 0.9959] 
VALID | loss: 0.0056 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9986 0.9959]
Epoch 35/40
TRAIN | loss: 0.0115 - global_acc: 0.9969 - class_acc: [0.9982 0.9966 0.9966 0.9961] 
VALID | loss: 0.0100 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9973 0.9939]
Epoch 36/40
TRAIN | loss: 0.0123 - global_acc: 0.9971 - class_acc: [0.9973 0.9977 0.9971 0.9964] 
VALID | loss: 0.0225 - global_acc: 0.9917 - class_acc: [1.0000 1.0000 0.9724 0.9947]
Epoch 37/40
TRAIN | loss: 0.0149 - global_acc: 0.9972 - class_acc: [0.9977 0.9975 0.9965 0.9969] 
VALID | loss: 0.0077 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9946 0.9960]
Epoch 38/40
TRAIN | loss: 0.0212 - global_acc: 0.9951 - class_acc: [0.9959 0.9970 0.9946 0.9928] 
VALID | loss: 0.0368 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9974 0.9774]
Epoch 39/40
TRAIN | loss: 0.0113 - global_acc: 0.9973 - class_acc: [0.9987 0.9975 0.9972 0.9960] 
VALID | loss: 0.0100 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9851 1.0000]
Epoch 40/40
TRAIN | loss: 0.0130 - global_acc: 0.9969 - class_acc: [0.9956 0.9965 0.9978 0.9978] 
VALID | loss: 0.0044 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9966 0.9979]


Evaluating...
TEST | loss: 0.4106 - global_acc: 0.9126 - class_acc: [1.0000 1.0000 0.9964 0.7862]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 23
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.6101 - global_acc: 0.7070 - class_acc: [0.8787 0.5546 0.8523 0.5414] 
VALID | loss: 0.1264 - global_acc: 0.9513 - class_acc: [0.9973 1.0000 0.8389 0.9687] - BEST!
Epoch 2/40
TRAIN | loss: 0.1603 - global_acc: 0.9322 - class_acc: [0.9811 0.9379 0.9245 0.8848] 
VALID | loss: 0.0831 - global_acc: 0.9731 - class_acc: [0.9993 1.0000 0.9090 0.9825] - BEST!
Epoch 3/40
TRAIN | loss: 0.1319 - global_acc: 0.9496 - class_acc: [0.9576 0.9660 0.9422 0.9323] 
VALID | loss: 0.0872 - global_acc: 0.9656 - class_acc: [1.0000 1.0000 0.8722 0.9959]
Epoch 4/40
TRAIN | loss: 0.0964 - global_acc: 0.9659 - class_acc: [0.9648 0.9760 0.9621 0.9608] 
VALID | loss: 0.0531 - global_acc: 0.9831 - class_acc: [0.9980 1.0000 0.9480 0.9865] - BEST!
Epoch 5/40
TRAIN | loss: 0.0885 - global_acc: 0.9694 - class_acc: [0.9669 0.9768 0.9637 0.9702] 
VALID | loss: 0.0637 - global_acc: 0.9762 - class_acc: [1.0000 1.0000 0.9930 0.9130]
Epoch 6/40
TRAIN | loss: 0.0782 - global_acc: 0.9749 - class_acc: [0.9727 0.9759 0.9704 0.9808] 
VALID | loss: 0.1204 - global_acc: 0.9449 - class_acc: [0.9993 1.0000 0.7791 0.9993]
Epoch 7/40
TRAIN | loss: 0.0728 - global_acc: 0.9756 - class_acc: [0.9813 0.9741 0.9671 0.9795] 
VALID | loss: 0.0256 - global_acc: 0.9917 - class_acc: [1.0000 1.0000 0.9863 0.9798] - BEST!
Epoch 8/40
TRAIN | loss: 0.0688 - global_acc: 0.9763 - class_acc: [0.9848 0.9733 0.9688 0.9783] 
VALID | loss: 0.0478 - global_acc: 0.9830 - class_acc: [1.0000 1.0000 0.9334 0.9966]
Epoch 9/40
TRAIN | loss: 0.0596 - global_acc: 0.9803 - class_acc: [0.9846 0.9763 0.9775 0.9826] 
VALID | loss: 0.0836 - global_acc: 0.9658 - class_acc: [1.0000 1.0000 0.8639 0.9993]
Epoch 10/40
TRAIN | loss: 0.0587 - global_acc: 0.9818 - class_acc: [0.9905 0.9795 0.9724 0.9847] 
VALID | loss: 0.0400 - global_acc: 0.9849 - class_acc: [0.9986 1.0000 0.9550 0.9861]
Epoch 11/40
TRAIN | loss: 0.0546 - global_acc: 0.9798 - class_acc: [0.9859 0.9748 0.9747 0.9837] 
VALID | loss: 0.0217 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9785 0.9926] - BEST!
Epoch 12/40
TRAIN | loss: 0.0606 - global_acc: 0.9792 - class_acc: [0.9867 0.9707 0.9763 0.9830] 
VALID | loss: 0.0882 - global_acc: 0.9644 - class_acc: [0.9986 1.0000 0.8613 1.0000]
Epoch 13/40
TRAIN | loss: 0.0526 - global_acc: 0.9800 - class_acc: [0.9811 0.9714 0.9812 0.9866] 
VALID | loss: 0.0462 - global_acc: 0.9804 - class_acc: [1.0000 1.0000 0.9220 1.0000]
Epoch 14/40
TRAIN | loss: 0.0537 - global_acc: 0.9799 - class_acc: [0.9928 0.9743 0.9717 0.9808] 
VALID | loss: 0.0213 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9749 0.9979] - BEST!
Epoch 15/40
TRAIN | loss: 0.0587 - global_acc: 0.9817 - class_acc: [0.9907 0.9737 0.9768 0.9857] 
VALID | loss: 0.0209 - global_acc: 0.9956 - class_acc: [0.9993 1.0000 0.9834 0.9993] - BEST!
Epoch 16/40
TRAIN | loss: 0.0502 - global_acc: 0.9806 - class_acc: [0.9869 0.9683 0.9809 0.9861] 
VALID | loss: 0.0327 - global_acc: 0.9881 - class_acc: [0.9986 1.0000 0.9546 0.9993]
Epoch 17/40
TRAIN | loss: 0.0481 - global_acc: 0.9840 - class_acc: [0.9924 0.9729 0.9844 0.9861] 
VALID | loss: 0.0148 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9873 0.9986] - BEST!
Epoch 18/40
TRAIN | loss: 0.0436 - global_acc: 0.9836 - class_acc: [0.9907 0.9733 0.9826 0.9879] 
VALID | loss: 0.0217 - global_acc: 0.9927 - class_acc: [1.0000 1.0000 0.9722 0.9987]
Epoch 19/40
TRAIN | loss: 0.0437 - global_acc: 0.9834 - class_acc: [0.9885 0.9724 0.9843 0.9884] 
VALID | loss: 0.0081 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9993 0.9918] - BEST!
Epoch 20/40
TRAIN | loss: 0.0374 - global_acc: 0.9847 - class_acc: [0.9885 0.9695 0.9900 0.9910] 
VALID | loss: 0.0132 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9910 0.9921]
Epoch 21/40
TRAIN | loss: 0.0433 - global_acc: 0.9836 - class_acc: [0.9887 0.9711 0.9857 0.9886] 
VALID | loss: 0.0425 - global_acc: 0.9864 - class_acc: [0.9993 1.0000 0.9459 1.0000]
Epoch 22/40
TRAIN | loss: 0.0477 - global_acc: 0.9824 - class_acc: [0.9878 0.9695 0.9842 0.9885] 
VALID | loss: 0.0376 - global_acc: 0.9900 - class_acc: [1.0000 1.0000 0.9614 1.0000]
Epoch 23/40
TRAIN | loss: 0.0391 - global_acc: 0.9855 - class_acc: [0.9903 0.9713 0.9878 0.9923] 
VALID | loss: 0.0127 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9896 0.9925]
Epoch 24/40
TRAIN | loss: 0.0433 - global_acc: 0.9846 - class_acc: [0.9928 0.9713 0.9831 0.9909] 
VALID | loss: 0.0312 - global_acc: 0.9905 - class_acc: [1.0000 1.0000 0.9993 0.9635]
Epoch 25/40
TRAIN | loss: 0.0410 - global_acc: 0.9853 - class_acc: [0.9925 0.9713 0.9884 0.9884] 
VALID | loss: 0.0283 - global_acc: 0.9905 - class_acc: [1.0000 1.0000 0.9610 1.0000]
Epoch 26/40
TRAIN | loss: 0.0386 - global_acc: 0.9860 - class_acc: [0.9936 0.9733 0.9866 0.9911] 
VALID | loss: 0.0308 - global_acc: 0.9934 - class_acc: [0.9987 1.0000 0.9777 0.9980]
Epoch 27/40
TRAIN | loss: 0.0409 - global_acc: 0.9861 - class_acc: [0.9937 0.9732 0.9859 0.9914] 
VALID | loss: 0.0697 - global_acc: 0.9751 - class_acc: [1.0000 1.0000 0.9031 1.0000]
Epoch 28/40
TRAIN | loss: 0.0370 - global_acc: 0.9866 - class_acc: [0.9953 0.9705 0.9868 0.9936] 
VALID | loss: 0.0406 - global_acc: 0.9871 - class_acc: [0.9993 1.0000 0.9474 1.0000]
Epoch 29/40
TRAIN | loss: 0.0384 - global_acc: 0.9867 - class_acc: [0.9946 0.9722 0.9877 0.9917] 
VALID | loss: 0.0309 - global_acc: 0.9923 - class_acc: [0.9993 1.0000 0.9706 1.0000]
Epoch 30/40
TRAIN | loss: 0.0323 - global_acc: 0.9881 - class_acc: [0.9950 0.9747 0.9885 0.9947] 
VALID | loss: 0.0137 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9860 1.0000]
Epoch 31/40
TRAIN | loss: 0.0361 - global_acc: 0.9870 - class_acc: [0.9937 0.9719 0.9897 0.9933] 
VALID | loss: 0.0131 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9897 0.9987]
Epoch 32/40
TRAIN | loss: 0.0336 - global_acc: 0.9869 - class_acc: [0.9948 0.9706 0.9918 0.9908] 
VALID | loss: 0.0558 - global_acc: 0.9809 - class_acc: [1.0000 1.0000 0.9256 0.9980]
Epoch 33/40
TRAIN | loss: 0.0421 - global_acc: 0.9828 - class_acc: [0.9897 0.9673 0.9822 0.9917] 
VALID | loss: 0.0210 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9917 1.0000] - BEST!
Epoch 34/40
TRAIN | loss: 0.0325 - global_acc: 0.9869 - class_acc: [0.9952 0.9689 0.9883 0.9950] 
VALID | loss: 0.0548 - global_acc: 0.9772 - class_acc: [1.0000 1.0000 0.9112 0.9986]
Epoch 35/40
TRAIN | loss: 0.0377 - global_acc: 0.9840 - class_acc: [0.9884 0.9669 0.9893 0.9918] 
VALID | loss: 0.0802 - global_acc: 0.9700 - class_acc: [1.0000 1.0000 0.8809 1.0000]
Epoch 36/40
TRAIN | loss: 0.0358 - global_acc: 0.9877 - class_acc: [0.9980 0.9712 0.9899 0.9916] 
VALID | loss: 0.1180 - global_acc: 0.9534 - class_acc: [1.0000 1.0000 0.8177 0.9986]
Epoch 37/40
TRAIN | loss: 0.0332 - global_acc: 0.9874 - class_acc: [0.9968 0.9696 0.9889 0.9939] 
VALID | loss: 0.0265 - global_acc: 0.9911 - class_acc: [0.9986 1.0000 0.9673 1.0000]
Epoch 38/40
TRAIN | loss: 0.0397 - global_acc: 0.9866 - class_acc: [0.9957 0.9699 0.9887 0.9916] 
VALID | loss: 0.0753 - global_acc: 0.9746 - class_acc: [0.9993 1.0000 0.8917 1.0000]
Epoch 39/40
TRAIN | loss: 0.0396 - global_acc: 0.9859 - class_acc: [0.9955 0.9693 0.9878 0.9912] 
VALID | loss: 0.1827 - global_acc: 0.8878 - class_acc: [0.9993 1.0000 0.5657 1.0000]
Epoch 40/40
TRAIN | loss: 0.0375 - global_acc: 0.9878 - class_acc: [0.9980 0.9711 0.9885 0.9936] 
VALID | loss: 0.0433 - global_acc: 0.9913 - class_acc: [0.9993 1.0000 0.9684 0.9980]


Evaluating...
TEST | loss: 0.0495 - global_acc: 0.9898 - class_acc: [1.0000 1.0000 0.9995 0.9751]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 24
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5377 - global_acc: 0.7867 - class_acc: [0.8555 0.7367 0.7396 0.8146] 
VALID | loss: 0.1332 - global_acc: 0.9501 - class_acc: [1.0000 0.9993 0.8215 0.9826] - BEST!
Epoch 2/40
TRAIN | loss: 0.1373 - global_acc: 0.9539 - class_acc: [0.9984 0.9586 0.9417 0.9159] 
VALID | loss: 0.1056 - global_acc: 0.9627 - class_acc: [0.9993 1.0000 0.8675 0.9876] - BEST!
Epoch 3/40
TRAIN | loss: 0.1001 - global_acc: 0.9651 - class_acc: [0.9991 0.9647 0.9591 0.9384] 
VALID | loss: 0.0464 - global_acc: 0.9845 - class_acc: [1.0000 1.0000 0.9630 0.9760] - BEST!
Epoch 4/40
TRAIN | loss: 0.0818 - global_acc: 0.9724 - class_acc: [0.9993 0.9660 0.9668 0.9575] 
VALID | loss: 0.1869 - global_acc: 0.9300 - class_acc: [0.9993 1.0000 0.7279 1.0000]
Epoch 5/40
TRAIN | loss: 0.0807 - global_acc: 0.9736 - class_acc: [0.9986 0.9641 0.9681 0.9642] 
VALID | loss: 0.0254 - global_acc: 0.9918 - class_acc: [1.0000 1.0000 0.9798 0.9880] - BEST!
Epoch 6/40
TRAIN | loss: 0.0706 - global_acc: 0.9750 - class_acc: [0.9989 0.9627 0.9695 0.9691] 
VALID | loss: 0.0315 - global_acc: 0.9874 - class_acc: [1.0000 1.0000 0.9933 0.9566]
Epoch 7/40
TRAIN | loss: 0.0581 - global_acc: 0.9799 - class_acc: [0.9995 0.9633 0.9766 0.9801] 
VALID | loss: 0.0313 - global_acc: 0.9894 - class_acc: [1.0000 1.0000 0.9701 0.9876]
Epoch 8/40
TRAIN | loss: 0.0663 - global_acc: 0.9800 - class_acc: [0.9986 0.9680 0.9738 0.9803] 
VALID | loss: 0.0223 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9911 0.9803] - BEST!
Epoch 9/40
TRAIN | loss: 0.0549 - global_acc: 0.9821 - class_acc: [0.9993 0.9664 0.9771 0.9853] 
VALID | loss: 0.0353 - global_acc: 0.9900 - class_acc: [1.0000 1.0000 0.9698 0.9897]
Epoch 10/40
TRAIN | loss: 0.0461 - global_acc: 0.9854 - class_acc: [0.9998 0.9738 0.9788 0.9891] 
VALID | loss: 0.0245 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9731 1.0000] - BEST!
Epoch 11/40
TRAIN | loss: 0.0464 - global_acc: 0.9845 - class_acc: [0.9991 0.9663 0.9836 0.9892] 
VALID | loss: 0.0188 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9824 1.0000] - BEST!
Epoch 12/40
TRAIN | loss: 0.0489 - global_acc: 0.9837 - class_acc: [0.9989 0.9626 0.9837 0.9898] 
VALID | loss: 0.0132 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9884 0.9945] - BEST!
Epoch 13/40
TRAIN | loss: 0.0436 - global_acc: 0.9866 - class_acc: [0.9998 0.9705 0.9848 0.9909] 
VALID | loss: 0.0185 - global_acc: 0.9946 - class_acc: [1.0000 0.9993 0.9843 0.9946]
Epoch 14/40
TRAIN | loss: 0.0430 - global_acc: 0.9858 - class_acc: [0.9991 0.9672 0.9848 0.9914] 
VALID | loss: 0.0201 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9810 0.9980]
Epoch 15/40
TRAIN | loss: 0.0386 - global_acc: 0.9880 - class_acc: [0.9995 0.9708 0.9876 0.9941] 
VALID | loss: 0.0782 - global_acc: 0.9753 - class_acc: [1.0000 1.0000 0.8980 1.0000]
Epoch 16/40
TRAIN | loss: 0.0424 - global_acc: 0.9858 - class_acc: [0.9986 0.9674 0.9857 0.9916] 
VALID | loss: 0.0264 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9785 1.0000]
Epoch 17/40
TRAIN | loss: 0.0385 - global_acc: 0.9872 - class_acc: [0.9995 0.9694 0.9874 0.9924] 
VALID | loss: 0.0161 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9868 0.9980] - BEST!
Epoch 18/40
TRAIN | loss: 0.0348 - global_acc: 0.9878 - class_acc: [1.0000 0.9668 0.9902 0.9948] 
VALID | loss: 0.0142 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9850 0.9987]
Epoch 19/40
TRAIN | loss: 0.0373 - global_acc: 0.9867 - class_acc: [0.9984 0.9685 0.9876 0.9928] 
VALID | loss: 0.0215 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9808 0.9986]
Epoch 20/40
TRAIN | loss: 0.0358 - global_acc: 0.9877 - class_acc: [0.9982 0.9702 0.9878 0.9944] 
VALID | loss: 0.0820 - global_acc: 0.9743 - class_acc: [1.0000 1.0000 0.8927 1.0000]
Epoch 21/40
TRAIN | loss: 0.0404 - global_acc: 0.9863 - class_acc: [0.9980 0.9688 0.9863 0.9920] 
VALID | loss: 0.0256 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9777 0.9979]
Epoch 22/40
TRAIN | loss: 0.0369 - global_acc: 0.9880 - class_acc: [0.9995 0.9697 0.9887 0.9942] 
VALID | loss: 0.0169 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9953 0.9797]
Epoch 23/40
TRAIN | loss: 0.0346 - global_acc: 0.9874 - class_acc: [0.9998 0.9664 0.9887 0.9945] 
VALID | loss: 0.0113 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9951 0.9967] - BEST!
Epoch 24/40
TRAIN | loss: 0.0315 - global_acc: 0.9890 - class_acc: [0.9998 0.9736 0.9875 0.9948] 
VALID | loss: 0.0694 - global_acc: 0.9818 - class_acc: [1.0000 1.0000 0.9273 1.0000]
Epoch 25/40
TRAIN | loss: 0.0338 - global_acc: 0.9881 - class_acc: [0.9998 0.9704 0.9874 0.9957] 
VALID | loss: 0.0129 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9892 0.9993]
Epoch 26/40
TRAIN | loss: 0.0359 - global_acc: 0.9874 - class_acc: [0.9991 0.9678 0.9889 0.9931] 
VALID | loss: 0.0049 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9987 0.9987] - BEST!
Epoch 27/40
TRAIN | loss: 0.0328 - global_acc: 0.9886 - class_acc: [0.9998 0.9708 0.9890 0.9948] 
VALID | loss: 0.0155 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9863 0.9993]
Epoch 28/40
TRAIN | loss: 0.0351 - global_acc: 0.9875 - class_acc: [0.9995 0.9650 0.9903 0.9950] 
VALID | loss: 0.0137 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9896 0.9986]
Epoch 29/40
TRAIN | loss: 0.0344 - global_acc: 0.9867 - class_acc: [0.9979 0.9619 0.9918 0.9944] 
VALID | loss: 0.0197 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9838 0.9979]
Epoch 30/40
TRAIN | loss: 0.0303 - global_acc: 0.9876 - class_acc: [0.9995 0.9667 0.9907 0.9939] 
VALID | loss: 0.0408 - global_acc: 0.9883 - class_acc: [1.0000 1.0000 0.9537 1.0000]
Epoch 31/40
TRAIN | loss: 0.0335 - global_acc: 0.9888 - class_acc: [1.0000 0.9702 0.9900 0.9952] 
VALID | loss: 0.0079 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9940 0.9993]
Epoch 32/40
TRAIN | loss: 0.0278 - global_acc: 0.9896 - class_acc: [0.9984 0.9721 0.9921 0.9952] 
VALID | loss: 0.0121 - global_acc: 0.9974 - class_acc: [1.0000 0.9993 0.9913 0.9993]
Epoch 33/40
TRAIN | loss: 0.0391 - global_acc: 0.9876 - class_acc: [0.9995 0.9685 0.9876 0.9945] 
VALID | loss: 0.0249 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9803 1.0000]
Epoch 34/40
TRAIN | loss: 0.0309 - global_acc: 0.9891 - class_acc: [1.0000 0.9691 0.9925 0.9952] 
VALID | loss: 0.0075 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9979 0.9986]
Epoch 35/40
TRAIN | loss: 0.0299 - global_acc: 0.9892 - class_acc: [0.9998 0.9699 0.9909 0.9964] 
VALID | loss: 0.0351 - global_acc: 0.9929 - class_acc: [1.0000 1.0000 0.9717 1.0000]
Epoch 36/40
TRAIN | loss: 0.0322 - global_acc: 0.9889 - class_acc: [0.9998 0.9688 0.9915 0.9948] 
VALID | loss: 0.0310 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9757 1.0000]
Epoch 37/40
TRAIN | loss: 0.0295 - global_acc: 0.9890 - class_acc: [0.9995 0.9674 0.9916 0.9975] 
VALID | loss: 0.0166 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9834 1.0000]
Epoch 38/40
TRAIN | loss: 0.0299 - global_acc: 0.9888 - class_acc: [1.0000 0.9701 0.9896 0.9959] 
VALID | loss: 0.0242 - global_acc: 0.9946 - class_acc: [1.0000 0.9993 0.9792 1.0000]
Epoch 39/40
TRAIN | loss: 0.0350 - global_acc: 0.9866 - class_acc: [0.9986 0.9653 0.9884 0.9945] 
VALID | loss: 0.0239 - global_acc: 0.9952 - class_acc: [1.0000 0.9993 0.9813 1.0000]
Epoch 40/40
TRAIN | loss: 0.0335 - global_acc: 0.9877 - class_acc: [0.9998 0.9667 0.9894 0.9943] 
VALID | loss: 0.0044 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9959 0.9993]


Evaluating...
TEST | loss: 0.0892 - global_acc: 0.9776 - class_acc: [0.0000 1.0000 1.0000 0.9452]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 25
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5423 - global_acc: 0.7732 - class_acc: [0.8253 0.9810 0.6841 0.6039] 
VALID | loss: 0.1424 - global_acc: 0.9493 - class_acc: [0.9954 0.9986 0.9498 0.8532] - BEST!
Epoch 2/40
TRAIN | loss: 0.1080 - global_acc: 0.9677 - class_acc: [0.9973 0.9852 0.9295 0.9588] 
VALID | loss: 0.0684 - global_acc: 0.9750 - class_acc: [0.9993 1.0000 0.9122 0.9869] - BEST!
Epoch 3/40
TRAIN | loss: 0.0740 - global_acc: 0.9810 - class_acc: [0.9995 0.9878 0.9615 0.9752] 
VALID | loss: 0.0378 - global_acc: 0.9862 - class_acc: [1.0000 1.0000 0.9685 0.9783] - BEST!
Epoch 4/40
TRAIN | loss: 0.0626 - global_acc: 0.9830 - class_acc: [0.9986 0.9906 0.9673 0.9758] 
VALID | loss: 0.0286 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9849 0.9911] - BEST!
Epoch 5/40
TRAIN | loss: 0.0530 - global_acc: 0.9863 - class_acc: [0.9993 0.9908 0.9740 0.9813] 
VALID | loss: 0.0319 - global_acc: 0.9884 - class_acc: [1.0000 1.0000 0.9556 0.9979]
Epoch 6/40
TRAIN | loss: 0.0487 - global_acc: 0.9887 - class_acc: [0.9986 0.9910 0.9798 0.9855] 
VALID | loss: 0.0218 - global_acc: 0.9932 - class_acc: [1.0000 1.0000 0.9762 0.9966]
Epoch 7/40
TRAIN | loss: 0.0450 - global_acc: 0.9891 - class_acc: [0.9996 0.9900 0.9812 0.9853] 
VALID | loss: 0.0143 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9904 0.9960] - BEST!
Epoch 8/40
TRAIN | loss: 0.0479 - global_acc: 0.9888 - class_acc: [0.9995 0.9892 0.9805 0.9861] 
VALID | loss: 0.0171 - global_acc: 0.9940 - class_acc: [0.9993 1.0000 0.9876 0.9889]
Epoch 9/40
TRAIN | loss: 0.0392 - global_acc: 0.9900 - class_acc: [0.9998 0.9878 0.9853 0.9870] 
VALID | loss: 0.0151 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9911 0.9903]
Epoch 10/40
TRAIN | loss: 0.0400 - global_acc: 0.9909 - class_acc: [0.9998 0.9906 0.9852 0.9880] 
VALID | loss: 0.0154 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9918 0.9966] - BEST!
Epoch 11/40
TRAIN | loss: 0.0393 - global_acc: 0.9912 - class_acc: [0.9996 0.9903 0.9859 0.9884] 
VALID | loss: 0.0175 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9867 0.9967]
Epoch 12/40
TRAIN | loss: 0.0321 - global_acc: 0.9926 - class_acc: [0.9998 0.9912 0.9904 0.9890] 
VALID | loss: 0.0201 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9825 0.9993]
Epoch 13/40
TRAIN | loss: 0.0357 - global_acc: 0.9916 - class_acc: [0.9995 0.9898 0.9871 0.9901] 
VALID | loss: 0.0105 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9946 0.9979] - BEST!
Epoch 14/40
TRAIN | loss: 0.0324 - global_acc: 0.9930 - class_acc: [0.9991 0.9916 0.9897 0.9915] 
VALID | loss: 0.0203 - global_acc: 0.9956 - class_acc: [1.0000 1.0000 0.9830 0.9993]
Epoch 15/40
TRAIN | loss: 0.0327 - global_acc: 0.9921 - class_acc: [1.0000 0.9898 0.9895 0.9892] 
VALID | loss: 0.0069 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9973 0.9973] - BEST!
Epoch 16/40
TRAIN | loss: 0.0286 - global_acc: 0.9937 - class_acc: [1.0000 0.9892 0.9902 0.9954] 
VALID | loss: 0.0147 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9904 0.9967]
Epoch 17/40
TRAIN | loss: 0.0305 - global_acc: 0.9931 - class_acc: [0.9984 0.9938 0.9891 0.9911] 
VALID | loss: 0.0120 - global_acc: 0.9971 - class_acc: [1.0000 0.9993 0.9912 0.9979]
Epoch 18/40
TRAIN | loss: 0.0264 - global_acc: 0.9931 - class_acc: [0.9995 0.9915 0.9899 0.9917] 
VALID | loss: 0.0706 - global_acc: 0.9825 - class_acc: [1.0000 1.0000 0.9302 0.9993]
Epoch 19/40
TRAIN | loss: 0.0272 - global_acc: 0.9942 - class_acc: [1.0000 0.9940 0.9916 0.9913] 
VALID | loss: 0.0079 - global_acc: 0.9986 - class_acc: [1.0000 0.9987 0.9993 0.9966]
Epoch 20/40
TRAIN | loss: 0.0230 - global_acc: 0.9948 - class_acc: [1.0000 0.9938 0.9929 0.9926] 
VALID | loss: 0.0073 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9973 0.9973]
Epoch 21/40
TRAIN | loss: 0.0198 - global_acc: 0.9951 - class_acc: [0.9998 0.9938 0.9922 0.9946] 
VALID | loss: 0.0049 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9973 0.9986] - BEST!
Epoch 22/40
TRAIN | loss: 0.0199 - global_acc: 0.9958 - class_acc: [0.9998 0.9962 0.9934 0.9940] 
VALID | loss: 0.0069 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9980 0.9937]
Epoch 23/40
TRAIN | loss: 0.0222 - global_acc: 0.9952 - class_acc: [1.0000 0.9940 0.9938 0.9931] 
VALID | loss: 0.0076 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9961 0.9986]
Epoch 24/40
TRAIN | loss: 0.0188 - global_acc: 0.9962 - class_acc: [0.9998 0.9957 0.9947 0.9945] 
VALID | loss: 0.0061 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9940 0.9993]
Epoch 25/40
TRAIN | loss: 0.0224 - global_acc: 0.9956 - class_acc: [0.9998 0.9945 0.9948 0.9934] 
VALID | loss: 0.0051 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9974 0.9993] - BEST!
Epoch 26/40
TRAIN | loss: 0.0176 - global_acc: 0.9960 - class_acc: [1.0000 0.9951 0.9956 0.9932] 
VALID | loss: 0.0100 - global_acc: 0.9978 - class_acc: [1.0000 0.9993 0.9917 1.0000]
Epoch 27/40
TRAIN | loss: 0.0180 - global_acc: 0.9958 - class_acc: [1.0000 0.9960 0.9927 0.9945] 
VALID | loss: 0.0079 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9979 0.9945]
Epoch 28/40
TRAIN | loss: 0.0216 - global_acc: 0.9956 - class_acc: [0.9998 0.9948 0.9942 0.9935] 
VALID | loss: 0.0195 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9811 1.0000]
Epoch 29/40
TRAIN | loss: 0.0182 - global_acc: 0.9957 - class_acc: [1.0000 0.9946 0.9942 0.9943] 
VALID | loss: 0.0180 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9785 1.0000]
Epoch 30/40
TRAIN | loss: 0.0212 - global_acc: 0.9960 - class_acc: [0.9998 0.9962 0.9941 0.9940] 
VALID | loss: 0.0115 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9911 0.9993]
Epoch 31/40
TRAIN | loss: 0.0193 - global_acc: 0.9962 - class_acc: [0.9991 0.9956 0.9946 0.9954] 
VALID | loss: 0.0458 - global_acc: 0.9835 - class_acc: [1.0000 1.0000 0.9884 0.9470]
Epoch 32/40
TRAIN | loss: 0.0142 - global_acc: 0.9968 - class_acc: [1.0000 0.9970 0.9943 0.9960] 
VALID | loss: 0.0045 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9986 0.9986] - BEST!
Epoch 33/40
TRAIN | loss: 0.0182 - global_acc: 0.9960 - class_acc: [1.0000 0.9949 0.9945 0.9946] 
VALID | loss: 0.0070 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9938 1.0000]
Epoch 34/40
TRAIN | loss: 0.0166 - global_acc: 0.9963 - class_acc: [1.0000 0.9975 0.9940 0.9939] 
VALID | loss: 0.0145 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9931 1.0000]
Epoch 35/40
TRAIN | loss: 0.0164 - global_acc: 0.9968 - class_acc: [1.0000 0.9959 0.9959 0.9955] 
VALID | loss: 0.0108 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9987 0.9954]
Epoch 36/40
TRAIN | loss: 0.0171 - global_acc: 0.9964 - class_acc: [0.9998 0.9949 0.9962 0.9946] 
VALID | loss: 0.0186 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9871 1.0000]
Epoch 37/40
TRAIN | loss: 0.0195 - global_acc: 0.9958 - class_acc: [0.9998 0.9926 0.9952 0.9956] 
VALID | loss: 0.0196 - global_acc: 0.9957 - class_acc: [1.0000 0.9993 0.9849 0.9987]
Epoch 38/40
TRAIN | loss: 0.0165 - global_acc: 0.9965 - class_acc: [0.9998 0.9966 0.9952 0.9946] 
VALID | loss: 0.0063 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9952 1.0000]
Epoch 39/40
TRAIN | loss: 0.0167 - global_acc: 0.9969 - class_acc: [1.0000 0.9950 0.9961 0.9966] 
VALID | loss: 0.0039 - global_acc: 0.9995 - class_acc: [1.0000 1.0000 1.0000 0.9980] - BEST!
Epoch 40/40
TRAIN | loss: 0.0199 - global_acc: 0.9959 - class_acc: [1.0000 0.9948 0.9957 0.9932] 
VALID | loss: 0.0407 - global_acc: 0.9947 - class_acc: [1.0000 1.0000 0.9788 1.0000]


Evaluating...
TEST | loss: 0.0093 - global_acc: 0.9985 - class_acc: [0.0000 1.0000 1.0000 0.9970]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 26
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5285 - global_acc: 0.7971 - class_acc: [0.8571 0.7891 0.8226 0.7209] 
VALID | loss: 0.1133 - global_acc: 0.9609 - class_acc: [1.0000 0.9986 0.8975 0.9480] - BEST!
Epoch 2/40
TRAIN | loss: 0.1195 - global_acc: 0.9670 - class_acc: [0.9984 0.9743 0.9401 0.9546] 
VALID | loss: 0.0707 - global_acc: 0.9762 - class_acc: [1.0000 1.0000 0.9228 0.9808] - BEST!
Epoch 3/40
TRAIN | loss: 0.0936 - global_acc: 0.9750 - class_acc: [0.9984 0.9798 0.9567 0.9653] 
VALID | loss: 0.0467 - global_acc: 0.9845 - class_acc: [1.0000 1.0000 0.9689 0.9693] - BEST!
Epoch 4/40
TRAIN | loss: 0.0725 - global_acc: 0.9812 - class_acc: [0.9998 0.9842 0.9681 0.9725] 
VALID | loss: 0.0439 - global_acc: 0.9877 - class_acc: [1.0000 1.0000 0.9889 0.9628] - BEST!
Epoch 5/40
TRAIN | loss: 0.0559 - global_acc: 0.9845 - class_acc: [0.9998 0.9894 0.9767 0.9716] 
VALID | loss: 0.0354 - global_acc: 0.9889 - class_acc: [1.0000 1.0000 0.9736 0.9811] - BEST!
Epoch 6/40
TRAIN | loss: 0.0511 - global_acc: 0.9858 - class_acc: [0.9998 0.9891 0.9781 0.9760] 
VALID | loss: 0.0219 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9886 0.9796] - BEST!
Epoch 7/40
TRAIN | loss: 0.0540 - global_acc: 0.9860 - class_acc: [0.9998 0.9839 0.9787 0.9818] 
VALID | loss: 0.0246 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9775 0.9972] - BEST!
Epoch 8/40
TRAIN | loss: 0.0383 - global_acc: 0.9899 - class_acc: [0.9998 0.9917 0.9807 0.9877] 
VALID | loss: 0.0515 - global_acc: 0.9835 - class_acc: [1.0000 0.9993 0.9341 1.0000]
Epoch 9/40
TRAIN | loss: 0.0464 - global_acc: 0.9883 - class_acc: [0.9998 0.9887 0.9808 0.9840] 
VALID | loss: 0.0191 - global_acc: 0.9944 - class_acc: [1.0000 1.0000 0.9973 0.9798] - BEST!
Epoch 10/40
TRAIN | loss: 0.0397 - global_acc: 0.9901 - class_acc: [0.9998 0.9894 0.9852 0.9861] 
VALID | loss: 0.0142 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9947 0.9897] - BEST!
Epoch 11/40
TRAIN | loss: 0.0374 - global_acc: 0.9905 - class_acc: [0.9998 0.9890 0.9848 0.9884] 
VALID | loss: 0.1081 - global_acc: 0.9653 - class_acc: [1.0000 1.0000 0.8635 0.9986]
Epoch 12/40
TRAIN | loss: 0.0444 - global_acc: 0.9894 - class_acc: [0.9972 0.9881 0.9851 0.9874] 
VALID | loss: 0.0773 - global_acc: 0.9745 - class_acc: [1.0000 0.9899 0.9134 0.9986]
Epoch 13/40
TRAIN | loss: 0.0325 - global_acc: 0.9921 - class_acc: [0.9995 0.9908 0.9874 0.9905] 
VALID | loss: 0.0196 - global_acc: 0.9951 - class_acc: [1.0000 1.0000 0.9823 0.9987]
Epoch 14/40
TRAIN | loss: 0.0352 - global_acc: 0.9920 - class_acc: [0.9995 0.9869 0.9888 0.9928] 
VALID | loss: 0.0317 - global_acc: 0.9915 - class_acc: [1.0000 1.0000 0.9654 0.9993]
Epoch 15/40
TRAIN | loss: 0.0318 - global_acc: 0.9930 - class_acc: [0.9998 0.9891 0.9890 0.9940] 
VALID | loss: 0.0383 - global_acc: 0.9860 - class_acc: [1.0000 1.0000 0.9986 0.9470]
Epoch 16/40
TRAIN | loss: 0.0333 - global_acc: 0.9927 - class_acc: [0.9998 0.9888 0.9885 0.9939] 
VALID | loss: 0.0384 - global_acc: 0.9920 - class_acc: [1.0000 1.0000 0.9678 0.9993]
Epoch 17/40
TRAIN | loss: 0.0300 - global_acc: 0.9930 - class_acc: [1.0000 0.9910 0.9901 0.9910] 
VALID | loss: 0.0208 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9916 0.9832]
Epoch 18/40
TRAIN | loss: 0.0296 - global_acc: 0.9930 - class_acc: [0.9993 0.9895 0.9890 0.9942] 
VALID | loss: 0.0200 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9825 0.9993]
Epoch 19/40
TRAIN | loss: 0.0203 - global_acc: 0.9956 - class_acc: [0.9998 0.9925 0.9942 0.9960] 
VALID | loss: 0.0109 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9952 0.9880]
Epoch 20/40
TRAIN | loss: 0.0283 - global_acc: 0.9947 - class_acc: [1.0000 0.9919 0.9917 0.9954] 
VALID | loss: 0.0094 - global_acc: 0.9985 - class_acc: [1.0000 0.9993 0.9980 0.9967] - BEST!
Epoch 21/40
TRAIN | loss: 0.0277 - global_acc: 0.9937 - class_acc: [0.9998 0.9915 0.9908 0.9925] 
VALID | loss: 0.0116 - global_acc: 0.9974 - class_acc: [1.0000 1.0000 0.9953 0.9945]
Epoch 22/40
TRAIN | loss: 0.0272 - global_acc: 0.9940 - class_acc: [0.9995 0.9894 0.9928 0.9943] 
VALID | loss: 0.0101 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9993 0.9877]
Epoch 23/40
TRAIN | loss: 0.0262 - global_acc: 0.9947 - class_acc: [1.0000 0.9915 0.9919 0.9951] 
VALID | loss: 0.0260 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9797 0.9993]
Epoch 24/40
TRAIN | loss: 0.0301 - global_acc: 0.9939 - class_acc: [0.9998 0.9879 0.9936 0.9943] 
VALID | loss: 0.0185 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9888 0.9920]
Epoch 25/40
TRAIN | loss: 0.0327 - global_acc: 0.9932 - class_acc: [0.9986 0.9891 0.9914 0.9936] 
VALID | loss: 0.0238 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9897 0.9978]
Epoch 26/40
TRAIN | loss: 0.0256 - global_acc: 0.9940 - class_acc: [1.0000 0.9909 0.9917 0.9935] 
VALID | loss: 0.0119 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9917 0.9986]
Epoch 27/40
TRAIN | loss: 0.0232 - global_acc: 0.9955 - class_acc: [1.0000 0.9940 0.9945 0.9933] 
VALID | loss: 0.0207 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9917 0.9965]
Epoch 28/40
TRAIN | loss: 0.0222 - global_acc: 0.9953 - class_acc: [0.9998 0.9938 0.9922 0.9955] 
VALID | loss: 0.0230 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9906 1.0000]
Epoch 29/40
TRAIN | loss: 0.0211 - global_acc: 0.9952 - class_acc: [1.0000 0.9920 0.9936 0.9952] 
VALID | loss: 0.0259 - global_acc: 0.9949 - class_acc: [1.0000 1.0000 0.9797 0.9993]
Epoch 30/40
TRAIN | loss: 0.0253 - global_acc: 0.9944 - class_acc: [1.0000 0.9896 0.9935 0.9947] 
VALID | loss: 0.0143 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9870 0.9972]
Epoch 31/40
TRAIN | loss: 0.0198 - global_acc: 0.9957 - class_acc: [1.0000 0.9928 0.9941 0.9960] 
VALID | loss: 0.0215 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9875 0.9966]
Epoch 32/40
TRAIN | loss: 0.0226 - global_acc: 0.9943 - class_acc: [0.9998 0.9910 0.9914 0.9950] 
VALID | loss: 0.0105 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9960 0.9905]
Epoch 33/40
TRAIN | loss: 0.0187 - global_acc: 0.9959 - class_acc: [1.0000 0.9918 0.9952 0.9967] 
VALID | loss: 0.0148 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9939 1.0000] - BEST!
Epoch 34/40
TRAIN | loss: 0.0233 - global_acc: 0.9943 - class_acc: [1.0000 0.9905 0.9917 0.9950] 
VALID | loss: 0.0093 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9973 0.9973] - BEST!
Epoch 35/40
TRAIN | loss: 0.0210 - global_acc: 0.9956 - class_acc: [0.9995 0.9917 0.9949 0.9964] 
VALID | loss: 0.0146 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9931 0.9949]
Epoch 36/40
TRAIN | loss: 0.0276 - global_acc: 0.9942 - class_acc: [1.0000 0.9895 0.9938 0.9933] 
VALID | loss: 0.0208 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9944 1.0000]
Epoch 37/40
TRAIN | loss: 0.0189 - global_acc: 0.9961 - class_acc: [1.0000 0.9925 0.9950 0.9968] 
VALID | loss: 0.0090 - global_acc: 0.9995 - class_acc: [1.0000 1.0000 0.9986 0.9993] - BEST!
Epoch 38/40
TRAIN | loss: 0.0246 - global_acc: 0.9951 - class_acc: [1.0000 0.9895 0.9942 0.9969] 
VALID | loss: 0.0184 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9916 1.0000]
Epoch 39/40
TRAIN | loss: 0.0174 - global_acc: 0.9957 - class_acc: [1.0000 0.9929 0.9939 0.9962] 
VALID | loss: 0.0136 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9925 1.0000]
Epoch 40/40
TRAIN | loss: 0.0193 - global_acc: 0.9963 - class_acc: [1.0000 0.9941 0.9948 0.9961] 
VALID | loss: 0.0185 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9931 0.9973]


Evaluating...
TEST | loss: 0.1327 - global_acc: 0.9781 - class_acc: [1.0000 1.0000 0.9990 0.9464]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 27
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5722 - global_acc: 0.7410 - class_acc: [0.7374 0.9078 0.7836 0.5344] 
VALID | loss: 0.1326 - global_acc: 0.9466 - class_acc: [1.0000 1.0000 0.8118 0.9713] - BEST!
Epoch 2/40
TRAIN | loss: 0.1215 - global_acc: 0.9596 - class_acc: [0.9991 0.9758 0.9377 0.9260] 
VALID | loss: 0.1327 - global_acc: 0.9529 - class_acc: [0.9993 1.0000 0.8143 0.9980] - BEST!
Epoch 3/40
TRAIN | loss: 0.0982 - global_acc: 0.9684 - class_acc: [0.9986 0.9771 0.9493 0.9485] 
VALID | loss: 0.1442 - global_acc: 0.9455 - class_acc: [0.9986 1.0000 0.7953 0.9973]
Epoch 4/40
TRAIN | loss: 0.0835 - global_acc: 0.9758 - class_acc: [0.9986 0.9761 0.9658 0.9638] 
VALID | loss: 0.0608 - global_acc: 0.9796 - class_acc: [1.0000 1.0000 0.9205 0.9980] - BEST!
Epoch 5/40
TRAIN | loss: 0.0799 - global_acc: 0.9760 - class_acc: [0.9993 0.9764 0.9627 0.9656] 
VALID | loss: 0.0370 - global_acc: 0.9871 - class_acc: [1.0000 1.0000 0.9566 0.9922] - BEST!
Epoch 6/40
TRAIN | loss: 0.0659 - global_acc: 0.9811 - class_acc: [0.9991 0.9795 0.9720 0.9742] 
VALID | loss: 0.0252 - global_acc: 0.9913 - class_acc: [1.0000 1.0000 0.9804 0.9847] - BEST!
Epoch 7/40
TRAIN | loss: 0.0664 - global_acc: 0.9820 - class_acc: [0.9995 0.9824 0.9718 0.9737] 
VALID | loss: 0.0377 - global_acc: 0.9876 - class_acc: [1.0000 0.9993 0.9562 0.9960]
Epoch 8/40
TRAIN | loss: 0.0608 - global_acc: 0.9832 - class_acc: [1.0000 0.9809 0.9738 0.9772] 
VALID | loss: 0.0212 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9848 0.9865] - BEST!
Epoch 9/40
TRAIN | loss: 0.0562 - global_acc: 0.9858 - class_acc: [0.9998 0.9842 0.9771 0.9823] 
VALID | loss: 0.0153 - global_acc: 0.9957 - class_acc: [0.9987 1.0000 0.9952 0.9890] - BEST!
Epoch 10/40
TRAIN | loss: 0.0540 - global_acc: 0.9860 - class_acc: [0.9996 0.9849 0.9795 0.9798] 
VALID | loss: 0.0504 - global_acc: 0.9867 - class_acc: [1.0000 0.9993 0.9497 0.9986]
Epoch 11/40
TRAIN | loss: 0.0521 - global_acc: 0.9863 - class_acc: [0.9996 0.9818 0.9816 0.9815] 
VALID | loss: 0.0205 - global_acc: 0.9935 - class_acc: [1.0000 1.0000 0.9869 0.9866]
Epoch 12/40
TRAIN | loss: 0.0479 - global_acc: 0.9874 - class_acc: [0.9995 0.9892 0.9781 0.9828] 
VALID | loss: 0.0279 - global_acc: 0.9935 - class_acc: [1.0000 1.0000 0.9777 0.9967]
Epoch 13/40
TRAIN | loss: 0.0427 - global_acc: 0.9897 - class_acc: [0.9995 0.9914 0.9809 0.9867] 
VALID | loss: 0.0147 - global_acc: 0.9959 - class_acc: [0.9993 1.0000 0.9938 0.9907] - BEST!
Epoch 14/40
TRAIN | loss: 0.0448 - global_acc: 0.9891 - class_acc: [0.9996 0.9876 0.9828 0.9860] 
VALID | loss: 0.0240 - global_acc: 0.9910 - class_acc: [1.0000 1.0000 0.9980 0.9648]
Epoch 15/40
TRAIN | loss: 0.0467 - global_acc: 0.9885 - class_acc: [0.9996 0.9866 0.9831 0.9846] 
VALID | loss: 0.0478 - global_acc: 0.9859 - class_acc: [0.9993 1.0000 0.9420 1.0000]
Epoch 16/40
TRAIN | loss: 0.0397 - global_acc: 0.9899 - class_acc: [0.9993 0.9909 0.9831 0.9862] 
VALID | loss: 0.0066 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9953 0.9973] - BEST!
Epoch 17/40
TRAIN | loss: 0.0390 - global_acc: 0.9893 - class_acc: [1.0000 0.9910 0.9810 0.9855] 
VALID | loss: 0.0142 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9932 0.9876]
Epoch 18/40
TRAIN | loss: 0.0418 - global_acc: 0.9896 - class_acc: [1.0000 0.9918 0.9789 0.9874] 
VALID | loss: 0.0120 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9919 0.9993]
Epoch 19/40
TRAIN | loss: 0.0379 - global_acc: 0.9903 - class_acc: [0.9998 0.9910 0.9842 0.9862] 
VALID | loss: 0.0144 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9959 0.9873]
Epoch 20/40
TRAIN | loss: 0.0404 - global_acc: 0.9905 - class_acc: [0.9991 0.9896 0.9852 0.9880] 
VALID | loss: 0.0125 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9959 0.9952]
Epoch 21/40
TRAIN | loss: 0.0353 - global_acc: 0.9908 - class_acc: [0.9995 0.9890 0.9894 0.9853] 
VALID | loss: 0.0359 - global_acc: 0.9905 - class_acc: [1.0000 1.0000 0.9636 0.9993]
Epoch 22/40
TRAIN | loss: 0.0318 - global_acc: 0.9922 - class_acc: [1.0000 0.9922 0.9887 0.9878] 
VALID | loss: 0.0105 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9939 0.9993] - BEST!
Epoch 23/40
TRAIN | loss: 0.0315 - global_acc: 0.9930 - class_acc: [0.9998 0.9945 0.9897 0.9882] 
VALID | loss: 0.0111 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9952 0.9980] - BEST!
Epoch 24/40
TRAIN | loss: 0.0384 - global_acc: 0.9894 - class_acc: [0.9995 0.9896 0.9851 0.9837] 
VALID | loss: 0.0189 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9839 0.9979]
Epoch 25/40
TRAIN | loss: 0.0304 - global_acc: 0.9915 - class_acc: [0.9998 0.9921 0.9872 0.9866] 
VALID | loss: 0.0119 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9946 0.9934]
Epoch 26/40
TRAIN | loss: 0.0308 - global_acc: 0.9919 - class_acc: [0.9998 0.9907 0.9878 0.9894] 
VALID | loss: 0.0134 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9972 0.9863]
Epoch 27/40
TRAIN | loss: 0.0258 - global_acc: 0.9934 - class_acc: [1.0000 0.9914 0.9917 0.9904] 
VALID | loss: 0.0096 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9959 1.0000] - BEST!
Epoch 28/40
TRAIN | loss: 0.0292 - global_acc: 0.9917 - class_acc: [0.9995 0.9934 0.9892 0.9846] 
VALID | loss: 0.0353 - global_acc: 0.9903 - class_acc: [1.0000 1.0000 0.9611 0.9993]
Epoch 29/40
TRAIN | loss: 0.0235 - global_acc: 0.9931 - class_acc: [1.0000 0.9917 0.9908 0.9899] 
VALID | loss: 0.0040 - global_acc: 0.9998 - class_acc: [1.0000 1.0000 0.9993 1.0000] - BEST!
Epoch 30/40
TRAIN | loss: 0.0307 - global_acc: 0.9915 - class_acc: [0.9996 0.9922 0.9890 0.9850] 
VALID | loss: 0.0111 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9979 0.9950]
Epoch 31/40
TRAIN | loss: 0.0312 - global_acc: 0.9917 - class_acc: [0.9995 0.9889 0.9908 0.9876] 
VALID | loss: 0.0127 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9922 0.9987]
Epoch 32/40
TRAIN | loss: 0.0298 - global_acc: 0.9911 - class_acc: [0.9998 0.9885 0.9904 0.9858] 
VALID | loss: 0.0074 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9972 1.0000]
Epoch 33/40
TRAIN | loss: 0.0289 - global_acc: 0.9921 - class_acc: [0.9996 0.9908 0.9897 0.9882] 
VALID | loss: 0.0102 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9943 0.9993]
Epoch 34/40
TRAIN | loss: 0.0247 - global_acc: 0.9931 - class_acc: [1.0000 0.9913 0.9909 0.9900] 
VALID | loss: 0.0073 - global_acc: 0.9988 - class_acc: [1.0000 1.0000 0.9966 0.9986]
Epoch 35/40
TRAIN | loss: 0.0257 - global_acc: 0.9928 - class_acc: [0.9998 0.9928 0.9911 0.9874] 
VALID | loss: 0.0080 - global_acc: 0.9981 - class_acc: [1.0000 1.0000 0.9952 0.9974]
Epoch 36/40
TRAIN | loss: 0.0293 - global_acc: 0.9925 - class_acc: [0.9998 0.9911 0.9908 0.9885] 
VALID | loss: 0.0150 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9934 1.0000]
Epoch 37/40
TRAIN | loss: 0.0354 - global_acc: 0.9913 - class_acc: [0.9984 0.9902 0.9892 0.9873] 
VALID | loss: 0.0904 - global_acc: 0.9791 - class_acc: [1.0000 1.0000 0.9202 0.9980]
Epoch 38/40
TRAIN | loss: 0.0298 - global_acc: 0.9922 - class_acc: [1.0000 0.9887 0.9923 0.9878] 
VALID | loss: 0.0445 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9803 1.0000]
Epoch 39/40
TRAIN | loss: 0.0268 - global_acc: 0.9936 - class_acc: [0.9998 0.9910 0.9921 0.9915] 
VALID | loss: 0.0129 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9967 0.9972]
Epoch 40/40
TRAIN | loss: 0.0211 - global_acc: 0.9938 - class_acc: [1.0000 0.9929 0.9951 0.9873] 
VALID | loss: 0.0103 - global_acc: 0.9981 - class_acc: [1.0000 0.9993 0.9966 0.9967]


Evaluating...
TEST | loss: 0.0088 - global_acc: 0.9980 - class_acc: [0.0000 1.0000 1.0000 0.9958]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 28
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5279 - global_acc: 0.7903 - class_acc: [0.7652 0.8764 0.8172 0.6986] 
VALID | loss: 0.1415 - global_acc: 0.9438 - class_acc: [0.9986 0.9993 0.8037 0.9794] - BEST!
Epoch 2/40
TRAIN | loss: 0.1155 - global_acc: 0.9623 - class_acc: [0.9973 0.9789 0.9329 0.9398] 
VALID | loss: 0.0741 - global_acc: 0.9711 - class_acc: [1.0000 1.0000 0.9114 0.9732] - BEST!
Epoch 3/40
TRAIN | loss: 0.0847 - global_acc: 0.9722 - class_acc: [0.9993 0.9814 0.9501 0.9590] 
VALID | loss: 0.0891 - global_acc: 0.9689 - class_acc: [1.0000 1.0000 0.9911 0.8826]
Epoch 4/40
TRAIN | loss: 0.0619 - global_acc: 0.9807 - class_acc: [0.9995 0.9873 0.9672 0.9681] 
VALID | loss: 0.0287 - global_acc: 0.9908 - class_acc: [1.0000 1.0000 0.9842 0.9788] - BEST!
Epoch 5/40
TRAIN | loss: 0.0578 - global_acc: 0.9810 - class_acc: [0.9996 0.9822 0.9707 0.9711] 
VALID | loss: 0.0327 - global_acc: 0.9886 - class_acc: [1.0000 1.0000 0.9660 0.9875]
Epoch 6/40
TRAIN | loss: 0.0476 - global_acc: 0.9851 - class_acc: [0.9989 0.9868 0.9744 0.9804] 
VALID | loss: 0.0312 - global_acc: 0.9884 - class_acc: [1.0000 1.0000 0.9811 0.9716]
Epoch 7/40
TRAIN | loss: 0.0456 - global_acc: 0.9859 - class_acc: [0.9995 0.9867 0.9761 0.9816] 
VALID | loss: 0.0208 - global_acc: 0.9946 - class_acc: [1.0000 1.0000 0.9849 0.9932] - BEST!
Epoch 8/40
TRAIN | loss: 0.0405 - global_acc: 0.9876 - class_acc: [0.9989 0.9856 0.9821 0.9839] 
VALID | loss: 0.0201 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9812 0.9938]
Epoch 9/40
TRAIN | loss: 0.0450 - global_acc: 0.9872 - class_acc: [0.9993 0.9875 0.9801 0.9819] 
VALID | loss: 0.0281 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9918 0.9888] - BEST!
Epoch 10/40
TRAIN | loss: 0.0405 - global_acc: 0.9884 - class_acc: [0.9996 0.9866 0.9799 0.9871] 
VALID | loss: 0.0118 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9938 0.9919] - BEST!
Epoch 11/40
TRAIN | loss: 0.0325 - global_acc: 0.9898 - class_acc: [1.0000 0.9894 0.9819 0.9876] 
VALID | loss: 0.0153 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9905 0.9912]
Epoch 12/40
TRAIN | loss: 0.0321 - global_acc: 0.9902 - class_acc: [0.9996 0.9873 0.9853 0.9886] 
VALID | loss: 0.0137 - global_acc: 0.9981 - class_acc: [0.9993 1.0000 0.9945 0.9986] - BEST!
Epoch 13/40
TRAIN | loss: 0.0292 - global_acc: 0.9913 - class_acc: [1.0000 0.9910 0.9840 0.9905] 
VALID | loss: 0.0197 - global_acc: 0.9925 - class_acc: [1.0000 1.0000 0.9959 0.9748]
Epoch 14/40
TRAIN | loss: 0.0356 - global_acc: 0.9894 - class_acc: [0.9998 0.9884 0.9824 0.9870] 
VALID | loss: 0.0111 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9899 0.9965]
Epoch 15/40
TRAIN | loss: 0.0293 - global_acc: 0.9918 - class_acc: [0.9993 0.9916 0.9844 0.9920] 
VALID | loss: 0.0107 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9951 0.9905]
Epoch 16/40
TRAIN | loss: 0.0294 - global_acc: 0.9919 - class_acc: [0.9998 0.9865 0.9890 0.9927] 
VALID | loss: 0.0212 - global_acc: 0.9954 - class_acc: [1.0000 1.0000 0.9822 1.0000]
Epoch 17/40
TRAIN | loss: 0.0297 - global_acc: 0.9917 - class_acc: [0.9998 0.9875 0.9865 0.9926] 
VALID | loss: 0.0462 - global_acc: 0.9888 - class_acc: [1.0000 1.0000 0.9555 1.0000]
Epoch 18/40
TRAIN | loss: 0.0311 - global_acc: 0.9920 - class_acc: [0.9996 0.9909 0.9861 0.9913] 
VALID | loss: 0.0089 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9943 0.9961]
Epoch 19/40
TRAIN | loss: 0.0267 - global_acc: 0.9931 - class_acc: [0.9998 0.9898 0.9898 0.9931] 
VALID | loss: 0.0081 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 0.9946 0.9993] - BEST!
Epoch 20/40
TRAIN | loss: 0.0270 - global_acc: 0.9925 - class_acc: [0.9998 0.9893 0.9894 0.9915] 
VALID | loss: 0.0088 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9972 0.9993] - BEST!
Epoch 21/40
TRAIN | loss: 0.0238 - global_acc: 0.9934 - class_acc: [1.0000 0.9896 0.9898 0.9942] 
VALID | loss: 0.0115 - global_acc: 0.9986 - class_acc: [1.0000 1.0000 0.9960 0.9986]
Epoch 22/40
TRAIN | loss: 0.0237 - global_acc: 0.9939 - class_acc: [0.9995 0.9927 0.9907 0.9926] 
VALID | loss: 0.0368 - global_acc: 0.9906 - class_acc: [1.0000 1.0000 0.9627 1.0000]
Epoch 23/40
TRAIN | loss: 0.0248 - global_acc: 0.9939 - class_acc: [1.0000 0.9909 0.9913 0.9934] 
VALID | loss: 0.0129 - global_acc: 0.9959 - class_acc: [1.0000 1.0000 0.9880 0.9952]
Epoch 24/40
TRAIN | loss: 0.0221 - global_acc: 0.9948 - class_acc: [0.9993 0.9911 0.9948 0.9939] 
VALID | loss: 0.0119 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9904 1.0000]
Epoch 25/40
TRAIN | loss: 0.0267 - global_acc: 0.9934 - class_acc: [1.0000 0.9902 0.9885 0.9946] 
VALID | loss: 0.0782 - global_acc: 0.9779 - class_acc: [1.0000 1.0000 0.9105 1.0000]
Epoch 26/40
TRAIN | loss: 0.0206 - global_acc: 0.9948 - class_acc: [0.9998 0.9931 0.9927 0.9936] 
VALID | loss: 0.0100 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9967 0.9882]
Epoch 27/40
TRAIN | loss: 0.0213 - global_acc: 0.9951 - class_acc: [0.9995 0.9907 0.9946 0.9956] 
VALID | loss: 0.0358 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9724 1.0000]
Epoch 28/40
TRAIN | loss: 0.0213 - global_acc: 0.9948 - class_acc: [1.0000 0.9908 0.9929 0.9954] 
VALID | loss: 0.0053 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9986 0.9980]
Epoch 29/40
TRAIN | loss: 0.0205 - global_acc: 0.9942 - class_acc: [0.9998 0.9896 0.9924 0.9951] 
VALID | loss: 0.0239 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9876 0.9953]
Epoch 30/40
TRAIN | loss: 0.0235 - global_acc: 0.9939 - class_acc: [1.0000 0.9898 0.9932 0.9929] 
VALID | loss: 0.0085 - global_acc: 0.9997 - class_acc: [1.0000 1.0000 0.9986 1.0000] - BEST!
Epoch 31/40
TRAIN | loss: 0.0189 - global_acc: 0.9959 - class_acc: [1.0000 0.9930 0.9935 0.9969] 
VALID | loss: 0.0068 - global_acc: 0.9991 - class_acc: [1.0000 1.0000 0.9987 0.9980]
Epoch 32/40
TRAIN | loss: 0.0180 - global_acc: 0.9948 - class_acc: [1.0000 0.9888 0.9937 0.9966] 
VALID | loss: 0.0087 - global_acc: 0.9997 - class_acc: [1.0000 1.0000 0.9987 1.0000]
Epoch 33/40
TRAIN | loss: 0.0261 - global_acc: 0.9938 - class_acc: [0.9991 0.9904 0.9929 0.9929] 
VALID | loss: 0.0865 - global_acc: 0.9889 - class_acc: [1.0000 0.9993 0.9580 1.0000]
Epoch 34/40
TRAIN | loss: 0.0182 - global_acc: 0.9952 - class_acc: [1.0000 0.9892 0.9959 0.9957] 
VALID | loss: 0.0248 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9844 1.0000]
Epoch 35/40
TRAIN | loss: 0.0183 - global_acc: 0.9959 - class_acc: [1.0000 0.9934 0.9944 0.9959] 
VALID | loss: 0.0224 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9986 0.9896]
Epoch 36/40
TRAIN | loss: 0.0187 - global_acc: 0.9956 - class_acc: [1.0000 0.9917 0.9950 0.9957] 
VALID | loss: 0.0389 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9744 1.0000]
Epoch 37/40
TRAIN | loss: 0.0161 - global_acc: 0.9961 - class_acc: [1.0000 0.9921 0.9957 0.9968] 
VALID | loss: 0.0253 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9901 1.0000]
Epoch 38/40
TRAIN | loss: 0.0248 - global_acc: 0.9942 - class_acc: [0.9995 0.9898 0.9926 0.9949] 
VALID | loss: 0.0236 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9916 0.9993]
Epoch 39/40
TRAIN | loss: 0.0167 - global_acc: 0.9956 - class_acc: [0.9998 0.9905 0.9958 0.9962] 
VALID | loss: 0.0072 - global_acc: 0.9971 - class_acc: [1.0000 1.0000 0.9974 0.9910]
Epoch 40/40
TRAIN | loss: 0.0169 - global_acc: 0.9957 - class_acc: [1.0000 0.9906 0.9948 0.9975] 
VALID | loss: 0.0085 - global_acc: 0.9990 - class_acc: [1.0000 1.0000 0.9959 1.0000]


Evaluating...
TEST | loss: 1.6827 - global_acc: 0.9254 - class_acc: [0.0000 1.0000 0.9990 0.8165]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 29
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.6321 - global_acc: 0.7002 - class_acc: [0.9727 0.7383 0.5513 0.5399] 
VALID | loss: 0.1775 - global_acc: 0.9513 - class_acc: [1.0000 0.9993 0.9255 0.8831] - BEST!
Epoch 2/40
TRAIN | loss: 0.1798 - global_acc: 0.9508 - class_acc: [0.9768 0.9596 0.9666 0.8993] 
VALID | loss: 0.0867 - global_acc: 0.9714 - class_acc: [1.0000 1.0000 0.9799 0.9032] - BEST!
Epoch 3/40
TRAIN | loss: 0.1296 - global_acc: 0.9678 - class_acc: [0.9827 0.9646 0.9788 0.9446] 
VALID | loss: 0.0570 - global_acc: 0.9821 - class_acc: [1.0000 1.0000 0.9837 0.9448] - BEST!
Epoch 4/40
TRAIN | loss: 0.1106 - global_acc: 0.9743 - class_acc: [0.9866 0.9602 0.9841 0.9662] 
VALID | loss: 0.0838 - global_acc: 0.9685 - class_acc: [1.0000 1.0000 0.9951 0.8793]
Epoch 5/40
TRAIN | loss: 0.0973 - global_acc: 0.9767 - class_acc: [0.9900 0.9637 0.9869 0.9657] 
VALID | loss: 0.1008 - global_acc: 0.9595 - class_acc: [0.9993 1.0000 0.9993 0.8447]
Epoch 6/40
TRAIN | loss: 0.0874 - global_acc: 0.9800 - class_acc: [0.9869 0.9678 0.9906 0.9749] 
VALID | loss: 0.0503 - global_acc: 0.9823 - class_acc: [1.0000 1.0000 0.9912 0.9385] - BEST!
Epoch 7/40
TRAIN | loss: 0.0851 - global_acc: 0.9800 - class_acc: [0.9913 0.9678 0.9902 0.9699] 
VALID | loss: 0.0804 - global_acc: 0.9707 - class_acc: [1.0000 1.0000 0.9986 0.8851]
Epoch 8/40
TRAIN | loss: 0.0810 - global_acc: 0.9806 - class_acc: [0.9907 0.9704 0.9906 0.9707] 
VALID | loss: 0.0733 - global_acc: 0.9763 - class_acc: [0.9987 1.0000 1.0000 0.9049]
Epoch 9/40
TRAIN | loss: 0.0764 - global_acc: 0.9825 - class_acc: [0.9895 0.9702 0.9941 0.9759] 
VALID | loss: 0.0290 - global_acc: 0.9922 - class_acc: [0.9993 1.0000 0.9912 0.9784] - BEST!
Epoch 10/40
TRAIN | loss: 0.0772 - global_acc: 0.9816 - class_acc: [0.9913 0.9682 0.9930 0.9739] 
VALID | loss: 0.0852 - global_acc: 0.9677 - class_acc: [1.0000 1.0000 0.9993 0.8732]
Epoch 11/40
TRAIN | loss: 0.0707 - global_acc: 0.9837 - class_acc: [0.9944 0.9718 0.9941 0.9740] 
VALID | loss: 0.0491 - global_acc: 0.9816 - class_acc: [1.0000 1.0000 0.9987 0.9261]
Epoch 12/40
TRAIN | loss: 0.0696 - global_acc: 0.9842 - class_acc: [0.9940 0.9697 0.9946 0.9785] 
VALID | loss: 0.0994 - global_acc: 0.9602 - class_acc: [1.0000 0.9993 1.0000 0.8400]
Epoch 13/40
TRAIN | loss: 0.0686 - global_acc: 0.9835 - class_acc: [0.9958 0.9649 0.9949 0.9787] 
VALID | loss: 0.0292 - global_acc: 0.9918 - class_acc: [1.0000 1.0000 0.9993 0.9677]
Epoch 14/40
TRAIN | loss: 0.0642 - global_acc: 0.9844 - class_acc: [0.9948 0.9679 0.9957 0.9793] 
VALID | loss: 0.0733 - global_acc: 0.9728 - class_acc: [1.0000 1.0000 0.9993 0.8947]
Epoch 15/40
TRAIN | loss: 0.0643 - global_acc: 0.9833 - class_acc: [0.9956 0.9701 0.9934 0.9750] 
VALID | loss: 0.1002 - global_acc: 0.9651 - class_acc: [1.0000 1.0000 0.9986 0.8656]
Epoch 16/40
TRAIN | loss: 0.0525 - global_acc: 0.9867 - class_acc: [0.9955 0.9799 0.9941 0.9775] 
VALID | loss: 0.0611 - global_acc: 0.9787 - class_acc: [1.0000 1.0000 1.0000 0.9112]
Epoch 17/40
TRAIN | loss: 0.0472 - global_acc: 0.9881 - class_acc: [0.9949 0.9850 0.9962 0.9769] 
VALID | loss: 0.0210 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 1.0000 0.9720] - BEST!
Epoch 18/40
TRAIN | loss: 0.0456 - global_acc: 0.9893 - class_acc: [0.9935 0.9875 0.9966 0.9794] 
VALID | loss: 0.0777 - global_acc: 0.9706 - class_acc: [1.0000 1.0000 1.0000 0.8789]
Epoch 19/40
TRAIN | loss: 0.0464 - global_acc: 0.9893 - class_acc: [0.9947 0.9877 0.9958 0.9793] 
VALID | loss: 0.1303 - global_acc: 0.9476 - class_acc: [0.9993 1.0000 1.0000 0.7904]
Epoch 20/40
TRAIN | loss: 0.0401 - global_acc: 0.9904 - class_acc: [0.9946 0.9910 0.9958 0.9802] 
VALID | loss: 0.0334 - global_acc: 0.9908 - class_acc: [1.0000 1.0000 1.0000 0.9618]
Epoch 21/40
TRAIN | loss: 0.0370 - global_acc: 0.9912 - class_acc: [0.9964 0.9902 0.9950 0.9832] 
VALID | loss: 0.0266 - global_acc: 0.9939 - class_acc: [1.0000 1.0000 0.9993 0.9764] - BEST!
Epoch 22/40
TRAIN | loss: 0.0378 - global_acc: 0.9917 - class_acc: [0.9955 0.9904 0.9968 0.9839] 
VALID | loss: 0.0826 - global_acc: 0.9663 - class_acc: [0.9993 1.0000 1.0000 0.8653]
Epoch 23/40
TRAIN | loss: 0.0309 - global_acc: 0.9930 - class_acc: [0.9958 0.9934 0.9963 0.9861] 
VALID | loss: 0.1097 - global_acc: 0.9568 - class_acc: [1.0000 1.0000 1.0000 0.8214]
Epoch 24/40
TRAIN | loss: 0.0327 - global_acc: 0.9928 - class_acc: [0.9956 0.9914 0.9961 0.9881] 
VALID | loss: 0.0969 - global_acc: 0.9658 - class_acc: [0.9993 1.0000 1.0000 0.8679]
Epoch 25/40
TRAIN | loss: 0.0287 - global_acc: 0.9942 - class_acc: [0.9966 0.9927 0.9982 0.9897] 
VALID | loss: 0.0712 - global_acc: 0.9755 - class_acc: [1.0000 1.0000 1.0000 0.9031]
Epoch 26/40
TRAIN | loss: 0.0338 - global_acc: 0.9922 - class_acc: [0.9948 0.9895 0.9975 0.9870] 
VALID | loss: 0.0457 - global_acc: 0.9891 - class_acc: [1.0000 1.0000 1.0000 0.9552]
Epoch 27/40
TRAIN | loss: 0.0312 - global_acc: 0.9935 - class_acc: [0.9942 0.9919 0.9987 0.9892] 
VALID | loss: 0.0694 - global_acc: 0.9775 - class_acc: [1.0000 1.0000 1.0000 0.9111]
Epoch 28/40
TRAIN | loss: 0.0370 - global_acc: 0.9917 - class_acc: [0.9947 0.9881 0.9969 0.9870] 
VALID | loss: 0.0169 - global_acc: 0.9963 - class_acc: [1.0000 0.9993 0.9993 0.9857] - BEST!
Epoch 29/40
TRAIN | loss: 0.0326 - global_acc: 0.9923 - class_acc: [0.9961 0.9907 0.9966 0.9858] 
VALID | loss: 0.0359 - global_acc: 0.9881 - class_acc: [1.0000 1.0000 1.0000 0.9527]
Epoch 30/40
TRAIN | loss: 0.0347 - global_acc: 0.9933 - class_acc: [0.9946 0.9903 0.9975 0.9906] 
VALID | loss: 0.1822 - global_acc: 0.9159 - class_acc: [1.0000 1.0000 1.0000 0.6660]
Epoch 31/40
TRAIN | loss: 0.0337 - global_acc: 0.9931 - class_acc: [0.9952 0.9899 0.9984 0.9891] 
VALID | loss: 0.0400 - global_acc: 0.9876 - class_acc: [1.0000 1.0000 1.0000 0.9496]
Epoch 32/40
TRAIN | loss: 0.0361 - global_acc: 0.9929 - class_acc: [0.9941 0.9912 0.9973 0.9888] 
VALID | loss: 0.0727 - global_acc: 0.9723 - class_acc: [0.9993 1.0000 1.0000 0.8934]
Epoch 33/40
TRAIN | loss: 0.0266 - global_acc: 0.9946 - class_acc: [0.9964 0.9912 0.9976 0.9931] 
VALID | loss: 0.0342 - global_acc: 0.9896 - class_acc: [1.0000 1.0000 1.0000 0.9577]
Epoch 34/40
TRAIN | loss: 0.0270 - global_acc: 0.9940 - class_acc: [0.9957 0.9917 0.9970 0.9919] 
VALID | loss: 0.0519 - global_acc: 0.9843 - class_acc: [1.0000 1.0000 1.0000 0.9370]
Epoch 35/40
TRAIN | loss: 0.0285 - global_acc: 0.9939 - class_acc: [0.9963 0.9918 0.9980 0.9897] 
VALID | loss: 0.1623 - global_acc: 0.9331 - class_acc: [1.0000 1.0000 1.0000 0.7389]
Epoch 36/40
TRAIN | loss: 0.0268 - global_acc: 0.9947 - class_acc: [0.9947 0.9916 0.9993 0.9932] 
VALID | loss: 0.0444 - global_acc: 0.9886 - class_acc: [1.0000 1.0000 0.9965 0.9581]
Epoch 37/40
TRAIN | loss: 0.0255 - global_acc: 0.9946 - class_acc: [0.9957 0.9919 0.9989 0.9917] 
VALID | loss: 0.0160 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 1.0000 0.9870] - BEST!
Epoch 38/40
TRAIN | loss: 0.0307 - global_acc: 0.9943 - class_acc: [0.9950 0.9931 0.9963 0.9926] 
VALID | loss: 0.0530 - global_acc: 0.9816 - class_acc: [1.0000 1.0000 1.0000 0.9259]
Epoch 39/40
TRAIN | loss: 0.0294 - global_acc: 0.9933 - class_acc: [0.9954 0.9909 0.9969 0.9899] 
VALID | loss: 0.0238 - global_acc: 0.9940 - class_acc: [1.0000 1.0000 1.0000 0.9758]
Epoch 40/40
TRAIN | loss: 0.0264 - global_acc: 0.9942 - class_acc: [0.9962 0.9893 0.9975 0.9937] 
VALID | loss: 0.0465 - global_acc: 0.9869 - class_acc: [1.0000 1.0000 1.0000 0.9479]


Evaluating...
TEST | loss: 2.4063 - global_acc: 0.9231 - class_acc: [1.0000 0.7197 1.0000 0.9937]
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse
M SAE | C 20 | RW 0.9 | B 64 | E 40 | R 30 | ATrue | TAFalse

R 30
Namespace(augmentation=True, batch_size=64, classes=['absent', 'blank', 'cap', 'stopper'], dataset='vials-detection/images', datetime='060122_164149', device='cuda:0', encoded_size=20, epochs=40, learning_rate=0.0001, model='SAE', num_workers=12, reconstruction_weight=0.9, splits=[0.6, 0.2, 0.2], test_augmentation=False)

Dataset preparation...
Model preparation...
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 12, 13, 13]           1,776
       BatchNorm2d-2           [-1, 12, 13, 13]              24
              ReLU-3           [-1, 12, 13, 13]               0
            Conv2d-4             [-1, 32, 9, 9]           9,632
       BatchNorm2d-5             [-1, 32, 9, 9]              64
              ReLU-6             [-1, 32, 9, 9]               0
            Conv2d-7             [-1, 64, 7, 7]          18,496
       BatchNorm2d-8             [-1, 64, 7, 7]             128
              ReLU-9             [-1, 64, 7, 7]               0
           Conv2d-10            [-1, 128, 2, 2]         204,928
      BatchNorm2d-11            [-1, 128, 2, 2]             256
             ReLU-12            [-1, 128, 2, 2]               0
          Flatten-13                  [-1, 512]               0
           Linear-14                  [-1, 256]         131,328
             ReLU-15                  [-1, 256]               0
           Linear-16                   [-1, 20]           5,140
             ReLU-17                   [-1, 20]               0
          Dropout-18                   [-1, 20]               0
          Encoder-19                   [-1, 20]               0
           Linear-20                  [-1, 256]           5,376
             ReLU-21                  [-1, 256]               0
          Dropout-22                  [-1, 256]               0
           Linear-23                  [-1, 512]         131,584
             ReLU-24                  [-1, 512]               0
        Unflatten-25            [-1, 128, 2, 2]               0
  ConvTranspose2d-26             [-1, 64, 7, 7]         204,864
      BatchNorm2d-27             [-1, 64, 7, 7]             128
             ReLU-28             [-1, 64, 7, 7]               0
  ConvTranspose2d-29             [-1, 32, 9, 9]          18,464
      BatchNorm2d-30             [-1, 32, 9, 9]              64
             ReLU-31             [-1, 32, 9, 9]               0
  ConvTranspose2d-32           [-1, 12, 13, 13]           9,612
      BatchNorm2d-33           [-1, 12, 13, 13]              24
             ReLU-34           [-1, 12, 13, 13]               0
  ConvTranspose2d-35            [-1, 3, 32, 32]           1,767
      BatchNorm2d-36            [-1, 3, 32, 32]               6
          Decoder-37            [-1, 3, 32, 32]               0
           Linear-38                  [-1, 256]           5,376
             ReLU-39                  [-1, 256]               0
          Dropout-40                  [-1, 256]               0
           Linear-41                  [-1, 512]         131,584
             ReLU-42                  [-1, 512]               0
           Linear-43                  [-1, 256]         131,328
             ReLU-44                  [-1, 256]               0
           Linear-45                    [-1, 4]           1,028
      OutputLayer-46                    [-1, 4]               0
================================================================
Total params: 1,012,977
Trainable params: 1,012,977
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.48
Params size (MB): 3.86
Estimated Total Size (MB): 4.36
----------------------------------------------------------------
Start training...
Epoch 1/40
TRAIN | loss: 0.5651 - global_acc: 0.7698 - class_acc: [0.7847 0.6866 0.8662 0.7413] 
VALID | loss: 0.1083 - global_acc: 0.9576 - class_acc: [0.9986 0.9980 0.8448 0.9855] - BEST!
Epoch 2/40
TRAIN | loss: 0.1212 - global_acc: 0.9605 - class_acc: [0.9964 0.9635 0.9410 0.9404] 
VALID | loss: 0.0861 - global_acc: 0.9678 - class_acc: [1.0000 1.0000 0.8846 0.9911] - BEST!
Epoch 3/40
TRAIN | loss: 0.0918 - global_acc: 0.9707 - class_acc: [0.9982 0.9759 0.9530 0.9555] 
VALID | loss: 0.0876 - global_acc: 0.9603 - class_acc: [1.0000 0.9993 0.8448 0.9972]
Epoch 4/40
TRAIN | loss: 0.0789 - global_acc: 0.9754 - class_acc: [0.9980 0.9762 0.9608 0.9660] 
VALID | loss: 0.0566 - global_acc: 0.9806 - class_acc: [1.0000 1.0000 0.9414 0.9808] - BEST!
Epoch 5/40
TRAIN | loss: 0.0630 - global_acc: 0.9803 - class_acc: [0.9996 0.9811 0.9700 0.9697] 
VALID | loss: 0.0322 - global_acc: 0.9872 - class_acc: [1.0000 1.0000 0.9723 0.9771] - BEST!
Epoch 6/40
TRAIN | loss: 0.0590 - global_acc: 0.9820 - class_acc: [0.9991 0.9847 0.9709 0.9732] 
VALID | loss: 0.0461 - global_acc: 0.9869 - class_acc: [0.9993 1.0000 0.9630 0.9873]
Epoch 7/40
TRAIN | loss: 0.0601 - global_acc: 0.9804 - class_acc: [0.9984 0.9806 0.9721 0.9707] 
VALID | loss: 0.0332 - global_acc: 0.9913 - class_acc: [1.0000 1.0000 0.9673 0.9979] - BEST!
Epoch 8/40
TRAIN | loss: 0.0484 - global_acc: 0.9843 - class_acc: [0.9989 0.9817 0.9764 0.9807] 
VALID | loss: 0.0260 - global_acc: 0.9937 - class_acc: [1.0000 1.0000 0.9919 0.9833] - BEST!
Epoch 9/40
TRAIN | loss: 0.0444 - global_acc: 0.9867 - class_acc: [0.9993 0.9845 0.9821 0.9805] 
VALID | loss: 0.0263 - global_acc: 0.9930 - class_acc: [1.0000 1.0000 0.9757 0.9959]
Epoch 10/40
TRAIN | loss: 0.0395 - global_acc: 0.9871 - class_acc: [0.9989 0.9843 0.9803 0.9848] 
VALID | loss: 0.0382 - global_acc: 0.9910 - class_acc: [1.0000 0.9993 0.9646 0.9993]
Epoch 11/40
TRAIN | loss: 0.0387 - global_acc: 0.9882 - class_acc: [0.9989 0.9829 0.9837 0.9872] 
VALID | loss: 0.0171 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9960 0.9908] - BEST!
Epoch 12/40
TRAIN | loss: 0.0420 - global_acc: 0.9882 - class_acc: [0.9995 0.9847 0.9834 0.9852] 
VALID | loss: 0.0225 - global_acc: 0.9934 - class_acc: [1.0000 1.0000 0.9939 0.9801]
Epoch 13/40
TRAIN | loss: 0.0385 - global_acc: 0.9892 - class_acc: [0.9989 0.9865 0.9878 0.9836] 
VALID | loss: 0.1343 - global_acc: 0.9484 - class_acc: [1.0000 0.9902 0.9966 0.8077]
Epoch 14/40
TRAIN | loss: 0.0424 - global_acc: 0.9865 - class_acc: [0.9977 0.9828 0.9840 0.9816] 
VALID | loss: 0.0180 - global_acc: 0.9966 - class_acc: [1.0000 1.0000 0.9953 0.9912]
Epoch 15/40
TRAIN | loss: 0.0330 - global_acc: 0.9898 - class_acc: [0.9996 0.9839 0.9887 0.9870] 
VALID | loss: 0.0152 - global_acc: 0.9957 - class_acc: [1.0000 1.0000 0.9973 0.9858]
Epoch 16/40
TRAIN | loss: 0.0279 - global_acc: 0.9913 - class_acc: [0.9993 0.9862 0.9910 0.9890] 
VALID | loss: 0.0164 - global_acc: 0.9980 - class_acc: [1.0000 1.0000 0.9925 0.9993] - BEST!
Epoch 17/40
TRAIN | loss: 0.0296 - global_acc: 0.9900 - class_acc: [0.9987 0.9844 0.9888 0.9881] 
VALID | loss: 0.0243 - global_acc: 0.9952 - class_acc: [1.0000 1.0000 0.9944 0.9867]
Epoch 18/40
TRAIN | loss: 0.0271 - global_acc: 0.9917 - class_acc: [0.9995 0.9871 0.9899 0.9902] 
VALID | loss: 0.0090 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9973 0.9938]
Epoch 19/40
TRAIN | loss: 0.0308 - global_acc: 0.9896 - class_acc: [0.9993 0.9805 0.9892 0.9894] 
VALID | loss: 0.0109 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9938 0.9973]
Epoch 20/40
TRAIN | loss: 0.0323 - global_acc: 0.9902 - class_acc: [0.9993 0.9852 0.9874 0.9892] 
VALID | loss: 0.0123 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9953 0.9906]
Epoch 21/40
TRAIN | loss: 0.0284 - global_acc: 0.9911 - class_acc: [0.9989 0.9824 0.9923 0.9913] 
VALID | loss: 0.0114 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9915 0.9987]
Epoch 22/40
TRAIN | loss: 0.0269 - global_acc: 0.9926 - class_acc: [0.9991 0.9864 0.9929 0.9917] 
VALID | loss: 0.0124 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9993 0.9915]
Epoch 23/40
TRAIN | loss: 0.0286 - global_acc: 0.9909 - class_acc: [0.9991 0.9834 0.9907 0.9902] 
VALID | loss: 0.0141 - global_acc: 0.9978 - class_acc: [1.0000 1.0000 0.9940 0.9972]
Epoch 24/40
TRAIN | loss: 0.0298 - global_acc: 0.9906 - class_acc: [0.9991 0.9796 0.9922 0.9916] 
VALID | loss: 0.0549 - global_acc: 0.9820 - class_acc: [1.0000 1.0000 0.9274 1.0000]
Epoch 25/40
TRAIN | loss: 0.0269 - global_acc: 0.9917 - class_acc: [0.9998 0.9814 0.9932 0.9918] 
VALID | loss: 0.0241 - global_acc: 0.9961 - class_acc: [1.0000 1.0000 0.9858 0.9986]
Epoch 26/40
TRAIN | loss: 0.0282 - global_acc: 0.9912 - class_acc: [0.9993 0.9825 0.9916 0.9910] 
VALID | loss: 0.0137 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9909 0.9960]
Epoch 27/40
TRAIN | loss: 0.0250 - global_acc: 0.9917 - class_acc: [0.9991 0.9819 0.9931 0.9925] 
VALID | loss: 0.0121 - global_acc: 0.9963 - class_acc: [1.0000 1.0000 0.9993 0.9855]
Epoch 28/40
TRAIN | loss: 0.0284 - global_acc: 0.9926 - class_acc: [0.9991 0.9888 0.9927 0.9897] 
VALID | loss: 0.0457 - global_acc: 0.9903 - class_acc: [1.0000 0.9980 0.9652 0.9972]
Epoch 29/40
TRAIN | loss: 0.0262 - global_acc: 0.9924 - class_acc: [1.0000 0.9854 0.9912 0.9928] 
VALID | loss: 0.0318 - global_acc: 0.9918 - class_acc: [1.0000 1.0000 0.9933 0.9743]
Epoch 30/40
TRAIN | loss: 0.0231 - global_acc: 0.9931 - class_acc: [0.9998 0.9838 0.9947 0.9942] 
VALID | loss: 0.0096 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9954 0.9980] - BEST!
Epoch 31/40
TRAIN | loss: 0.0216 - global_acc: 0.9929 - class_acc: [0.9988 0.9842 0.9945 0.9943] 
VALID | loss: 0.0110 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9972 1.0000] - BEST!
Epoch 32/40
TRAIN | loss: 0.0239 - global_acc: 0.9934 - class_acc: [0.9998 0.9854 0.9947 0.9937] 
VALID | loss: 0.0144 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9912 0.9993]
Epoch 33/40
TRAIN | loss: 0.0204 - global_acc: 0.9940 - class_acc: [0.9991 0.9846 0.9955 0.9965] 
VALID | loss: 0.0081 - global_acc: 0.9995 - class_acc: [1.0000 1.0000 0.9993 0.9986] - BEST!
Epoch 34/40
TRAIN | loss: 0.0257 - global_acc: 0.9922 - class_acc: [0.9993 0.9825 0.9928 0.9943] 
VALID | loss: 0.0086 - global_acc: 0.9985 - class_acc: [1.0000 1.0000 1.0000 0.9939]
Epoch 35/40
TRAIN | loss: 0.0283 - global_acc: 0.9916 - class_acc: [1.0000 0.9817 0.9924 0.9924] 
VALID | loss: 0.0267 - global_acc: 0.9964 - class_acc: [1.0000 1.0000 0.9903 0.9958]
Epoch 36/40
TRAIN | loss: 0.0191 - global_acc: 0.9940 - class_acc: [0.9998 0.9858 0.9958 0.9950] 
VALID | loss: 0.0144 - global_acc: 0.9976 - class_acc: [1.0000 1.0000 0.9926 0.9980]
Epoch 37/40
TRAIN | loss: 0.0242 - global_acc: 0.9925 - class_acc: [0.9998 0.9828 0.9921 0.9955] 
VALID | loss: 0.0245 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9918 0.9952]
Epoch 38/40
TRAIN | loss: 0.0193 - global_acc: 0.9933 - class_acc: [0.9995 0.9849 0.9947 0.9941] 
VALID | loss: 0.0087 - global_acc: 0.9983 - class_acc: [1.0000 1.0000 0.9937 0.9993]
Epoch 39/40
TRAIN | loss: 0.0249 - global_acc: 0.9930 - class_acc: [1.0000 0.9846 0.9929 0.9942] 
VALID | loss: 0.0083 - global_acc: 0.9993 - class_acc: [1.0000 1.0000 0.9993 0.9979]
Epoch 40/40
TRAIN | loss: 0.0259 - global_acc: 0.9921 - class_acc: [0.9984 0.9817 0.9937 0.9945] 
VALID | loss: 0.0172 - global_acc: 0.9969 - class_acc: [1.0000 1.0000 0.9909 0.9967]


Evaluating...
TEST | loss: 0.0154 - global_acc: 0.9968 - class_acc: [1.0000 1.0000 0.9995 0.9924]


